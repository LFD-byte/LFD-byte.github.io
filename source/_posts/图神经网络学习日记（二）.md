---
title: 图神经网络学习日记（二）传统机器学习方法
date: 2023-05-28 16:52:00
author: 培根请加蛋
img: 
top: true
hide: false
cover: true
coverImg: 
toc: true
mathjax: true
summary: 图神经网络学习日记（二）
categories: 图神经网络
tags:
  - 图神经网络
---

**标准机器学习范式**

首先，基于启发式函数或领域知识提取一些统计特征；然后将其作为标准机器学习分类器（如逻辑回归）的输入。

## 图统计特征

### 节点层面的统计特征

**节点的度**

节点$u$的度反映与这个节点相连接的边的数目，可由下式表示
$$
d_u = \sum_{v \in \mathcal{V}} A[u,v]
$$
对于有向图和加权图，度分为入度和出度。对矩阵$A$中的节点$u$的行求和可以得到出度，对节点$u$的列求和可以得到入度。

**节点的中心性**

角度一：特征向量中心性度量不仅考虑邻居节点个数的度，还考虑了邻居节点的重要性。
$$
e_u = \frac{1}{\lambda}\sum_{v\in \mathcal{V}}A[u,v]e_v, \forall u \in \mathcal{V}
$$
将向量表示$e$代入上述等式取代节点中心性向量可得到邻接矩阵的标准特征向量方程：
$$
\lambda e = Ae
$$
角度二：特征向量中心性衡量了一个节点在路径无限长的情况下在随机游走时被访问的概率。这种理解方式连接了节点重要性、随机游走和谱三个重要概念。$\lambda$是$A$的主要特征向量，可通过幂次迭代法则计算$e$如下所示：
$$
e^{(t+1)} = Ae^{(t)}
$$
从向量$e^{(0)}=(1,1,\cdots,1)^T$开始，依据幂次迭代法则，第一次迭代可以得到每个节点的度，在第$t$次迭代$(t \geq 1)$时，$e^{(t)}$包括了尝试到达每个节点且长度为$t$的路线的长度的数量，无限重复下去可得到路径无限长时每个节点被访问的次数。



**聚类系数**

聚类系数通过一个节点的局部邻域中闭合三角形的比例度量节点的邻居节点聚类的紧密程度。聚类系数计算方法 Local Variant 方法如下式所示：
$$
c_u = \frac{|(v_1, v_2)\in \varepsilon: v_1, v_2 \in \mathcal{N}(u)|}{\binom{d_u}{2}}
$$
其中$\mathcal{N}(u)=\{v\in \mathcal{V}: (u,v)\in \varepsilon\}$表示节点$u$的邻居节点。

**闭合三角形、自我中心图、Motifs**

**闭合三角形**



### 图层面的统计特征

节点袋



Weisfeiler-Lehman 核



Graphlets 和基于路径的方法



## 邻域重叠检测



## 图的拉普拉斯矩阵和图的谱方法

