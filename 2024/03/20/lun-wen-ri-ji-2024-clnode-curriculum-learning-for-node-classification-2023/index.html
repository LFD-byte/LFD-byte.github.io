

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="培根请加蛋">
  <meta name="keywords" content="">
  
    <meta name="description" content="CLNode Curriculum Learning for Node Classification">
<meta property="og:type" content="article">
<meta property="og:title" content="2024 论文砖 CLNode Curriculum Learning for Node Classification(2023)">
<meta property="og:url" content="https://blog.lfd.world/2024/03/20/lun-wen-ri-ji-2024-clnode-curriculum-learning-for-node-classification-2023/index.html">
<meta property="og:site_name" content="培根请加蛋">
<meta property="og:description" content="CLNode Curriculum Learning for Node Classification">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322101325947.png">
<meta property="og:image" content="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322102804876.png">
<meta property="article:published_time" content="2024-03-20T07:26:00.000Z">
<meta property="article:modified_time" content="2024-03-25T08:52:04.679Z">
<meta property="article:author" content="培根请加蛋">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Curriculum Learning">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322101325947.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>2024 论文砖 CLNode Curriculum Learning for Node Classification(2023) - 培根请加蛋</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.lfd.world","root":"/","version":"1.9.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":false,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>培根请加蛋</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="2024 论文砖 CLNode Curriculum Learning for Node Classification(2023)"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-03-20 15:26" pubdate>
          2024年3月20日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          10k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          88 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">2024 论文砖 CLNode Curriculum Learning for Node Classification(2023)</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="abstract">Abstract</h2>
<p>节点分类是一项基于图的基本任务，旨在预测未标记节点的类别，其中图神经网络（GNN）是最先进的方法。当前的
GNN
假设训练集中的节点在训练期间贡献相等。然而，训练节点的质量差异很大，两种类型的低质量训练节点可能会损害
GNN 的性能：（1）位于类边界附近的类间节点，缺乏相应类的典型特征。由于
GNN 是数据驱动的方法，因此对这些节点进行训练可能会降低准确性。 (2)
错误标记的节点。在现实世界的图中，节点经常被错误标记，这会显着降低 GNN
的鲁棒性。为了减轻低质量训练节点的不利影响，我们提出了
CLNode，它采用选择性训练策略根据节点的质量来训练
GNN。具体来说，我们首先设计一个多视角难度测量器来准确测量训练节点的质量。然后，根据测量的质量，我们使用训练调度程序来选择适当的训练节点来在每个时期训练
GNN。为了评估 CLNode 的有效性，我们将其合并到六个代表性骨干 GNN
中进行了广泛的实验。现实网络的实验结果表明，CLNode
是一个通用框架，可以与各种 GNN 结合以提高其准确性和鲁棒性。</p>
<h2 id="introduction">Introduction</h2>
<p>节点分类是一项基本的基于图的任务。给定一个带有有限标记节点（训练节点）的图，该任务旨在将标签分配给未标记节点[23]。最先进的节点分类方法是图神经网络（GNN）[35,
40]。一般来说，GNN
通过聚合从邻居传递的消息来更新节点表示。受益于这种聚合机制，GNN
学习保留拓扑信息和节点特征属性的低维节点表示，然后将其用于预测标签。尽管已经提出了许多基于
GNN 的节点分类工作
[3,10,16,22,34]，但这些工作通常假设所有训练节点的贡献相等。事实上，训练节点的质量差异很大。作为数据驱动的方法，GNN
通过在低质量节点上进行训练而表现出性能下降。</p>
<h2 id="related-work">Related Work</h2>
<h3 id="node-classification-and-gnns">Node Classification and GNNs</h3>
<p>节点分类[23]旨在预测给定图中未标记节点的标签。作为图上的一项基本任务，节点分类具有多种应用，包括欺诈检测
[7,12,39]、安全和隐私分析 [27] 以及社区检测 [11, 14]。</p>
<p>最近，GNN 已成为分析图数据的有前途的方法。由于 GNN
的悠久历史，我们建议读者参考 [35, 40]
进行全面回顾。根据图卷积的定义，GNN 可以大致分为两类，即基于谱的 [2, 16,
26] 和基于空间的 [10, 37]。布鲁纳等人 [2]
首先通过在谱空间上利用谱滤波器来探索基于谱的 GNN。在后续工作中，GCN
[16]简化了图卷积操作。 SGC[34] 提出消除 GCN
中的非线性，从而加速模型。与基于谱的方法不同，基于空间的方法通过对空间上的近邻执行操作来直接在图上定义卷积。
GraphSAGE [10]
是一个通用的归纳框架，它通过对本地邻居进行采样来生成节点的表示。 JK-Net
[37]设计了一种基于图结构的替代策略来选择节点的邻居。尽管 GNN
取得了巨大的成功，但它们只是简单地假设所有训练节点做出同等的贡献；因此，对低质量困难节点的训练会显着降低其准确性和鲁棒性。</p>
<h3 id="curriculum-learning">Curriculum Learning</h3>
<p>受人类认知过程背后的学习原理的启发，课程学习[1]被提出作为一种训练策略，将机器学习模型从较容易的样本训练到较难的样本。先前的研究[1,32,33]表明课程学习提高了泛化能力并引导模型走向更好的参数空间。受此推动，学者们在广泛的领域中利用了课程学习的力量，包括计算机视觉（CV）[9,13,38]、自然语言处理（NLP）[6,28,29]和图分类[
31]等。然而，据我们所知，还没有任何工作尝试将课程学习应用于节点分类。</p>
<h2 id="preliminaries">Preliminaries</h2>
<h3 id="notation">Notation</h3>
<p>令 <span class="math inline">\(G = (\mathcal{V}, \mathcal{E},
X)\)</span> 表示一个图，其中 <span
class="math inline">\(\mathcal{V}\)</span> 是节点集，<span
class="math inline">\(\mathcal{E}\)</span> 是边集，<span
class="math inline">\(X\)</span> 是节点特征矩阵。节点 <span
class="math inline">\(i\)</span> 的输入特征为 <span
class="math inline">\(x_i\)</span> ，节点 <span
class="math inline">\(i\)</span> 的邻域为 <span
class="math inline">\(\mathcal{N}(i)\)</span>。对于节点分类任务，给出一个标记节点集
<span class="math inline">\(\mathcal{V}_L = {v_1, ..., v_l
}\)</span>，其中 <span class="math inline">\(Y_L\)</span> 表示输入标签。
<span class="math inline">\(C\)</span>
是类的集合。节点分类的目标是预测图中未标记节点的标签。</p>
<h3 id="graph-neural-networks">Graph Neural Networks</h3>
<p>一般来说，GNN 每层的每个节点 i
都涉及两个关键计算：（1）邻域聚合：聚合从 <span
class="math inline">\(\mathcal{N}(i)\)</span> 传递的消息。
(2)更新表示：根据上一层的表示和聚合消息更新i的表示。形式上，节点 <span
class="math inline">\(i\)</span> 的第 <span
class="math inline">\(l\)</span> 层表示由下式给出： <span
class="math display">\[
h_i^l = UPDATE(h_i^{l-1}, AGGREGATE(\{ h_j^{l-1}| j \in \mathcal{N}(i)
\})) \tag{1}
\]</span> 最终节点表示 <span class="math inline">\(h_i^L\)</span>
，即最后一层的输出，用于各种下游任务。对于节点分类任务，在获得节点表示后，通常使用多层感知器将它们映射到预测标签。</p>
<h3 id="curriculum-learning-1">Curriculum Learning</h3>
<p>课程学习通过使用课程来训练模型来减轻低质量样本的不利影响。课程是
<span class="math inline">\(T\)</span> 个训练周期中的一系列训练标准
<span class="math inline">\(&lt; Q_1, \dots , Q_t , \dots, Q_T
&gt;\)</span> 。每个标准 <span class="math inline">\(Q_t\)</span>
都是一个训练子集。初始 <span class="math inline">\(Q_1\)</span>
由更简单的样本组成；随着 <span class="math inline">\(t\)</span>
的增加，更困难的样本逐渐引入 <span class="math inline">\(Q_t\)</span>
中。本质上，设计这样一个节点分类课程需要我们设计一个难度测量器和一个训练调度器。这里，难度测量器估计每个训练节点的难度；随后，根据难度，训练调度器在任意训练时期
<span class="math inline">\(t\)</span> 生成 <span
class="math inline">\(Q_t\)</span> 来训练模型。</p>
<h2 id="methodology">Methodology</h2>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240320154049737.png"
alt="image-20240320154049737" />
<figcaption aria-hidden="true">image-20240320154049737</figcaption>
</figure>
<p>在本节中，我们将介绍 CLNode 的详细信息。如图 3 所示，CLNode
包含两个组件：(i) 多视角难度测量器（图
3(a)）。我们首先进行标准的节点分类以获得额外的标签信息，然后提出两个从局部和全局角度的难度测量器来测量节点难度。
(ii) 持续训练调度程序（图
3(b)）。确定节点难度后，我们设计了一个训练调度器，最初用简单的节点训练骨干
GNN，并不断引入更难的训练节点。通过减少对困难节点的关注，CLNode
提高了主干 GNN 的准确性和鲁棒性。我们将在以下小节中详细介绍 CLNode
的组件。</p>
<h3 id="multi-perspective-difficulty-measurer">Multi-perspective
Difficulty Measurer</h3>
<p>一般来说，邻域聚合受益于图的<strong>同质性</strong>，即节点 i 的邻居
<span class="math inline">\(\mathcal{N}(i)\)</span> 往往具有与 <span
class="math inline">\(i\)</span>
相同的标签。然而，困难节点违反了同质性；例如，类间困难节点的邻居具有不同的标签，因为它们属于多个类。更进一步，可以借助标签信息来衡量节点的难度。因此，第一步是为未标记的节点分配伪标签（见图3（a））。具体来说，我们首先在整个训练集
<span class="math inline">\(\mathcal{V}_L\)</span> 上训练 GNN <span
class="math inline">\(f_1\)</span>
以执行标准节点分类。训练过程结束后，<span
class="math inline">\(f_1\)</span> 用于获取伪标签： <span
class="math display">\[
H = f_1(\mathcal{G}), \tag{2}
\]</span></p>
<p><span class="math display">\[
Y_P = MLP(H), \tag{3}
\]</span></p>
<p>其中 <span class="math inline">\(H\)</span> 是 GNN <span
class="math inline">\(f_1\)</span> 获得的节点表示矩阵，<span
class="math inline">\(Y_P\)</span>
是多层感知器预测的伪标签。然而，直接使用 <span
class="math inline">\(Y_P\)</span>
来测量节点难度可能会导致结果不准确，因为训练节点的 <span
class="math inline">\(Y_P\)</span> 可能与输入标签 <span
class="math inline">\(Y_L\)</span>
不同。因此，为了更好地衡量节点难度，我们保留训练节点的输入标签： <span
class="math display">\[
\tilde{Y}[i] = \begin{cases}  
Y_L[i], &amp; i \in \mathcal{V}_L \\
Y_P[i], &amp; otherwise \tag{4}
\end{cases}
\]</span>
随后，为了识别两种类型的困难节点，即类间节点和错误标记节点，我们提出了两种难度测量器来捕获局部和全局信息来测量节点难度。</p>
<h4 id="neighborhood-based-difficulty-measurer.">Neighborhood-based
Difficulty Measurer.</h4>
<p>我们首先介绍如何从局部角度识别困难节点。获得 <span
class="math inline">\(\tilde{Y}\)</span> 后，对于每个训练节点 <span
class="math inline">\(u\)</span>，我们参考其邻域的标签分布来计算其难度。第一类困难节点（类间节点）具有属于多个类的不同邻居。为了识别这些类间困难节点，我们计算邻域标签的多样性：
<span class="math display">\[
P_c(u) = \frac{| \{ \tilde{Y}[v]=c|v \in \tilde{\mathcal{N}}(u) \} |}{|
\hat{\mathcal{N}}(u) |}, \tag{5}
\]</span></p>
<p><span class="math display">\[
D_{local}(u) = -\sum_{c\in C} P_c(u)log(P_c(u)), \tag{6}
\]</span></p>
<p>其中 <span class="math inline">\(\hat{\mathcal{N}}(u)\)</span> 表示
<span class="math inline">\(\mathcal{N}(u) \cup \{u\}\)</span>，<span
class="math inline">\(P_c(u)\)</span> 表示邻域 <span
class="math inline">\(\hat{\mathcal{N}}(u)\)</span> 属于 <span
class="math inline">\(c\)</span> 类的比例。 <span
class="math inline">\(D_{local}\)</span> 越大表示邻域越多样化。以图 3(a)
为例，节点 1 的 <span class="math inline">\(D_{local}\)</span> 为
0.54，远大于 <span class="math inline">\(D_{local} (8)\)</span> =
0，表明节点 1 比节点 8 拥有更多样的邻居。<span
class="math inline">\(D_{local}\)</span>
较大的节点更有可能是类间节点。因此，在邻域聚合过程中，这些节点聚合邻居的特征以获得不清晰的表示，从而使
GNN 难以学习。通过减少对这些困难节点的关注，CLNode
可以学到更多有用的信息，并有效提高主干 GNN 的准确性。</p>
<h4 id="feature-based-difficulty-measurer.">Feature-based Difficulty
Measurer.</h4>
<p>由于伪标签可能不准确，因此可能无法使用本地信息识别错误标记的训练节点。例如，考虑图
4 中的训练节点 7，其真值标签为 <span
class="math inline">\(c_3\)</span>，但被错误标记为 <span
class="math inline">\(c_1\)</span>。节点 7
的标签信息会影响其邻居的伪标签。因此，节点 2
的伪标签很可能被预测为误标签类 <span
class="math inline">\(c_1\)</span>，因此节点 7
的局部标签分布是一致的，从中我们无法将其识别为误标签节点。因此，我们建议使用全局特征信息来识别错误标记的节点。</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322162230804.png"
alt="image-20240322162230804" />
<figcaption aria-hidden="true">image-20240322162230804</figcaption>
</figure>
<p>同一类的节点具有相似的特征，例如，在论文引用网络中，同一领域的论文往往包含相同的关键词。然而，错误标记的节点违反了这一原则。例如，在图
4 中，错误标记的节点 7 与其标签类的许多节点（例如节点
10）的特征相似度较低，因为它们实际上不属于同一类。相反，节点 7 与类
<span class="math inline">\(c_3\)</span> 中的节点（例如节点
8）具有较高的特征相似度。因此，通过探索特征相似性，我们可以推断节点 7
很可能被错误标记。输入特征 <span class="math inline">\(X\)</span>
在高维空间中是稀疏的，相反，我们使用 <span
class="math inline">\(H\)</span>（见方程（2））作为节点特征来计算相似度。令
<span class="math inline">\(h_v\)</span> 表示节点 <span
class="math inline">\(v\)</span> 的特征，则 <span
class="math inline">\(c\)</span> 类的代表特征定义为 <span
class="math inline">\(c\)</span> 类节点特征的平均值： <span
class="math display">\[
\mathcal{V}_L = \{ u| \tilde{Y}[v] = c \}, \tag{7}
\]</span></p>
<p><span class="math display">\[
h_c = AVG(h_v|v \in \mathcal{V}_c), \tag{8}
\]</span></p>
<p>其中 <span class="math inline">\(\mathcal{V}_c\)</span> 表示属于
<span class="math inline">\(c\)</span> 类的节点，<span
class="math inline">\(h_c\)</span> 是 <span
class="math inline">\(c\)</span>
类的代表特征。为了识别错误标记的困难节点，对于每个训练节点 <span
class="math inline">\(u\)</span>，我们计算其与标签类的特征相似度： <span
class="math display">\[
S(u) = \frac{exp(h_u \cdot h_{c_u})}{max_{c \in C}(h_u \cdot h_c)},
\tag{9}
\]</span> 其中 <span class="math inline">\(c_u\)</span> 表示节点 <span
class="math inline">\(u\)</span> 的标签类别，<span
class="math inline">\(S(u)\)</span> 计算 <span
class="math inline">\(h_u\)</span> 和 <span
class="math inline">\(h_{c_u}\)</span>
之间的特征相似度。错误标记的节点往往比正确标记的节点具有更小的 <span
class="math inline">\(S (u)\)</span>。基于 <span
class="math inline">\(S(u)\)</span>，基于特征的难度测量器定义为： <span
class="math display">\[
D_{global}(u) = 1 - S(u). \tag{10}
\]</span> <span class="math inline">\(D_{global}\)</span>
从全局角度衡量节点难度。通过使用 <span
class="math inline">\(D_{global}\)</span>
来识别错误标记的训练节点，CLNode
有选择地从训练过程中排除这些节点，从而提高了主干 GNN
对标记噪声的鲁棒性。从局部和全局角度考虑两个难度衡量指标，我们最终将
<span class="math inline">\(u\)</span> 的难度定义为： <span
class="math display">\[
D(u) = D_{local} + \alpha \cdot D_{global}(u), \tag{11}
\]</span> 其中 <span class="math inline">\(\alpha\)</span> 是控制 <span
class="math inline">\(D_{global}(u)\)</span> 权重的超参数。</p>
<h3 id="continuous-training-scheduler">Continuous Training
Scheduler</h3>
<p>在测量节点难度后，我们使用基于课程的训练策略来训练更好的 GNN
模型（见图 3(b)）。为了与 <span class="math inline">\(f_1\)</span>
区分开，我们将用课程训练的模型表示为 <span
class="math inline">\(f_2\)</span>。我们提出了一个持续训练调度程序来生成从简单到困难的课程。更详细地说，我们首先对训练集
<span class="math inline">\(\mathcal{V}_L\)</span>
按照节点难度升序进行排序；随后，使用调步函数 <span
class="math inline">\(g(t)\)</span> 将每个训练时期 <span
class="math inline">\(t\)</span> 映射到范围为 (0, 1] 的标量 <span
class="math inline">\(\lambda_t\)</span>，这意味着最简单的训练节点的比例
<span class="math inline">\(\lambda_t\)</span> 被用作 <span
class="math inline">\(t\)</span> 时刻的训练子集。令 <span
class="math inline">\(\lambda_0\)</span>
表示可用的最简单节点的初始比例，而 <span
class="math inline">\(T\)</span> 表示 <span
class="math inline">\(g(t)\)</span> 第一次达到 1 时的
epoch。我们考虑三种调步函数，即 linear、root 和 geometric：</p>
<ul>
<li><p>linear: <span class="math display">\[
g(t) = min(1, \lambda_0 + (1 - \lambda_0) * \frac{t}{T}). \tag{12}
\]</span></p></li>
<li><p>root: <span class="math display">\[
g(t) = min(1, \sqrt{\lambda_0^2 + (1 - \lambda_0^2) * \frac{t}{T}}).
\tag{13}
\]</span></p></li>
<li><p>geometric <span class="math display">\[
g(t) = min(1, 2^{log_2 \lambda_0 - log_2\lambda_0 * \frac{t}{T}}).
\tag{14}
\]</span></p></li>
</ul>
<p>这三个调步函数的可视化如图 5 所示。如图所示，linear
函数增加了以均匀速率训练节点的难度；root
在更少的时期内引入更困难的节点，而 geometric
函数在简单节点的子集上训练更多的时期。 CLNode
通过使用调步函数不断地将训练节点引入到训练过程中，为不同难度级别的节点分配适当的训练权重。具体来说，训练节点越难，就越晚被引入训练过程，意味着其训练权重越小。</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322162253706.png"
alt="image-20240322162253706" />
<figcaption aria-hidden="true">image-20240322162253706</figcaption>
</figure>
<p>此外，当 <span class="math inline">\(t = T\)</span>
时，我们不会立即停止训练，因为此时主干 GNN <span
class="math inline">\(f_2\)</span>
可能还没有完全探索最近引入的节点的知识。相反，当 <span
class="math inline">\(t &gt; T\)</span> 时，我们使用整个训练集来训练
<span class="math inline">\(f_2\)</span>
，直到验证集上的测试准确性收敛。</p>
<h3 id="pseudo-code-and-complexity-analysis">Pseudo-code and Complexity
Analysis</h3>
<p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322101325947.png" alt="image-20240322101325947" style="zoom:80%;" /></p>
<p>在本小节中，我们将介绍 CLNode 的伪代码并探讨其时间复杂度。算法 1
详细介绍了 CLNode 的过程。第 2-7 行描述了测量节点难度的过程，第 8-17
行描述了用课程训练主干 GNN f2 的过程。训练过程结束后，f2
最终用于节点分类（参见第 18 行）。正如伪代码所示，CLNode
很容易插入任何骨干 GNN，因为它只改变每个训练时期的训练集。</p>
<p>为了方便复杂度分析，我们考虑 GCN 作为主干。 <span
class="math inline">\(L\)</span> 层 GCN 在一个epoch中的时间复杂度为
<span class="math inline">\(O(L|\mathcal{E}|F +
L|\mathcal{V}|F^2)\)</span>，其中 <span class="math inline">\(F\)</span>
是节点特征属性的数量。我们假设GCN 在 <span
class="math inline">\(T_1\)</span> 个 epoch 后收敛，因此其时间复杂度为
<span class="math inline">\(O(T_1 \cdot L|\mathcal{E}|F +
L|\mathcal{V}|F^2)\)</span>，这也是训练 <span
class="math inline">\(f_1\)</span>
的时间复杂度。接下来，测量节点难度的时间复杂度为 <span
class="math inline">\(O(ld + l|C|F)\)</span>，其中 <span
class="math inline">\(d\)</span> 是平均节点度。排序 <span
class="math inline">\(\mathcal{V}_L\)</span> 的时间复杂度为 <span
class="math inline">\(O(l \cdot log l)\)</span>。最后我们分析训练 <span
class="math inline">\(f_2\)</span> 的时间复杂度。我们首先使用课程训练
<span class="math inline">\(T\)</span> 个 epoch，然后用整个 <span
class="math inline">\(\mathcal{V}_L\)</span> 训练 <span
class="math inline">\(f_2\)</span> 直到收敛。第 <span
class="math inline">\(T\)</span> 个 epoch
的训练可以看作是用高质量训练节点预训练 <span
class="math inline">\(f_2\)</span>。因此，<span
class="math inline">\(f_2\)</span> 将在 <span class="math inline">\(T +
T_1\)</span> epoch 之前收敛。因为 <span class="math inline">\(l &lt;
|\mathcal{V}| \ll |E|\)</span>，CLNode 时间复杂度上限为 <span
class="math inline">\(O ((2T_1 +T ) \cdot (L|\mathcal{E}|F +
L|\mathcal{V}|F^2))\)</span>。在我们的实验中，我们观察到 CLNode
的运行时间大约是基线 GNN 的两倍。</p>
<h2 id="experiments">Experiments</h2>
<p>在本节中，我们首先评估 CLNode 相对于各种骨干 GNN
所实现的准确率提升。在带有标签噪声的图上进行了进一步的实验，以证明
CLNode 的鲁棒性。随后，我们进行了消融研究来验证 CLNode
中组件的有效性。最后，我们讨论参数对超参数的敏感性。</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322102741753.png"
alt="image-20240322102741753" />
<figcaption aria-hidden="true">image-20240322102741753</figcaption>
</figure>
<p>我们在五个基准数据集上进行了实验：Cora、Citeseer、PubMed [23]、Amazon
Computers (A-Computers) 和 Amazon Photo (A-Photo) [24]。 Cora、CiteSeer
和 PubMed 是论文引用网络，而 A-Computers 和 A-Photo
是产品共同购买网络。使用随机分割和标准分割对这些数据集进行实验。随机分割遵循[25,
36]随机标记特定比例的节点作为训练集，标记率如表1所示；标准分割遵循 [16,
26]，使用每类 20 个标记节点作为训练集。在每个数据集中，我们按照 [26, 34]
使用 500 个节点进行验证，使用 1000 个节点进行测试。</p>
<p>我们使用六种流行的 GNN 作为主干模型，即 GCN [16]、GraphSAGE [10]、GAT
[26]、SuperGAT [15]、JK-Net [37] 和 GCNII [3]，它们代表了广泛的范围GNN
的数量。更详细地说，GCN 是典型的基于卷积的 GNN，GraphSAGE
可以应用于归纳学习，GAT 和 SuperGAT 在邻域聚合中使用注意力机制，而
JK-Net 和 GCNII 是深度 GNN。我们使用没有课程学习的骨干 GNN
作为基线来探索 CLNode 所取得的改进。所有模型均在 PyTorch-geometric [8]
中实现。我们使用 Adam 优化器，学习率为 0.01，权重衰减为 <span
class="math inline">\(5 \times
10^{−4}\)</span>。论文引用网络中的隐藏单元固定为
16，产品共同购买网络中的隐藏单元固定为 64。我们为 GCN、GAT、GraphSage 和
SuperGAT 应用两个图卷积层，为 JK-Net 应用 6 层，为 GCNII 应用 64
层。为了便于公平比较，CLNode 的骨干 GNN 参数与基线相同。对于
CLNode，<span class="math inline">\(\alpha\)</span> 固定为
1，因为我们在该值下观察到良好的性能。我们默认使用 geometric
步调函数。超参数 <span class="math inline">\(\lambda_0\)</span> 在
{0.25,0.5,0.75} 范围内搜索，而 <span class="math inline">\(T\)</span>
的搜索空间为 {50,100,150}。代码可在 https://github.com/wxwmd/CLNode
获取。</p>
<h3 id="node-classification">Node Classification</h3>
<p>在本小节中，在五个数据集上进行节点分类实验。对于每个基线
GNN，我们将其原始精度与插入 CLNode
框架的精度进行比较。我们对每个实验进行十次试验，以报告平均测试精度和标准偏差。</p>
<p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322102804876.png" alt="image-20240322102804876" style="zoom:80%;" /></p>
<p>表 2 报告了随机分割下的实验结果。结果表明，CLNode 可以与六个骨干 GNN
结合，并提高其节点分类的准确性。例如，在 Cora 数据集上，CLNode 将主干
GNN 的测试精度提高了 3.5% (GCN)、2.0% (GraphSAGE)、2.9% (GAT)、1.1%
(SuperGAT)、2.8% (JK-Net) 和1.6%（GCNII）。结果证明，CLNode
有效减轻了困难节点的不利影响，从而能够从质量参差不齐的训练节点中学到更多有用的信息。</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322102841344.png"
alt="image-20240322102841344" />
<figcaption aria-hidden="true">image-20240322102841344</figcaption>
</figure>
<p>此外，我们在不同标签率下进行节点分类实验。表 3 显示了 Cora
数据集在标签率分别为 1%、2%、3%
时的准确率。我们观察到，当标记训练节点较少时，CLNode
取得的改进更加明显。这是因为当训练节点较多时，困难节点的不利影响会被大量简单节点所减轻；相反，当训练节点较少时，困难节点很容易误导
GNN 学习错误的知识。因此，通过从初始训练中排除困难节点，CLNode
在低标签率下显着提高了 GNN
的准确性。对于许多现实世界的图来说，标记过程既繁琐又昂贵，导致标签有限，在这些情况下使用
CLNode 将非常有益。</p>
<h3 id="robustness-to-noise">Robustness to Noise</h3>
<p>在本小节中，我们研究 CLNode 是否增强了主干 GNN
标记噪声的鲁棒性。在噪声标记图中，标签有概率 <span
class="math inline">\(p\)</span> 翻转到其他类，其中 <span
class="math inline">\(p\)</span> 表示噪声率。按照[5,
18]，我们用两种标签噪声破坏了训练集和验证集的标签：</p>
<ul>
<li>均匀的噪音。该标签被错误标记为任何其他类别的概率为 <span
class="math inline">\(p\)</span>。</li>
<li>对噪声。我们假设一类中的节点只能被错误标记为其最接近的类；也就是说，标签有概率
<span class="math inline">\(p\)</span> 翻转到它们的配对类别。</li>
</ul>
<p>我们在标准分割下对 Cora 进行实验，并将 <span
class="math inline">\(p\)</span> 从 {0, 5%,..., 30%} 变化，以比较 CLNode
和基线 GNN 在不同噪声水平下的性能。我们只报告使用 GCN 和 GAT 作为主干
GNN 的结果，因为我们对其他 GNN 也有类似的观察结果。 CLNode(GCN) 和
CLNode(GAT) 分别表示使用 GCN 和 GAT 作为骨干 GNN 的 CLNode 方法。</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322102256737.png"
alt="image-20240322102256737" />
<figcaption aria-hidden="true">image-20240322102256737</figcaption>
</figure>
<p>结果如图 6
所示，从中我们观察到，随着噪声率的增加，所有基线的性能都急剧下降。
CLNode
在噪声率增加的情况下也会受到影响；然而，当图中的噪声较多时，CLNode
与基线之间的性能差距就会增大。这一观察结果表明，CLNode 有效增强了主干
GNN 对两种标签噪声的鲁棒性，因为 CLNode
将错误标记的训练节点视为困难节点，并有选择地将它们排除在训练过程之外，而基线
GNN 将所有训练节点视为平等，从而导致过拟合噪音。</p>
<h3 id="ablation-study">Ablation Study</h3>
<p>在本小节中，我们进行消融研究，以探索多视角难度测量器的有效性以及
CLNode
对不同起搏功能的敏感性。消融研究是在标准分割下对三个论文引文数据集进行的，其中图形被均匀标签噪声破坏，噪声率
<span class="math inline">\(p\)</span> 设置为 30%。</p>
<p>首先，为了验证多视角难度测量器从结合局部和全局信息中获益，我们设计了两个难度测量器来代替它：</p>
<ul>
<li>仅使用本地信息来测量难度，即我们仅使用 Dlocal 来测量节点难度。</li>
<li>仅使用全局信息来衡量难度，即我们仅使用 Dglobal 来衡量节点难度。</li>
</ul>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322104824085.png"
alt="image-20240322104824085" />
<figcaption aria-hidden="true">image-20240322104824085</figcaption>
</figure>
<p>我们使用这两个难度测量器进行消融研究；在下面，我们将消融方法分别称为
CLNode(local) 和 CLNode(global)。使用 GCN 作为基线方法。结果如表 4
所示，从中我们观察到以下情况：（1）CLNode（local）和
CLNode（global）都优于基线方法，这表明它们从不同的角度衡量节点难度，从而减轻了不利的影响。不同类型困难节点的影响；
（2）CLNode
在所有实验中都取得了最好的结果，证明通过结合局部和全局视角来衡量节点难度，CLNode
有效地识别了两类困难节点，从而增强了骨干GNN的准确性和鲁棒性。</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedimage-20240322104834018.png"
alt="image-20240322104834018" />
<figcaption aria-hidden="true">image-20240322104834018</figcaption>
</figure>
<p>在表 5 中，我们评估了 CLNode 对三种调步函数的敏感性：linear、root 和
geometric。我们发现 geometric 起步函数在所有数据集上都有轻微的优势。如图
5 所示，几何函数在引入困难节点之前在简单节点的子集上训练更多的
epoch。因此，为了减轻困难节点的不利影响，我们认为在引入更困难的节点之前，应该充分探索简单节点中的高置信度知识。</p>
<h3 id="parameter-sensitivity-analysis">Parameter Sensitivity
Analysis</h3>
<p>最后但并非最不重要的一点是，我们研究了超参数 <span
class="math inline">\(\lambda_0\)</span> 和 <span
class="math inline">\(T\)</span> 如何影响 CLNode 的性能。 <span
class="math inline">\(\lambda_0\)</span> 控制训练节点的初始数量，而
<span class="math inline">\(T\)</span>
控制将困难节点引入训练过程的速度。为了探索参数敏感性，我们分别将 <span
class="math inline">\(\lambda_0\)</span> 和 <span
class="math inline">\(T\)</span> 从 {0.1, 0.2,..., 0.9} 和 {20, 40,...,
200} 更改。我们使用 GCN 作为主干 GNN，并在随机分割下在 Cora
上报告结果。图 7 的结果表明： (1) 一般来说，随着 <span
class="math inline">\(\lambda_0\)</span>
的增大，性能呈现先增大后减小的趋势；具体来说，当 <span
class="math inline">\(\lambda_0\)</span>
在0.3到0.7之间时，性能相对较好。 <span
class="math inline">\(\lambda_0\)</span>
太小会导致初始训练过程中训练节点较少，导致模型无法高效学习。相反，过大的
<span class="math inline">\(\lambda_0\)</span>
会在初始训练期间引入困难节点，从而降低准确性。 (2) 同样，随着 <span
class="math inline">\(T\)</span>
的增大，测试精度也呈现先增大后减小的趋势。太小的 <span
class="math inline">\(T\)</span> 会很快引入更多困难的节点，从而降低主干
GNN 的性能；相反，极大的 <span class="math inline">\(T\)</span>
会导致主干GNN主要在简单子集上进行训练，从而导致困难节点中包含的信息丢失。</p>
<h2 id="conclusion">Conclusion</h2>
<p>在本文中，我们研究了在质量不均匀的训练节点上训练 GNN 的问题。当前的
GNN
假设所有训练节点在训练过程中贡献均等；因此，困难节点会降低其准确性和鲁棒性。为了解决这些问题，我们提出了一种新颖的框架
CLNode
来减轻困难节点的有害影响。具体来说，我们设计了一个多视角难度测量器，利用本地和全局信息准确测量节点难度。基于这些测量，提出了一种连续训练调度程序，将节点提供给从简单到困难的课程中的训练进度。对五个基准数据集的大量实验表明，CLNode
是一个通用框架，可以与六个代表性骨干 GNN
结合以提高其准确性。在噪声标记图上进行了进一步的实验，以证明 CLNode
增强了主干 GNN
的鲁棒性。扩展当前工作的一个有趣的未来方向是探索课程学习在更多与图相关的任务中的应用，例如链接预测。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Deep-Learning/" class="category-chain-item">Deep Learning</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Deep-Learning/" class="print-no-link">#Deep Learning</a>
      
        <a href="/tags/Curriculum-Learning/" class="print-no-link">#Curriculum Learning</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>2024 论文砖 CLNode Curriculum Learning for Node Classification(2023)</div>
      <div>https://blog.lfd.world/2024/03/20/lun-wen-ri-ji-2024-clnode-curriculum-learning-for-node-classification-2023/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>培根请加蛋</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年3月20日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/03/20/2024-science-research-writing-a-guide-for-non-native-speakers-of-english-introduction/" title="Science Research Writing A Guide for Non-Native Speakers of English--Introduction">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Science Research Writing A Guide for Non-Native Speakers of English--Introduction</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/03/20/lun-wen-ri-ji-2024-dropedge-towards-deep-graph-convolutional-networks-on-node-classification/" title="论文日记 2024 Dropedge-Towards Deep Graph Convolutional Networks on Node Classification (2020)">
                        <span class="hidden-mobile">论文日记 2024 Dropedge-Towards Deep Graph Convolutional Networks on Node Classification (2020)</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>







  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
