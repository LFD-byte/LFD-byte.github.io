<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="WandB 学习日记（一）Doc, 培根请加蛋">
    <meta name="description" content="WandB 学习日记（一）Doc">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google-site-verification" content="qvBHqgbyc_CYw3ZE9lrEIxYSUzkcL8LH9-_uDtcme5A" />
    <meta name="baidu-site-verification" content="codeva-mJZ2sqHuqv" />
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>WandB 学习日记（一）Doc | 培根请加蛋</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    


    
    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 5.4.2">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="培根请加蛋" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">培根请加蛋</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">培根请加蛋</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/LFD-byte" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/LFD-byte" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/18.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">WandB 学习日记（一）Doc</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/WandB/">
                                <span class="chip bg-color">WandB</span>
                            </a>
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/WandB/" class="post-category">
                                WandB
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-06-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2023-06-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    24 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="Track-experiments"><a href="#Track-experiments" class="headerlink" title="Track experiments"></a>Track experiments</h2><p>快速实验是机器学习的基础。在本教程中，我们使用 W&amp;B 来跟踪和可视化实验，以便我们可以快速迭代和理解我们的结果。</p>
<h3 id="A-shared-dashboard-for-your-experiments"><a href="#A-shared-dashboard-for-your-experiments" class="headerlink" title="A shared dashboard for your experiments"></a>A shared dashboard for your experiments</h3><p>只需几行代码，您就可以获得丰富的、交互式的、可共享的仪表板，您可以在这里看到<a target="_blank" rel="noopener" href="https://wandb.ai/wandb/wandb_example?_gl=1*1ycseye*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MDE0OC41MC4wLjA.">自己的 dashboard </a>。</p>
<p><img src="https://i.imgur.com/Pell4Oo.png" alt="img"></p>
<h3 id="Data-amp-Privacy"><a href="#Data-amp-Privacy" class="headerlink" title="Data &amp; Privacy"></a>Data &amp; Privacy</h3><p>我们非常重视安全性，我们的云托管 dashboard 使用行业标准最佳加密实践。如果您正在使用无法离开企业集群的数据集，我们可以提供<a target="_blank" rel="noopener" href="https://docs.wandb.com/self-hosted">本地安装</a>。</p>
<p>下载所有数据并将其导出到其他工具也很容易——例如在 Jupyter 笔记本中进行自定义分析。下面是关于我们 <a target="_blank" rel="noopener" href="https://docs.wandb.com/library/api">API</a> 的更多信息。</p>
<h3 id="Install-wandb-library-and-login"><a href="#Install-wandb-library-and-login" class="headerlink" title="Install wandb library and login"></a>Install <code>wandb</code> library and login</h3><p>首先安装库并登录到您的免费帐户。</p>
<pre class=" language-bash"><code class="language-bash"><span class="token operator">!</span>pip <span class="token function">install</span> wandb -qU
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Log in to your W&amp;B account</span>
<span class="token keyword">import</span> wandb
wandb<span class="token punctuation">.</span>login<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="Run-an-experiment"><a href="#Run-an-experiment" class="headerlink" title="Run an experiment"></a>Run an experiment</h3><p>1️⃣. 开始新的运行并传入超参数进行跟踪</p>
<p>2️⃣. 训练或评估的日志指标</p>
<p>3️⃣. 在 dashboard 中可视化结果</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> random

<span class="token comment" spellcheck="true"># Launch 5 simulated experiments</span>
total_runs <span class="token operator">=</span> <span class="token number">5</span>
<span class="token keyword">for</span> run <span class="token keyword">in</span> range<span class="token punctuation">(</span>total_runs<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment" spellcheck="true"># 🐝 1️⃣ Start a new run to track this script</span>
  wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>
      <span class="token comment" spellcheck="true"># Set the project where this run will be logged</span>
      project<span class="token operator">=</span><span class="token string">"basic-intro"</span><span class="token punctuation">,</span> 
      <span class="token comment" spellcheck="true"># We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)</span>
      name<span class="token operator">=</span>f<span class="token string">"experiment_{run}"</span><span class="token punctuation">,</span> 
      <span class="token comment" spellcheck="true"># Track hyperparameters and run metadata</span>
      config<span class="token operator">=</span><span class="token punctuation">{</span>
      <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token number">0.02</span><span class="token punctuation">,</span>
      <span class="token string">"architecture"</span><span class="token punctuation">:</span> <span class="token string">"CNN"</span><span class="token punctuation">,</span>
      <span class="token string">"dataset"</span><span class="token punctuation">:</span> <span class="token string">"CIFAR-100"</span><span class="token punctuation">,</span>
      <span class="token string">"epochs"</span><span class="token punctuation">:</span> <span class="token number">10</span><span class="token punctuation">,</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
  
  <span class="token comment" spellcheck="true"># This simple block simulates a training loop logging metrics</span>
  epochs <span class="token operator">=</span> <span class="token number">10</span>
  offset <span class="token operator">=</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">5</span>
  <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
      acc <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> <span class="token number">2</span> <span class="token operator">**</span> <span class="token operator">-</span>epoch <span class="token operator">-</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> epoch <span class="token operator">-</span> offset
      loss <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">**</span> <span class="token operator">-</span>epoch <span class="token operator">+</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> epoch <span class="token operator">+</span> offset
      
      <span class="token comment" spellcheck="true"># 🐝 2️⃣ Log metrics from your script to W&amp;B</span>
      wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"acc"</span><span class="token punctuation">:</span> acc<span class="token punctuation">,</span> <span class="token string">"loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">}</span><span class="token punctuation">)</span>
      
  <span class="token comment" spellcheck="true"># Mark the run as finished</span>
  wandb<span class="token punctuation">.</span>finish<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>3️⃣ 当您运行此代码时，您可以通过单击上面的任何 👆 wandb 链接找到您的交互式 dashboard。</p>
<h3 id="Simple-Pytorch-Neural-Network"><a href="#Simple-Pytorch-Neural-Network" class="headerlink" title="Simple Pytorch Neural Network"></a>Simple Pytorch Neural Network</h3><p>运行此模型以训练一个简单的 MNIST 分类器，然后单击项目页面链接以实时查看您的结果流到 W&amp;B 项目。</p>
<p>wandb 中的任何运行都会自动记录 <a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#charts-tab">metrics</a>, <a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#system-tab">system information</a>, <a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#overview-tab">hyperparameters</a>, <a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#logs-tab">terminal output</a> ，您将看到一个包含模型输入和输出的交互式表格。</p>
<h4 id="Set-up-Dataloader"><a href="#Set-up-Dataloader" class="headerlink" title="Set up Dataloader"></a>Set up Dataloader</h4><p>要运行此示例，我们需要安装 PyTorch。如果您使用的是 Google Colab，则它已经预装。</p>
<pre class=" language-bash"><code class="language-bash"><span class="token operator">!</span>pip <span class="token function">install</span> torch torchvision
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> wandb
<span class="token keyword">import</span> math
<span class="token keyword">import</span> random
<span class="token keyword">import</span> torch<span class="token punctuation">,</span> torchvision
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T

device <span class="token operator">=</span> <span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>

<span class="token keyword">def</span> <span class="token function">get_dataloader</span><span class="token punctuation">(</span>is_train<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> slice<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Get a training dataloader"</span>
    full_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">,</span> train<span class="token operator">=</span>is_train<span class="token punctuation">,</span> transform<span class="token operator">=</span>T<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    sub_dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Subset<span class="token punctuation">(</span>full_dataset<span class="token punctuation">,</span> indices<span class="token operator">=</span>range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>full_dataset<span class="token punctuation">)</span><span class="token punctuation">,</span> slice<span class="token punctuation">)</span><span class="token punctuation">)</span>
    loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>sub_dataset<span class="token punctuation">,</span> 
                                         batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> 
                                         shuffle<span class="token operator">=</span><span class="token boolean">True</span> <span class="token keyword">if</span> is_train <span class="token keyword">else</span> <span class="token boolean">False</span><span class="token punctuation">,</span> 
                                         pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> loader

<span class="token keyword">def</span> <span class="token function">get_model</span><span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"A simple model"</span>
    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                         nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                         nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                         nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                         nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">,</span>
                         nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">return</span> model

<span class="token keyword">def</span> <span class="token function">validate_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> valid_dl<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> log_images<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> batch_idx<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Compute performance of the model on the validation dataset and log a wandb.Table"</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    val_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">.</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        correct <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>valid_dl<span class="token punctuation">)</span><span class="token punctuation">:</span>
            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Forward pass ➡</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            val_loss <span class="token operator">+=</span> loss_func<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token operator">*</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Compute accuracy and accumulate</span>
            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Log one batch of images to the dashboard, always same batch_idx.</span>
            <span class="token keyword">if</span> i<span class="token operator">==</span>batch_idx <span class="token operator">and</span> log_images<span class="token punctuation">:</span>
                log_image_table<span class="token punctuation">(</span>images<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> outputs<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> val_loss <span class="token operator">/</span> len<span class="token punctuation">(</span>valid_dl<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span> correct <span class="token operator">/</span> len<span class="token punctuation">(</span>valid_dl<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">log_image_table</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> probs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Log a wandb.Table with (img, pred, target, scores)"</span>
    <span class="token comment" spellcheck="true"># 🐝 Create a wandb Table to log images, labels and predictions to</span>
    table <span class="token operator">=</span> wandb<span class="token punctuation">.</span>Table<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">,</span> <span class="token string">"pred"</span><span class="token punctuation">,</span> <span class="token string">"target"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token punctuation">[</span>f<span class="token string">"score_{i}"</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> img<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> targ<span class="token punctuation">,</span> prob <span class="token keyword">in</span> zip<span class="token punctuation">(</span>images<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> predicted<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> probs<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        table<span class="token punctuation">.</span>add_data<span class="token punctuation">(</span>wandb<span class="token punctuation">.</span>Image<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">,</span> pred<span class="token punctuation">,</span> targ<span class="token punctuation">,</span> <span class="token operator">*</span>prob<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"predictions_table"</span><span class="token punctuation">:</span>table<span class="token punctuation">}</span><span class="token punctuation">,</span> commit<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="Train-Your-Model"><a href="#Train-Your-Model" class="headerlink" title="Train Your Model"></a>Train Your Model</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Launch 5 experiments, trying different dropout rates</span>
<span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 🐝 initialise a wandb run</span>
    wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>
        project<span class="token operator">=</span><span class="token string">"pytorch-intro"</span><span class="token punctuation">,</span>
        config<span class="token operator">=</span><span class="token punctuation">{</span>
            <span class="token string">"epochs"</span><span class="token punctuation">:</span> <span class="token number">10</span><span class="token punctuation">,</span>
            <span class="token string">"batch_size"</span><span class="token punctuation">:</span> <span class="token number">128</span><span class="token punctuation">,</span>
            <span class="token string">"lr"</span><span class="token punctuation">:</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span>
            <span class="token string">"dropout"</span><span class="token punctuation">:</span> random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.80</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Copy your config </span>
    config <span class="token operator">=</span> wandb<span class="token punctuation">.</span>config

    <span class="token comment" spellcheck="true"># Get the data</span>
    train_dl <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>is_train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
    valid_dl <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>is_train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token operator">*</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
    n_steps_per_epoch <span class="token operator">=</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_dl<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span> <span class="token operator">/</span> config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># A simple MLP model</span>
    model <span class="token operator">=</span> get_model<span class="token punctuation">(</span>config<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Make the loss and optimizer</span>
    loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">.</span>lr<span class="token punctuation">)</span>

   <span class="token comment" spellcheck="true"># Training</span>
    example_ct <span class="token operator">=</span> <span class="token number">0</span>
    step_ct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>config<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_dl<span class="token punctuation">)</span><span class="token punctuation">:</span>
            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            train_loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
            example_ct <span class="token operator">+=</span> len<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"train/train_loss"</span><span class="token punctuation">:</span> train_loss<span class="token punctuation">,</span> 
                       <span class="token string">"train/epoch"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>step <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>n_steps_per_epoch <span class="token operator">*</span> epoch<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> n_steps_per_epoch<span class="token punctuation">,</span> 
                       <span class="token string">"train/example_ct"</span><span class="token punctuation">:</span> example_ct<span class="token punctuation">}</span>
            
            <span class="token keyword">if</span> step <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">&lt;</span> n_steps_per_epoch<span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 🐝 Log train metrics to wandb </span>
                wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span>metrics<span class="token punctuation">)</span>
                
            step_ct <span class="token operator">+=</span> <span class="token number">1</span>

        val_loss<span class="token punctuation">,</span> accuracy <span class="token operator">=</span> validate_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> valid_dl<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> log_images<span class="token operator">=</span><span class="token punctuation">(</span>epoch<span class="token operator">==</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>epochs<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 🐝 Log train and validation metrics to wandb</span>
        val_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"val/val_loss"</span><span class="token punctuation">:</span> val_loss<span class="token punctuation">,</span> 
                       <span class="token string">"val/val_accuracy"</span><span class="token punctuation">:</span> accuracy<span class="token punctuation">}</span>
        wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token operator">**</span>metrics<span class="token punctuation">,</span> <span class="token operator">**</span>val_metrics<span class="token punctuation">}</span><span class="token punctuation">)</span>
        
        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># If you had a test set, this is how you could log it as a Summary metric</span>
    wandb<span class="token punctuation">.</span>summary<span class="token punctuation">[</span><span class="token string">'test_accuracy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.8</span>

    <span class="token comment" spellcheck="true"># 🐝 Close your wandb run </span>
    wandb<span class="token punctuation">.</span>finish<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>您现在已经使用 wandb 训练了您的第一个模型！ 👆 单击上面的 wandb 链接查看您的指标</p>
<h3 id="Try-W-amp-B-Alerts"><a href="#Try-W-amp-B-Alerts" class="headerlink" title="Try W&amp;B Alerts"></a>Try W&amp;B Alerts</h3><p><strong><a target="_blank" rel="noopener" href="https://docs.wandb.ai/guides/track/alert">W&amp;B Alerts</a></strong>  允许您将从 Python 代码触发的警报发送到您的 Slack 或电子邮件。第一次发送 Slack 或电子邮件警报时，需要执行 2 个步骤，这些警报由您的代码触发：</p>
<p>1) 在你的 W&amp;B <a target="_blank" rel="noopener" href="https://wandb.ai/settings">User Settings</a> 开启警报</p>
<p>2) 添加 <code>wandb.alert()</code> 到你的代码:</p>
<pre class=" language-python"><code class="language-python">wandb<span class="token punctuation">.</span>alert<span class="token punctuation">(</span>
    title<span class="token operator">=</span><span class="token string">"Low accuracy"</span><span class="token punctuation">,</span> 
    text<span class="token operator">=</span>f<span class="token string">"Accuracy is below the acceptable threshold"</span>
<span class="token punctuation">)</span>
</code></pre>
<p>请参阅下面的最小示例以了解如何使用 wandb.alert，您可以在此处找到 <a target="_blank" rel="noopener" href="https://docs.wandb.ai/guides/track/alert">W&amp;B Alerts</a>的完整文档</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Start a wandb run</span>
wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>project<span class="token operator">=</span><span class="token string">"pytorch-intro"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Simulating a model training loop</span>
acc_threshold <span class="token operator">=</span> <span class="token number">0.3</span>
<span class="token keyword">for</span> training_step <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment" spellcheck="true"># Generate a random number for accuracy</span>
    accuracy <span class="token operator">=</span> round<span class="token punctuation">(</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Accuracy is: {accuracy}, {acc_threshold}'</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># 🐝 Log accuracy to wandb</span>
    wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"Accuracy"</span><span class="token punctuation">:</span> accuracy<span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 🔔 If the accuracy is below the threshold, fire a W&amp;B Alert and stop the run</span>
    <span class="token keyword">if</span> accuracy <span class="token operator">&lt;=</span> acc_threshold<span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 🐝 Send the wandb Alert</span>
        wandb<span class="token punctuation">.</span>alert<span class="token punctuation">(</span>
            title<span class="token operator">=</span><span class="token string">'Low Accuracy'</span><span class="token punctuation">,</span>
            text<span class="token operator">=</span>f<span class="token string">'Accuracy {accuracy} at step {training_step} is below the acceptable theshold, {acc_threshold}'</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Alert triggered'</span><span class="token punctuation">)</span>
        <span class="token keyword">break</span>

<span class="token comment" spellcheck="true"># Mark the run as finished (useful in Jupyter notebooks)</span>
wandb<span class="token punctuation">.</span>finish<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="Visualize-predictions"><a href="#Visualize-predictions" class="headerlink" title="Visualize predictions"></a>Visualize predictions</h2><p>这包括如何在训练过程中使用 PyTorch 对 MNIST 数据进行跟踪、可视化和比较模型预测。</p>
<p>你将学到如何：</p>
<ol>
<li>在模型训练或评估期间将指标、图像、文本等记录到 <code>wandb.Table()</code></li>
<li>查看、排序、筛选、分组、加入、交互式查询和探索这些表</li>
<li>比较模型预测或结果：动态地跨越特定图像、超参数/模型版本或时间步长。</li>
</ol>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><h4 id="Compare-predicted-scores-for-specific-images"><a href="#Compare-predicted-scores-for-specific-images" class="headerlink" title="Compare predicted scores for specific images"></a>Compare predicted scores for specific images</h4><p><a target="_blank" rel="noopener" href="https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU?_gl=1*6z1980*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MTg0Ni4zOC4wLjA.#compare-predictions-after-1-vs-5-epochs">实例：比较 1 和 5 个训练周期后的预测</a></p>
<p><img src="https://i.imgur.com/NMme6Qj.png" alt="1 epoch vs 5 epochs of training"></p>
<p>直方图比较了两个模型之间的每类分数。每个直方图中顶部的绿色条代表模型“CNN-2, 1 epoch”（id 0），它只训练了 1 个 epoch。底部的紫色条代表模型“CNN-2, 5 epochs” (id 1)，它训练了 5 个 epochs。图像被过滤到模型不一致的情况。例如，在第一行中，“4”在 1 个时期后在所有可能的数字中获得高分，但在 5 个时期后，它在正确标签上得分最高，而在其余部分得分非常低。</p>
<h4 id="Focus-on-top-errors-over-time"><a href="#Focus-on-top-errors-over-time" class="headerlink" title="Focus on top errors over time"></a>Focus on top errors over time</h4><p><a target="_blank" rel="noopener" href="https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU?_gl=1*1nxbzl7*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MTg0Ni4zOC4wLjA.#top-errors-over-time">实例 →</a></p>
<p>查看完整测试数据的不正确预测（过滤 “guess” != “truth” 的行）。请注意，在 1 个训练时期后有 229 个错误猜测，但在 5 个时期后只有 98 个。</p>
<p><img src="https://i.imgur.com/7g8nodn.png" alt="side by side, 1 vs 5 epochs of training"></p>
<h4 id="Compare-model-performance-and-find-patterns"><a href="#Compare-model-performance-and-find-patterns" class="headerlink" title="Compare model performance and find patterns"></a>Compare model performance and find patterns</h4><p><a target="_blank" rel="noopener" href="https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU?_gl=1*8r828v*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MTg0Ni4zOC4wLjA.#false-positives-grouped-by-guess">查看实例中的完整详细信息 →</a></p>
<p>过滤出正确答案，然后按猜测分组，以查看错误分类图像的示例和真实标签的基本分布——并排显示两个模型。具有 2X layer sizes 和学习率的模型变体在左侧，基线在右侧。请注意，对于每个猜测的类，基线都会犯更多的错误。</p>
<p><img src="https://i.imgur.com/i5PP9AE.png" alt="grouped errors for baseline vs double variant"></p>
<h3 id="Sign-up-or-login"><a href="#Sign-up-or-login" class="headerlink" title="Sign up or login"></a>Sign up or login</h3><p><a target="_blank" rel="noopener" href="https://wandb.ai/login">Sign up or login</a> W&amp;B 以在浏览器中查看您的实验并与之互动。</p>
<p>在此示例中，我们使用 Google Colab 作为方便的托管环境，但您可以从任何地方运行自己的训练脚本，并使用 W&amp;B 的实验跟踪工具可视化指标。</p>
<pre class=" language-bash"><code class="language-bash"><span class="token operator">!</span>pip <span class="token function">install</span> wandb -qqq
</code></pre>
<p>登录您的帐户</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> wandb
wandb<span class="token punctuation">.</span>login<span class="token punctuation">(</span><span class="token punctuation">)</span>

WANDB_PROJECT <span class="token operator">=</span> <span class="token string">"mnist-viz"</span>
</code></pre>
<h3 id="0-Setup"><a href="#0-Setup" class="headerlink" title="0. Setup"></a>0. Setup</h3><p>安装依赖项，下载 MNIST，并使用 PyTorch 创建训练和测试数据集。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T 
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F


device <span class="token operator">=</span> <span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>

<span class="token comment" spellcheck="true"># create train and test dataloaders</span>
<span class="token keyword">def</span> <span class="token function">get_dataloader</span><span class="token punctuation">(</span>is_train<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> slice<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Get a training dataloader"</span>
    ds <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">,</span> train<span class="token operator">=</span>is_train<span class="token punctuation">,</span> transform<span class="token operator">=</span>T<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>ds<span class="token punctuation">,</span> 
                                         batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> 
                                         shuffle<span class="token operator">=</span><span class="token boolean">True</span> <span class="token keyword">if</span> is_train <span class="token keyword">else</span> <span class="token boolean">False</span><span class="token punctuation">,</span> 
                                         pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> loader
</code></pre>
<h3 id="1-Define-the-model-and-training-schedule"><a href="#1-Define-the-model-and-training-schedule" class="headerlink" title="1. Define the model and training schedule"></a>1. Define the model and training schedule</h3><ul>
<li>设置要运行的纪元数，其中每个纪元包含一个训练步骤和一个验证（测试）步骤。 （可选）配置每个测试步骤要记录的数据量。这里要可视化的批次数和每批次的图像数设置得较低，以简化演示。</li>
<li>定义一个简单的卷积神经网络（遵循 <a target="_blank" rel="noopener" href="https://github.com/yunjey/pytorch-tutorial">pytorch-tutorial</a> 代码）。</li>
<li>使用 PyTorch 加载训练集和测试集</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Number of epochs to run</span>
<span class="token comment" spellcheck="true"># Each epoch includes a training step and a test step, so this sets</span>
<span class="token comment" spellcheck="true"># the number of tables of test predictions to log</span>
EPOCHS <span class="token operator">=</span> <span class="token number">1</span>

<span class="token comment" spellcheck="true"># Number of batches to log from the test data for each test step</span>
<span class="token comment" spellcheck="true"># (default set low to simplify demo)</span>
NUM_BATCHES_TO_LOG <span class="token operator">=</span> <span class="token number">10</span> <span class="token comment" spellcheck="true">#79</span>

<span class="token comment" spellcheck="true"># Number of images to log per test batch</span>
<span class="token comment" spellcheck="true"># (default set low to simplify demo)</span>
NUM_IMAGES_PER_BATCH <span class="token operator">=</span> <span class="token number">32</span> <span class="token comment" spellcheck="true">#128</span>

<span class="token comment" spellcheck="true"># training configuration and hyperparameters</span>
NUM_CLASSES <span class="token operator">=</span> <span class="token number">10</span>
BATCH_SIZE <span class="token operator">=</span> <span class="token number">32</span>
LEARNING_RATE <span class="token operator">=</span> <span class="token number">0.001</span>
L1_SIZE <span class="token operator">=</span> <span class="token number">32</span>
L2_SIZE <span class="token operator">=</span> <span class="token number">64</span>
<span class="token comment" spellcheck="true"># changing this may require changing the shape of adjacent layers</span>
CONV_KERNEL_SIZE <span class="token operator">=</span> <span class="token number">5</span>

<span class="token comment" spellcheck="true"># define a two-layer convolutional neural network</span>
<span class="token keyword">class</span> <span class="token class-name">ConvNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>ConvNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L1_SIZE<span class="token punctuation">,</span> CONV_KERNEL_SIZE<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>L1_SIZE<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>L1_SIZE<span class="token punctuation">,</span> L2_SIZE<span class="token punctuation">,</span> CONV_KERNEL_SIZE<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>L2_SIZE<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span>L2_SIZE<span class="token punctuation">,</span> NUM_CLASSES<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span>NUM_CLASSES<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># uncomment to see the shape of a given layer:</span>
        <span class="token comment" spellcheck="true">#print("x: ", x.size())</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out

train_loader <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>is_train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>is_train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token operator">*</span>BATCH_SIZE<span class="token punctuation">)</span>

device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="2-Run-training-and-log-test-predictions"><a href="#2-Run-training-and-log-test-predictions" class="headerlink" title="2. Run training and log test predictions"></a>2. Run training and log test predictions</h3><p>对于每个时期，运行一个训练步骤和一个测试步骤。对于每个测试步骤，创建一个 wandb.Table() 来存储测试预测。这些可以在您的浏览器中进行可视化、动态查询和并排比较。</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ✨ W&amp;B: Initialize a new run to track this model's training</span>
wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>project<span class="token operator">=</span><span class="token string">"table-quickstart"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># ✨ W&amp;B: Log hyperparameters using config</span>
cfg <span class="token operator">=</span> wandb<span class="token punctuation">.</span>config
cfg<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"epochs"</span> <span class="token punctuation">:</span> EPOCHS<span class="token punctuation">,</span> <span class="token string">"batch_size"</span><span class="token punctuation">:</span> BATCH_SIZE<span class="token punctuation">,</span> <span class="token string">"lr"</span> <span class="token punctuation">:</span> LEARNING_RATE<span class="token punctuation">,</span>
            <span class="token string">"l1_size"</span> <span class="token punctuation">:</span> L1_SIZE<span class="token punctuation">,</span> <span class="token string">"l2_size"</span><span class="token punctuation">:</span> L2_SIZE<span class="token punctuation">,</span>
            <span class="token string">"conv_kernel"</span> <span class="token punctuation">:</span> CONV_KERNEL_SIZE<span class="token punctuation">,</span>
            <span class="token string">"img_count"</span> <span class="token punctuation">:</span> min<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> NUM_IMAGES_PER_BATCH<span class="token operator">*</span>NUM_BATCHES_TO_LOG<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># define model, loss, and optimizer</span>
model <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span>NUM_CLASSES<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LEARNING_RATE<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># convenience funtion to log predictions for a batch of test images</span>
<span class="token keyword">def</span> <span class="token function">log_test_predictions</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> test_table<span class="token punctuation">,</span> log_counter<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment" spellcheck="true"># obtain confidence scores for all classes</span>
  scores <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
  log_scores <span class="token operator">=</span> scores<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  log_images <span class="token operator">=</span> images<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  log_labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  log_preds <span class="token operator">=</span> predicted<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token comment" spellcheck="true"># adding ids based on the order of the images</span>
  _id <span class="token operator">=</span> <span class="token number">0</span>
  <span class="token keyword">for</span> i<span class="token punctuation">,</span> l<span class="token punctuation">,</span> p<span class="token punctuation">,</span> s <span class="token keyword">in</span> zip<span class="token punctuation">(</span>log_images<span class="token punctuation">,</span> log_labels<span class="token punctuation">,</span> log_preds<span class="token punctuation">,</span> log_scores<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># add required info to data table:</span>
    <span class="token comment" spellcheck="true"># id, image pixels, model's guess, true label, scores for all classes</span>
    img_id <span class="token operator">=</span> str<span class="token punctuation">(</span>_id<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>log_counter<span class="token punctuation">)</span>
    test_table<span class="token punctuation">.</span>add_data<span class="token punctuation">(</span>img_id<span class="token punctuation">,</span> wandb<span class="token punctuation">.</span>Image<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> p<span class="token punctuation">,</span> l<span class="token punctuation">,</span> <span class="token operator">*</span>s<span class="token punctuation">)</span>
    _id <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">if</span> _id <span class="token operator">==</span> NUM_IMAGES_PER_BATCH<span class="token punctuation">:</span>
      <span class="token keyword">break</span>

<span class="token comment" spellcheck="true"># train the model</span>
total_step <span class="token operator">=</span> len<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>EPOCHS<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># training step</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># forward pass</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># backward and optimize</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
  
        <span class="token comment" spellcheck="true"># ✨ W&amp;B: Log loss over training steps, visualized in the UI live</span>
        wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"loss"</span> <span class="token punctuation">:</span> loss<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'</span>
                <span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> EPOCHS<span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> total_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            

    <span class="token comment" spellcheck="true"># ✨ W&amp;B: Create a Table to store predictions for each test step</span>
    columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">,</span> <span class="token string">"image"</span><span class="token punctuation">,</span> <span class="token string">"guess"</span><span class="token punctuation">,</span> <span class="token string">"truth"</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> digit <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      columns<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">"score_"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>digit<span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_table <span class="token operator">=</span> wandb<span class="token punctuation">.</span>Table<span class="token punctuation">(</span>columns<span class="token operator">=</span>columns<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># test the model</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    log_counter <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        correct <span class="token operator">=</span> <span class="token number">0</span>
        total <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> log_counter <span class="token operator">&lt;</span> NUM_BATCHES_TO_LOG<span class="token punctuation">:</span>
              log_test_predictions<span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> test_table<span class="token punctuation">,</span> log_counter<span class="token punctuation">)</span>
              log_counter <span class="token operator">+=</span> <span class="token number">1</span>
            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        acc <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total
        <span class="token comment" spellcheck="true"># ✨ W&amp;B: Log accuracy across training epochs, to visualize in the UI</span>
        wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"epoch"</span> <span class="token punctuation">:</span> epoch<span class="token punctuation">,</span> <span class="token string">"acc"</span> <span class="token punctuation">:</span> acc<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test Accuracy of the model on the 10000 test images: {} %'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>acc<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># ✨ W&amp;B: Log predictions table to wandb</span>
    wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"test_predictions"</span> <span class="token punctuation">:</span> test_table<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># ✨ W&amp;B: Mark the run as complete (useful for multi-cell notebook)</span>
wandb<span class="token punctuation">.</span>finish<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="Tune-hyperparameters"><a href="#Tune-hyperparameters" class="headerlink" title="Tune hyperparameters"></a>Tune hyperparameters</h2><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W&amp;B.ipynb">在此处试用 Colab Notebook →</a></p>
<p>在高维超参数空间中搜索以找到性能最高的模型可能会很快变得笨拙。超参数扫描提供了一种有组织且高效的方式来进行模型大逃杀并选择最准确的模型。他们通过自动搜索超参数值的组合（例如 learning rate, batch size, number of hidden layers, optimizer type）来找到最佳值来实现这一点。</p>
<p>在本教程中，我们将了解如何使用 Weights &amp; Biases 通过 3 个简单步骤运行复杂的超参数扫描。</p>
<h3 id="Follow-along-with-a-video-tutorial"><a href="#Follow-along-with-a-video-tutorial" class="headerlink" title="Follow along with a video tutorial!"></a>Follow along with a <a target="_blank" rel="noopener" href="http://wandb.me/sweeps-video">video tutorial</a>!</h3><p><img src="https://i.imgur.com/WVKkMWw.png" alt="img"></p>
<h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h3><p>首先安装实验跟踪库并设置您的免费 W&amp;B 帐户：</p>
<ol>
<li>使用 <code>pip install</code> 安装</li>
<li><code>import</code> Python 所需依赖</li>
<li><code>.login()</code> 这样您就可以将指标记录到您的项目中</li>
</ol>
<p>如果您以前从未使用过 Weights &amp; Biases，登录电话会给您一个注册帐户的链接。 W&amp;B 可免费用于个人和学术项目！</p>
<pre class=" language-bash"><code class="language-bash"><span class="token operator">!</span>pip <span class="token function">install</span> wandb -Uq
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> wandb

wandb<span class="token punctuation">.</span>login<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="Step-1️⃣-Define-the-Sweep"><a href="#Step-1️⃣-Define-the-Sweep" class="headerlink" title="Step 1️⃣. Define the Sweep"></a>Step 1️⃣. Define the Sweep</h3><p>从根本上说，Sweep 将尝试一堆超参数值的策略与评估它们的代码结合在一起。您只需要以<a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/configuration">配置</a>的形式定义您的策略。</p>
<p>当您像这样在笔记本中设置 Sweep 时，该配置对象是一个嵌套字典。当您通过命令行运行 Sweep 时，配置对象是一个 <a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/quickstart#2-sweep-config">YAML file</a>。</p>
<p>让我们一起了解 Sweep 配置的定义。我们会慢慢来，这样我们就有机会解释每个组件。在典型的 Sweep 管道中，此步骤将在单个分配中完成。</p>
<h4 id="Pick-a-method"><a href="#Pick-a-method" class="headerlink" title="Pick a method"></a>Pick a <code>method</code></h4><p>我们需要定义的第一件事是选择新参数值的 <code>method</code>。</p>
<p>我们提供以下搜索 <code>methods</code>：</p>
<ul>
<li>**<code>grid</code> Search **– 迭代超参数值的每个组合。非常有效，但计算量大。</li>
<li><strong><code>random</code> Search</strong> – 根据提供的 <code>distribution</code> 随机选择每个新组合。出乎意料的有效！</li>
<li><strong><code>bayesian</code> Search</strong> – 创建一个度量分数作为超参数函数的概率模型，并选择具有提高度量的高概率的参数。适用于少量连续参数但扩展性差。</li>
</ul>
<p><code>random</code> 方法：</p>
<pre class=" language-python"><code class="language-python">sweep_config <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'method'</span><span class="token punctuation">:</span> <span class="token string">'random'</span>
    <span class="token punctuation">}</span>
</code></pre>
<p>对于 <code>bayesian</code> Sweeps，您还需要告诉我们一些关于您的 metric 的信息。我们需要知道它的名称，以便我们可以在模型输出中找到它，我们需要知道您的目标是最小化它（例如，如果它是 squared error）还是最大化它（例如，如果它是 accuracy）。</p>
<pre class=" language-python"><code class="language-python">metric <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'name'</span><span class="token punctuation">:</span> <span class="token string">'loss'</span><span class="token punctuation">,</span>
    <span class="token string">'goal'</span><span class="token punctuation">:</span> <span class="token string">'minimize'</span>   
    <span class="token punctuation">}</span>

sweep_config<span class="token punctuation">[</span><span class="token string">'metric'</span><span class="token punctuation">]</span> <span class="token operator">=</span> metric
</code></pre>
<p>如果您没有运行 <code>bayesian</code> Sweep，则不必这样做，但无论如何将其包含在您的 <code>sweep_config</code> 中并不是一个坏主意，以防您以后改变主意。记录这样的事情也是很好的再现性实践，以防万一您或其他人在 6 个月或 6 年后回到您的 Sweep 并且不知道 <code>val_G_batch</code> 应该是高还是低。</p>
<h4 id="Name-the-hyperparameters"><a href="#Name-the-hyperparameters" class="headerlink" title="Name the hyperparameters"></a>Name the hyper<code>parameters</code></h4><p>一旦您选择了一种 <code>method</code> 来尝试超参数的新值，您需要定义这些 <code>parameters</code>是什么</p>
<p>大多数时候，这一步很简单：您只需为 <code>parameter</code> 命名并指定参数的合法 <code>values</code> 列表。</p>
<p>例如，当我们为我们的网络选择 <code>optimizer</code> 时，只有有限数量的选项。在这里，我们坚持使用两个最受欢迎的选择，<code>adam</code> 和 <code>sgd</code>。即使对于具有潜在无限选项的超参数，通常也只尝试几个选择 <code>values</code> 才有意义，就像我们在此处对隐藏层 <code>layer_size</code> 和 <code>dropout</code> 所做的那样。</p>
<pre class=" language-python"><code class="language-python">parameters_dict <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'optimizer'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token string">'values'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'adam'</span><span class="token punctuation">,</span> <span class="token string">'sgd'</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'fc_layer_size'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token string">'values'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'dropout'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
          <span class="token string">'values'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>

sweep_config<span class="token punctuation">[</span><span class="token string">'parameters'</span><span class="token punctuation">]</span> <span class="token operator">=</span> parameters_dict
</code></pre>
<p>通常情况下，有些超参数我们不想在此 Sweep 中改变，但我们仍希望在我们的 <code>sweep_config</code> 中设置它们。</p>
<p>在那种情况下，我们直接设置 <code>value</code>：</p>
<pre class=" language-python"><code class="language-python">parameters_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">'epochs'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token string">'value'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
<p>对于 <code>grid</code> 搜索，这就是您所需要的。</p>
<p>对于 <code>random</code> 搜索，参数的所有 <code>values</code> 在给定运行中被选择的可能性相同。</p>
<p>如果这样做不行，您可以改为指定命名 <code>distribution</code> 及其参数，例如 <code>normal</code> 分布的均值 <code>mu</code> 和标准差 <code>sigma</code>。</p>
<p>在<a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/configuration#distributions">此处</a>查看有关如何设置随机变量分布的更多信息。</p>
<pre class=" language-python"><code class="language-python">parameters_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true"># a flat distribution between 0 and 0.1</span>
        <span class="token string">'distribution'</span><span class="token punctuation">:</span> <span class="token string">'uniform'</span><span class="token punctuation">,</span>
        <span class="token string">'min'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token string">'max'</span><span class="token punctuation">:</span> <span class="token number">0.1</span>
      <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'batch_size'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true"># integers between 32 and 256</span>
        <span class="token comment" spellcheck="true"># with evenly-distributed logarithms </span>
        <span class="token string">'distribution'</span><span class="token punctuation">:</span> <span class="token string">'q_log_uniform_values'</span><span class="token punctuation">,</span>
        <span class="token string">'q'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
        <span class="token string">'min'</span><span class="token punctuation">:</span> <span class="token number">32</span><span class="token punctuation">,</span>
        <span class="token string">'max'</span><span class="token punctuation">:</span> <span class="token number">256</span><span class="token punctuation">,</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
<p>当我们完成后，<code>sweep_config</code> 是一个嵌套的字典，它准确地指定了我们有兴趣尝试哪些 <code>parameters</code> 以及我们将使用什么 <code>method</code> 来尝试它们。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pprint

pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>sweep_config<span class="token punctuation">)</span>
</code></pre>
<p>但这不是所有的配置选项！</p>
<p>例如，我们还提供了使用 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.06560.pdf">HyperBand</a> 调度算法 <code>early_terminate</code> 运行的选项。在<a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/configuration#stopping-criteria">这里</a>查看更多。</p>
<p>您可以在<a target="_blank" rel="noopener" href="https://docs.wandb.com/library/sweeps/configuration">此处</a>找到所有配置选项的列表，并在<a target="_blank" rel="noopener" href="https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion">此处</a>找到大量 YAML 格式的示例。</p>
<h3 id="Step-2️⃣-Initialize-the-Sweep"><a href="#Step-2️⃣-Initialize-the-Sweep" class="headerlink" title="Step 2️⃣. Initialize the Sweep"></a>Step 2️⃣. Initialize the Sweep</h3><p>一旦您定义了搜索策略，就该设置一些东西来实现它了。</p>
<p>负责我们 Sweep 的 clockwork taskmaster 被称为 <em>Sweep Controller</em>。每次运行完成时，它将发出一组新的指令来描述要执行的新运行。这些指令由实际执行运行的 <em>agents</em> 获取。</p>
<p>在典型的 Sweep 中，Controller 位于我们的机器上，而完成运行的代理位于您的机器上，如下图所示。这种分工使得只需添加更多机器来运行代理就可以非常容易地扩展 Sweeps！</p>
<p><img src="https://i.imgur.com/zlbw3vQ.png" alt="sweeps-diagram"></p>
<p>我们可以通过使用适当的 <code>sweep_config</code> 和 <code>project</code> 名称调用 <code>wandb.sweep</code> 来结束 Sweep Controller。</p>
<p>此函数返回一个 <code>sweep_id</code>，我们稍后将使用它来将 agents 分配给此 Controller。</p>
<p>旁注：在命令行上，此功能被替换为</p>
<pre class=" language-bash"><code class="language-bash">wandb sweep config.yaml
</code></pre>
<p><a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/quickstart">了解更多关于在命令行中使用 Sweeps ➡</a></p>
<pre class=" language-python"><code class="language-python">sweep_id <span class="token operator">=</span> wandb<span class="token punctuation">.</span>sweep<span class="token punctuation">(</span>sweep_config<span class="token punctuation">,</span> project<span class="token operator">=</span><span class="token string">"pytorch-sweeps-demo"</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="Step-3️⃣-Run-the-Sweep-agent"><a href="#Step-3️⃣-Run-the-Sweep-agent" class="headerlink" title="Step 3️⃣. Run the Sweep agent"></a>Step 3️⃣. Run the Sweep agent</h3><h4 id="Define-Your-Training-Procedure"><a href="#Define-Your-Training-Procedure" class="headerlink" title="Define Your Training Procedure"></a>Define Your Training Procedure</h4><p>在我们实际执行 sweep 之前，我们需要定义使用这些值的训练过程。</p>
<p>在下面的函数中，我们在 PyTorch 中定义了一个简单的全连接神经网络，并添加了以下 <code>wandb</code> 工具来记录模型指标、可视化性能和输出并跟踪我们的实验：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://docs.wandb.com/library/init"><strong><code>wandb.init()</code></strong></a> – 初始化新的 W&amp;B 运行。每次运行都是训练功能的一次执行。</li>
<li><a target="_blank" rel="noopener" href="https://docs.wandb.com/library/config"><strong><code>wandb.config</code></strong></a> – 将所有超参数保存在配置对象中，以便记录它们。在<a target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-config/Configs_in_W%26B.ipynb">此处</a>阅读有关如何使用 <code>wandb.config</code> 的更多信息。</li>
<li><a target="_blank" rel="noopener" href="https://docs.wandb.com/library/log"><strong><code>wandb.log()</code></strong></a> – 将模型行为记录到 W&amp;B。在这里，我们只记录性能；有关可以使用 <code>wandb.log</code> 记录的所有其他富媒体，请参阅此 <a target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Log_(Almost)_Anything_with_W%26B_Media.ipynb">Colab</a>。</li>
</ul>
<p>有关使用 PyTorch 检测 W&amp;B 的更多详细信息，请参阅此 <a target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb">Colab</a>。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms

device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>config<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Initialize a new wandb run</span>
    <span class="token keyword">with</span> wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>config<span class="token operator">=</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># If called by wandb.agent, as below,</span>
        <span class="token comment" spellcheck="true"># this config will be set by Sweep Controller</span>
        config <span class="token operator">=</span> wandb<span class="token punctuation">.</span>config

        loader <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        network <span class="token operator">=</span> build_network<span class="token punctuation">(</span>config<span class="token punctuation">.</span>fc_layer_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>
        optimizer <span class="token operator">=</span> build_optimizer<span class="token punctuation">(</span>network<span class="token punctuation">,</span> config<span class="token punctuation">.</span>optimizer<span class="token punctuation">,</span> config<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span>

        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>config<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            avg_loss <span class="token operator">=</span> train_epoch<span class="token punctuation">(</span>network<span class="token punctuation">,</span> loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span>
            wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"loss"</span><span class="token punctuation">:</span> avg_loss<span class="token punctuation">,</span> <span class="token string">"epoch"</span><span class="token punctuation">:</span> epoch<span class="token punctuation">}</span><span class="token punctuation">)</span>           
</code></pre>
<p>这个单元格定义了我们训练过程的四个部分：<code>build_dataset</code>, <code>build_network</code>, <code>build_optimizer</code> 和<code>train_epoch</code>.</p>
<p>所有这些都是基本 PyTorch 管道的标准部分，它们的实现不受使用 W&amp;B 的影响，因此我们不会对它们发表评论。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_dataset</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
   
    transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># download MNIST training dataset</span>
    dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                             transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
    sub_dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Subset<span class="token punctuation">(</span>
        dataset<span class="token punctuation">,</span> indices<span class="token operator">=</span>range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>sub_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>

    <span class="token keyword">return</span> loader


<span class="token keyword">def</span> <span class="token function">build_network</span><span class="token punctuation">(</span>fc_layer_size<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
    network <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>  <span class="token comment" spellcheck="true"># fully-connected, single hidden layer</span>
        nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> fc_layer_size<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>fc_layer_size<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> network<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        

<span class="token keyword">def</span> <span class="token function">build_optimizer</span><span class="token punctuation">(</span>network<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> optimizer <span class="token operator">==</span> <span class="token string">"sgd"</span><span class="token punctuation">:</span>
        optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>network<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                              lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> optimizer <span class="token operator">==</span> <span class="token string">"adam"</span><span class="token punctuation">:</span>
        optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>network<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                               lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>
    <span class="token keyword">return</span> optimizer


<span class="token keyword">def</span> <span class="token function">train_epoch</span><span class="token punctuation">(</span>network<span class="token punctuation">,</span> loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    cumu_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> _<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data<span class="token punctuation">,</span> target <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># ➡ Forward pass</span>
        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>network<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span>
        cumu_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># ⬅ Backward pass + weight update</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"batch loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> cumu_loss <span class="token operator">/</span> len<span class="token punctuation">(</span>loader<span class="token punctuation">)</span>
</code></pre>
<p>现在，我们准备开始 sweeping 了！</p>
<p>Sweep Controllers，就像我们通过运行 <code>wandb.sweep</code> 制作的控制器一样，坐等有人要求他们提供 <code>config </code>来试用。</p>
<p>某人是 <code>agent</code>，他们是用 <code>wandb.agent</code> 创建的。要开始，agent 只需要知道</p>
<ol>
<li>它是 (<code>sweep_id</code>) 的一部分</li>
<li>它应该运行哪个函数（这里是 <code>train</code>）</li>
<li>（可选）有多少配置要求控制器（<code>count</code>）</li>
</ol>
<p>仅供参考，您可以在不同的计算资源上启动具有相同 <code>sweep_id</code> 的多个 <code>agent</code>，Controller 将确保它们根据 <code>sweep_config</code> 中制定的策略协同工作。这使得在尽可能多的节点上扩展 Sweeps 变得轻而易举！</p>
<p>旁注：在命令行上，此功能被替换为</p>
<pre class=" language-bash"><code class="language-bash">wandb agent sweep_id
</code></pre>
<p><a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/quickstart">了解更多关于在命令行中使用 Sweeps ➡</a></p>
<p>下面的单元格将启动一个运行 <code>train</code> 5 次的 <code>agent</code>，使用 Sweep Controller 返回的随机生成的超参数值。执行时间不到 5 分钟。</p>
<pre class=" language-python"><code class="language-python">wandb<span class="token punctuation">.</span>agent<span class="token punctuation">(</span>sweep_id<span class="token punctuation">,</span> train<span class="token punctuation">,</span> count<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="Visualize-Sweep-Results"><a href="#Visualize-Sweep-Results" class="headerlink" title="Visualize Sweep Results"></a>Visualize Sweep Results</h3><h4 id="Parallel-Coordinates-Plot"><a href="#Parallel-Coordinates-Plot" class="headerlink" title="Parallel Coordinates Plot"></a>Parallel Coordinates Plot</h4><p>此图将超参数值映射到模型指标。它对于磨练导致最佳模型性能的超参数组合很有用。</p>
<p><img src="https://assets.website-files.com/5ac6b7f2924c652fd013a891/5e190366778ad831455f9af2_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695138341_image.png" alt="img"></p>
<h4 id="Hyperparameter-Importance-Plot"><a href="#Hyperparameter-Importance-Plot" class="headerlink" title="Hyperparameter Importance Plot"></a>Hyperparameter Importance Plot</h4><p>超参数重要性图表明哪些超参数是指标的最佳预测因子。我们报告特征重要性（来自随机森林模型）和相关性（隐式线性模型）。</p>
<p><img src="https://assets.website-files.com/5ac6b7f2924c652fd013a891/5e190367778ad820b35f9af5_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695757573_image.png" alt="img"></p>
<p>这些可视化可以通过磨练最重要的参数（和值范围）来帮助您节省运行昂贵的超参数优化的时间和资源，因此值得进一步探索。</p>
<h3 id="Get-your-hands-dirty-with-sweeps"><a href="#Get-your-hands-dirty-with-sweeps" class="headerlink" title="Get your hands dirty with sweeps"></a>Get your hands dirty with sweeps</h3><p>我们创建了一个简单的训练脚本和一些<a target="_blank" rel="noopener" href="https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion">sweep configs</a> 风格供您使用。我们强烈建议您尝试一下。</p>
<p>该存储库还提供了一些示例，可帮助您尝试更高级的扫描功能，例如 <a target="_blank" rel="noopener" href="https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/us0ifmrf?workspace=user-lavanyashukla&amp;_gl=1*1h57q6p*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjYyMjIyOS43LjAuMTY4NjYyMjIyOS42MC4wLjA.">Bayesian Hyperband</a> 和 <a target="_blank" rel="noopener" href="https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/xbs2wm5e?workspace=user-lavanyashukla&amp;_gl=1*5hk37j*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjYyMjIyOS43LjAuMTY4NjYyMjIyOS42MC4wLjA.">Hyperopt</a>。</p>
<h2 id="Track-models-and-datasets"><a href="#Track-models-and-datasets" class="headerlink" title="Track models and datasets"></a>Track models and datasets</h2>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">培根请加蛋</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://blog.lfd-world.online/2023/06/12/wandb-xue-xi-ri-ji-yi-doc/">https://blog.lfd-world.online/2023/06/12/wandb-xue-xi-ri-ji-yi-doc/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">培根请加蛋</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/WandB/">
                                    <span class="chip bg-color">WandB</span>
                                </a>
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/2023/06/12/wandb-xue-xi-ri-ji-yi-doc/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/18.jpg" class="responsive-img" alt="WandB 学习日记（一）Doc">
                        
                        <span class="card-title">WandB 学习日记（一）Doc</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            WandB 学习日记（一）Doc
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-06-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/WandB/" class="post-category">
                                    WandB
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/WandB/">
                        <span class="chip bg-color">WandB</span>
                    </a>
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2023/06/04/2023-0github-pages-ge-ren-bo-ke-da-jian-si-zi-ding-yi-yu-ming-ji-bai-du-gu-ge-shou-lu/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/18.jpg" class="responsive-img" alt="Github Pages + Hexo + Vercel 个人博客搭建（四）自定义域名及百度谷歌收录">
                        
                        <span class="card-title">Github Pages + Hexo + Vercel 个人博客搭建（四）自定义域名及百度谷歌收录</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            自定义域名及百度谷歌收录
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-06-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Blog/" class="post-category">
                                    Blog
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Blog/">
                        <span class="chip bg-color">Blog</span>
                    </a>
                    
                    <a href="/tags/Hexo/">
                        <span class="chip bg-color">Hexo</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE' || selection.getRangeAt(0).commonAncestorContainer.nodeName === 'CODE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 培根请加蛋<br />'
            + '文章作者: 培根请加蛋<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023</span>
            
            <a href="/about" target="_blank">培根请加蛋</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">15k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/LFD-byte" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:huifali@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
