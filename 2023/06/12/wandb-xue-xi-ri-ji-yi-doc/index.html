<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="WandB 学习日记（一）Tutorials, 培根请加蛋">
    <meta name="description" content="WandB 学习日记（一）Tutorials">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google-site-verification" content="qvBHqgbyc_CYw3ZE9lrEIxYSUzkcL8LH9-_uDtcme5A" />
    <meta name="baidu-site-verification" content="codeva-mJZ2sqHuqv" />
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>WandB 学习日记（一）Tutorials | 培根请加蛋</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    


    
    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="培根请加蛋" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">培根请加蛋</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">培根请加蛋</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/LFD-byte" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/LFD-byte" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">WandB 学习日记（一）Tutorials</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/WandB/">
                                <span class="chip bg-color">WandB</span>
                            </a>
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/WandB/" class="post-category">
                                WandB
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-06-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2023-06-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    42 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="Track-experiments"><a href="#Track-experiments" class="headerlink" title="Track experiments"></a>Track experiments</h2><p>快速实验是机器学习的基础。在本教程中，我们使用 W&amp;B 来跟踪和可视化实验，以便我们可以快速迭代和理解我们的结果。</p>
<h3 id="A-shared-dashboard-for-your-experiments"><a href="#A-shared-dashboard-for-your-experiments" class="headerlink" title="A shared dashboard for your experiments"></a>A shared dashboard for your experiments</h3><p>只需几行代码，您就可以获得丰富的、交互式的、可共享的仪表板，您可以在这里看到<a target="_blank" rel="noopener" href="https://wandb.ai/wandb/wandb_example?_gl=1*1ycseye*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MDE0OC41MC4wLjA.">自己的 dashboard </a>。</p>
<p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedPell4Oo.png" alt="dashboard"></p>
<h3 id="Data-amp-Privacy"><a href="#Data-amp-Privacy" class="headerlink" title="Data &amp; Privacy"></a>Data &amp; Privacy</h3><p>我们非常重视安全性，我们的云托管 dashboard 使用行业标准最佳加密实践。如果您正在使用无法离开企业集群的数据集，我们可以提供<a target="_blank" rel="noopener" href="https://docs.wandb.com/self-hosted">本地安装</a>。</p>
<p>下载所有数据并将其导出到其他工具也很容易——例如在 Jupyter 笔记本中进行自定义分析。下面是关于我们 <a target="_blank" rel="noopener" href="https://docs.wandb.com/library/api">API</a> 的更多信息。</p>
<h3 id="Install-wandb-library-and-login"><a href="#Install-wandb-library-and-login" class="headerlink" title="Install wandb library and login"></a>Install <code>wandb</code> library and login</h3><p>首先安装库并登录到您的免费帐户。</p>
<pre class=" language-bash"><code class="language-bash"><span class="token operator">!</span>pip <span class="token function">install</span> wandb -qU
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Log in to your W&amp;B account</span>
<span class="token keyword">import</span> wandb
wandb<span class="token punctuation">.</span>login<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="Run-an-experiment"><a href="#Run-an-experiment" class="headerlink" title="Run an experiment"></a>Run an experiment</h3><p>1️⃣. 开始新的运行并传入超参数进行跟踪</p>
<p>2️⃣. 训练或评估的日志指标</p>
<p>3️⃣. 在 dashboard 中可视化结果</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> random

<span class="token comment" spellcheck="true"># Launch 5 simulated experiments</span>
total_runs <span class="token operator">=</span> <span class="token number">5</span>
<span class="token keyword">for</span> run <span class="token keyword">in</span> range<span class="token punctuation">(</span>total_runs<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment" spellcheck="true"># 🐝 1️⃣ Start a new run to track this script</span>
  wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>
      <span class="token comment" spellcheck="true"># Set the project where this run will be logged</span>
      project<span class="token operator">=</span><span class="token string">"basic-intro"</span><span class="token punctuation">,</span> 
      <span class="token comment" spellcheck="true"># We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)</span>
      name<span class="token operator">=</span>f<span class="token string">"experiment_{run}"</span><span class="token punctuation">,</span> 
      <span class="token comment" spellcheck="true"># Track hyperparameters and run metadata</span>
      config<span class="token operator">=</span><span class="token punctuation">{</span>
      <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> <span class="token number">0.02</span><span class="token punctuation">,</span>
      <span class="token string">"architecture"</span><span class="token punctuation">:</span> <span class="token string">"CNN"</span><span class="token punctuation">,</span>
      <span class="token string">"dataset"</span><span class="token punctuation">:</span> <span class="token string">"CIFAR-100"</span><span class="token punctuation">,</span>
      <span class="token string">"epochs"</span><span class="token punctuation">:</span> <span class="token number">10</span><span class="token punctuation">,</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
  
  <span class="token comment" spellcheck="true"># This simple block simulates a training loop logging metrics</span>
  epochs <span class="token operator">=</span> <span class="token number">10</span>
  offset <span class="token operator">=</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">5</span>
  <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
      acc <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> <span class="token number">2</span> <span class="token operator">**</span> <span class="token operator">-</span>epoch <span class="token operator">-</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> epoch <span class="token operator">-</span> offset
      loss <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">**</span> <span class="token operator">-</span>epoch <span class="token operator">+</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> epoch <span class="token operator">+</span> offset
      
      <span class="token comment" spellcheck="true"># 🐝 2️⃣ Log metrics from your script to W&amp;B</span>
      wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"acc"</span><span class="token punctuation">:</span> acc<span class="token punctuation">,</span> <span class="token string">"loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">}</span><span class="token punctuation">)</span>
      
  <span class="token comment" spellcheck="true"># Mark the run as finished</span>
  wandb<span class="token punctuation">.</span>finish<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>3️⃣ 当您运行此代码时，您可以通过单击上面的任何 👆 wandb 链接找到您的交互式 dashboard。</p>
<h3 id="Simple-Pytorch-Neural-Network"><a href="#Simple-Pytorch-Neural-Network" class="headerlink" title="Simple Pytorch Neural Network"></a>Simple Pytorch Neural Network</h3><p>运行此模型以训练一个简单的 MNIST 分类器，然后单击项目页面链接以实时查看您的结果流到 W&amp;B 项目。</p>
<p>wandb 中的任何运行都会自动记录 <a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#charts-tab">metrics</a>, <a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#system-tab">system information</a>, <a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#overview-tab">hyperparameters</a>, <a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#logs-tab">terminal output</a> ，您将看到一个包含模型输入和输出的交互式表格。</p>
<h4 id="Set-up-Dataloader"><a href="#Set-up-Dataloader" class="headerlink" title="Set up Dataloader"></a>Set up Dataloader</h4><p>要运行此示例，我们需要安装 PyTorch。如果您使用的是 Google Colab，则它已经预装。</p>
<pre class=" language-bash"><code class="language-bash"><span class="token operator">!</span>pip <span class="token function">install</span> torch torchvision
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> wandb
<span class="token keyword">import</span> math
<span class="token keyword">import</span> random
<span class="token keyword">import</span> torch<span class="token punctuation">,</span> torchvision
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T

device <span class="token operator">=</span> <span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>

<span class="token keyword">def</span> <span class="token function">get_dataloader</span><span class="token punctuation">(</span>is_train<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> slice<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Get a training dataloader"</span>
    full_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">,</span> train<span class="token operator">=</span>is_train<span class="token punctuation">,</span> transform<span class="token operator">=</span>T<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    sub_dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Subset<span class="token punctuation">(</span>full_dataset<span class="token punctuation">,</span> indices<span class="token operator">=</span>range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>full_dataset<span class="token punctuation">)</span><span class="token punctuation">,</span> slice<span class="token punctuation">)</span><span class="token punctuation">)</span>
    loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>sub_dataset<span class="token punctuation">,</span> 
                                         batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> 
                                         shuffle<span class="token operator">=</span><span class="token boolean">True</span> <span class="token keyword">if</span> is_train <span class="token keyword">else</span> <span class="token boolean">False</span><span class="token punctuation">,</span> 
                                         pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> loader

<span class="token keyword">def</span> <span class="token function">get_model</span><span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"A simple model"</span>
    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                         nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                         nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                         nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                         nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">,</span>
                         nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">return</span> model

<span class="token keyword">def</span> <span class="token function">validate_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> valid_dl<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> log_images<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> batch_idx<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Compute performance of the model on the validation dataset and log a wandb.Table"</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    val_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">.</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>inference_mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        correct <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>valid_dl<span class="token punctuation">)</span><span class="token punctuation">:</span>
            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Forward pass ➡</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            val_loss <span class="token operator">+=</span> loss_func<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token operator">*</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Compute accuracy and accumulate</span>
            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># Log one batch of images to the dashboard, always same batch_idx.</span>
            <span class="token keyword">if</span> i<span class="token operator">==</span>batch_idx <span class="token operator">and</span> log_images<span class="token punctuation">:</span>
                log_image_table<span class="token punctuation">(</span>images<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> outputs<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> val_loss <span class="token operator">/</span> len<span class="token punctuation">(</span>valid_dl<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span> correct <span class="token operator">/</span> len<span class="token punctuation">(</span>valid_dl<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">log_image_table</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> probs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Log a wandb.Table with (img, pred, target, scores)"</span>
    <span class="token comment" spellcheck="true"># 🐝 Create a wandb Table to log images, labels and predictions to</span>
    table <span class="token operator">=</span> wandb<span class="token punctuation">.</span>Table<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">,</span> <span class="token string">"pred"</span><span class="token punctuation">,</span> <span class="token string">"target"</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token punctuation">[</span>f<span class="token string">"score_{i}"</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> img<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> targ<span class="token punctuation">,</span> prob <span class="token keyword">in</span> zip<span class="token punctuation">(</span>images<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> predicted<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> probs<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        table<span class="token punctuation">.</span>add_data<span class="token punctuation">(</span>wandb<span class="token punctuation">.</span>Image<span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">,</span> pred<span class="token punctuation">,</span> targ<span class="token punctuation">,</span> <span class="token operator">*</span>prob<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"predictions_table"</span><span class="token punctuation">:</span>table<span class="token punctuation">}</span><span class="token punctuation">,</span> commit<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="Train-Your-Model"><a href="#Train-Your-Model" class="headerlink" title="Train Your Model"></a>Train Your Model</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Launch 5 experiments, trying different dropout rates</span>
<span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 🐝 initialise a wandb run</span>
    wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>
        project<span class="token operator">=</span><span class="token string">"pytorch-intro"</span><span class="token punctuation">,</span>
        config<span class="token operator">=</span><span class="token punctuation">{</span>
            <span class="token string">"epochs"</span><span class="token punctuation">:</span> <span class="token number">10</span><span class="token punctuation">,</span>
            <span class="token string">"batch_size"</span><span class="token punctuation">:</span> <span class="token number">128</span><span class="token punctuation">,</span>
            <span class="token string">"lr"</span><span class="token punctuation">:</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span>
            <span class="token string">"dropout"</span><span class="token punctuation">:</span> random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.80</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># Copy your config </span>
    config <span class="token operator">=</span> wandb<span class="token punctuation">.</span>config

    <span class="token comment" spellcheck="true"># Get the data</span>
    train_dl <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>is_train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
    valid_dl <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>is_train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token operator">*</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
    n_steps_per_epoch <span class="token operator">=</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_dl<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span> <span class="token operator">/</span> config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># A simple MLP model</span>
    model <span class="token operator">=</span> get_model<span class="token punctuation">(</span>config<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Make the loss and optimizer</span>
    loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>config<span class="token punctuation">.</span>lr<span class="token punctuation">)</span>

   <span class="token comment" spellcheck="true"># Training</span>
    example_ct <span class="token operator">=</span> <span class="token number">0</span>
    step_ct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>config<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_dl<span class="token punctuation">)</span><span class="token punctuation">:</span>
            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            train_loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
            example_ct <span class="token operator">+=</span> len<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"train/train_loss"</span><span class="token punctuation">:</span> train_loss<span class="token punctuation">,</span> 
                       <span class="token string">"train/epoch"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>step <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>n_steps_per_epoch <span class="token operator">*</span> epoch<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> n_steps_per_epoch<span class="token punctuation">,</span> 
                       <span class="token string">"train/example_ct"</span><span class="token punctuation">:</span> example_ct<span class="token punctuation">}</span>
            
            <span class="token keyword">if</span> step <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">&lt;</span> n_steps_per_epoch<span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 🐝 Log train metrics to wandb </span>
                wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span>metrics<span class="token punctuation">)</span>
                
            step_ct <span class="token operator">+=</span> <span class="token number">1</span>

        val_loss<span class="token punctuation">,</span> accuracy <span class="token operator">=</span> validate_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> valid_dl<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> log_images<span class="token operator">=</span><span class="token punctuation">(</span>epoch<span class="token operator">==</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>epochs<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 🐝 Log train and validation metrics to wandb</span>
        val_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"val/val_loss"</span><span class="token punctuation">:</span> val_loss<span class="token punctuation">,</span> 
                       <span class="token string">"val/val_accuracy"</span><span class="token punctuation">:</span> accuracy<span class="token punctuation">}</span>
        wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token operator">**</span>metrics<span class="token punctuation">,</span> <span class="token operator">**</span>val_metrics<span class="token punctuation">}</span><span class="token punctuation">)</span>
        
        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}"</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># If you had a test set, this is how you could log it as a Summary metric</span>
    wandb<span class="token punctuation">.</span>summary<span class="token punctuation">[</span><span class="token string">'test_accuracy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.8</span>

    <span class="token comment" spellcheck="true"># 🐝 Close your wandb run </span>
    wandb<span class="token punctuation">.</span>finish<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>您现在已经使用 wandb 训练了您的第一个模型！ 👆 单击上面的 wandb 链接查看您的指标</p>
<h3 id="Try-W-amp-B-Alerts"><a href="#Try-W-amp-B-Alerts" class="headerlink" title="Try W&amp;B Alerts"></a>Try W&amp;B Alerts</h3><p><strong><a target="_blank" rel="noopener" href="https://docs.wandb.ai/guides/track/alert">W&amp;B Alerts</a></strong>  允许您将从 Python 代码触发的警报发送到您的 Slack 或电子邮件。第一次发送 Slack 或电子邮件警报时，需要执行 2 个步骤，这些警报由您的代码触发：</p>
<p>1) 在你的 W&amp;B <a target="_blank" rel="noopener" href="https://wandb.ai/settings">User Settings</a> 开启警报</p>
<p>2) 添加 <code>wandb.alert()</code> 到你的代码:</p>
<pre class=" language-python"><code class="language-python">wandb<span class="token punctuation">.</span>alert<span class="token punctuation">(</span>
    title<span class="token operator">=</span><span class="token string">"Low accuracy"</span><span class="token punctuation">,</span> 
    text<span class="token operator">=</span>f<span class="token string">"Accuracy is below the acceptable threshold"</span>
<span class="token punctuation">)</span>
</code></pre>
<p>请参阅下面的最小示例以了解如何使用 wandb.alert，您可以在此处找到 <a target="_blank" rel="noopener" href="https://docs.wandb.ai/guides/track/alert">W&amp;B Alerts</a>的完整文档</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Start a wandb run</span>
wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>project<span class="token operator">=</span><span class="token string">"pytorch-intro"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Simulating a model training loop</span>
acc_threshold <span class="token operator">=</span> <span class="token number">0.3</span>
<span class="token keyword">for</span> training_step <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment" spellcheck="true"># Generate a random number for accuracy</span>
    accuracy <span class="token operator">=</span> round<span class="token punctuation">(</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Accuracy is: {accuracy}, {acc_threshold}'</span><span class="token punctuation">)</span>
    
    <span class="token comment" spellcheck="true"># 🐝 Log accuracy to wandb</span>
    wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"Accuracy"</span><span class="token punctuation">:</span> accuracy<span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 🔔 If the accuracy is below the threshold, fire a W&amp;B Alert and stop the run</span>
    <span class="token keyword">if</span> accuracy <span class="token operator">&lt;=</span> acc_threshold<span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 🐝 Send the wandb Alert</span>
        wandb<span class="token punctuation">.</span>alert<span class="token punctuation">(</span>
            title<span class="token operator">=</span><span class="token string">'Low Accuracy'</span><span class="token punctuation">,</span>
            text<span class="token operator">=</span>f<span class="token string">'Accuracy {accuracy} at step {training_step} is below the acceptable theshold, {acc_threshold}'</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Alert triggered'</span><span class="token punctuation">)</span>
        <span class="token keyword">break</span>

<span class="token comment" spellcheck="true"># Mark the run as finished (useful in Jupyter notebooks)</span>
wandb<span class="token punctuation">.</span>finish<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="Visualize-predictions"><a href="#Visualize-predictions" class="headerlink" title="Visualize predictions"></a>Visualize predictions</h2><p>这包括如何在训练过程中使用 PyTorch 对 MNIST 数据进行跟踪、可视化和比较模型预测。</p>
<p>你将学到如何：</p>
<ol>
<li>在模型训练或评估期间将指标、图像、文本等记录到 <code>wandb.Table()</code></li>
<li>查看、排序、筛选、分组、加入、交互式查询和探索这些表</li>
<li>比较模型预测或结果：动态地跨越特定图像、超参数/模型版本或时间步长。</li>
</ol>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><h4 id="Compare-predicted-scores-for-specific-images"><a href="#Compare-predicted-scores-for-specific-images" class="headerlink" title="Compare predicted scores for specific images"></a>Compare predicted scores for specific images</h4><p><a target="_blank" rel="noopener" href="https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU?_gl=1*6z1980*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MTg0Ni4zOC4wLjA.#compare-predictions-after-1-vs-5-epochs">实例：比较 1 和 5 个训练周期后的预测</a></p>
<p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedNMme6Qj.png" alt="1 epoch vs 5 epochs of training"></p>
<p>直方图比较了两个模型之间的每类分数。每个直方图中顶部的绿色条代表模型“CNN-2, 1 epoch”（id 0），它只训练了 1 个 epoch。底部的紫色条代表模型“CNN-2, 5 epochs” (id 1)，它训练了 5 个 epochs。图像被过滤到模型不一致的情况。例如，在第一行中，“4”在 1 个时期后在所有可能的数字中获得高分，但在 5 个时期后，它在正确标签上得分最高，而在其余部分得分非常低。</p>
<h4 id="Focus-on-top-errors-over-time"><a href="#Focus-on-top-errors-over-time" class="headerlink" title="Focus on top errors over time"></a>Focus on top errors over time</h4><p><a target="_blank" rel="noopener" href="https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU?_gl=1*1nxbzl7*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MTg0Ni4zOC4wLjA.#top-errors-over-time">实例 →</a></p>
<p>查看完整测试数据的不正确预测（过滤 “guess” != “truth” 的行）。请注意，在 1 个训练时期后有 229 个错误猜测，但在 5 个时期后只有 98 个。</p>
<p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefined7g8nodn.png" alt="side by side, 1 vs 5 epochs of training"></p>
<h4 id="Compare-model-performance-and-find-patterns"><a href="#Compare-model-performance-and-find-patterns" class="headerlink" title="Compare model performance and find patterns"></a>Compare model performance and find patterns</h4><p><a target="_blank" rel="noopener" href="https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU?_gl=1*8r828v*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MTg0Ni4zOC4wLjA.#false-positives-grouped-by-guess">查看实例中的完整详细信息 →</a></p>
<p>过滤出正确答案，然后按猜测分组，以查看错误分类图像的示例和真实标签的基本分布——并排显示两个模型。具有 2X layer sizes 和学习率的模型变体在左侧，基线在右侧。请注意，对于每个猜测的类，基线都会犯更多的错误。</p>
<p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedi5PP9AE.png" alt="grouped errors for baseline vs double variant"></p>
<h3 id="Sign-up-or-login"><a href="#Sign-up-or-login" class="headerlink" title="Sign up or login"></a>Sign up or login</h3><p><a target="_blank" rel="noopener" href="https://wandb.ai/login">Sign up or login</a> W&amp;B 以在浏览器中查看您的实验并与之互动。</p>
<p>在此示例中，我们使用 Google Colab 作为方便的托管环境，但您可以从任何地方运行自己的训练脚本，并使用 W&amp;B 的实验跟踪工具可视化指标。</p>
<pre class=" language-bash"><code class="language-bash"><span class="token operator">!</span>pip <span class="token function">install</span> wandb -qqq
</code></pre>
<p>登录您的帐户</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> wandb
wandb<span class="token punctuation">.</span>login<span class="token punctuation">(</span><span class="token punctuation">)</span>

WANDB_PROJECT <span class="token operator">=</span> <span class="token string">"mnist-viz"</span>
</code></pre>
<h3 id="0-Setup"><a href="#0-Setup" class="headerlink" title="0. Setup"></a>0. Setup</h3><p>安装依赖项，下载 MNIST，并使用 PyTorch 创建训练和测试数据集。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> T 
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F


device <span class="token operator">=</span> <span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>

<span class="token comment" spellcheck="true"># create train and test dataloaders</span>
<span class="token keyword">def</span> <span class="token function">get_dataloader</span><span class="token punctuation">(</span>is_train<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> slice<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Get a training dataloader"</span>
    ds <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">,</span> train<span class="token operator">=</span>is_train<span class="token punctuation">,</span> transform<span class="token operator">=</span>T<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>ds<span class="token punctuation">,</span> 
                                         batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> 
                                         shuffle<span class="token operator">=</span><span class="token boolean">True</span> <span class="token keyword">if</span> is_train <span class="token keyword">else</span> <span class="token boolean">False</span><span class="token punctuation">,</span> 
                                         pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> loader
</code></pre>
<h3 id="1-Define-the-model-and-training-schedule"><a href="#1-Define-the-model-and-training-schedule" class="headerlink" title="1. Define the model and training schedule"></a>1. Define the model and training schedule</h3><ul>
<li>设置要运行的纪元数，其中每个纪元包含一个训练步骤和一个验证（测试）步骤。 （可选）配置每个测试步骤要记录的数据量。这里要可视化的批次数和每批次的图像数设置得较低，以简化演示。</li>
<li>定义一个简单的卷积神经网络（遵循 <a target="_blank" rel="noopener" href="https://github.com/yunjey/pytorch-tutorial">pytorch-tutorial</a> 代码）。</li>
<li>使用 PyTorch 加载训练集和测试集</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Number of epochs to run</span>
<span class="token comment" spellcheck="true"># Each epoch includes a training step and a test step, so this sets</span>
<span class="token comment" spellcheck="true"># the number of tables of test predictions to log</span>
EPOCHS <span class="token operator">=</span> <span class="token number">1</span>

<span class="token comment" spellcheck="true"># Number of batches to log from the test data for each test step</span>
<span class="token comment" spellcheck="true"># (default set low to simplify demo)</span>
NUM_BATCHES_TO_LOG <span class="token operator">=</span> <span class="token number">10</span> <span class="token comment" spellcheck="true">#79</span>

<span class="token comment" spellcheck="true"># Number of images to log per test batch</span>
<span class="token comment" spellcheck="true"># (default set low to simplify demo)</span>
NUM_IMAGES_PER_BATCH <span class="token operator">=</span> <span class="token number">32</span> <span class="token comment" spellcheck="true">#128</span>

<span class="token comment" spellcheck="true"># training configuration and hyperparameters</span>
NUM_CLASSES <span class="token operator">=</span> <span class="token number">10</span>
BATCH_SIZE <span class="token operator">=</span> <span class="token number">32</span>
LEARNING_RATE <span class="token operator">=</span> <span class="token number">0.001</span>
L1_SIZE <span class="token operator">=</span> <span class="token number">32</span>
L2_SIZE <span class="token operator">=</span> <span class="token number">64</span>
<span class="token comment" spellcheck="true"># changing this may require changing the shape of adjacent layers</span>
CONV_KERNEL_SIZE <span class="token operator">=</span> <span class="token number">5</span>

<span class="token comment" spellcheck="true"># define a two-layer convolutional neural network</span>
<span class="token keyword">class</span> <span class="token class-name">ConvNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>ConvNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> L1_SIZE<span class="token punctuation">,</span> CONV_KERNEL_SIZE<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>L1_SIZE<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>L1_SIZE<span class="token punctuation">,</span> L2_SIZE<span class="token punctuation">,</span> CONV_KERNEL_SIZE<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>L2_SIZE<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span>L2_SIZE<span class="token punctuation">,</span> NUM_CLASSES<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span>NUM_CLASSES<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># uncomment to see the shape of a given layer:</span>
        <span class="token comment" spellcheck="true">#print("x: ", x.size())</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out

train_loader <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>is_train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> get_dataloader<span class="token punctuation">(</span>is_train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token operator">*</span>BATCH_SIZE<span class="token punctuation">)</span>

device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="2-Run-training-and-log-test-predictions"><a href="#2-Run-training-and-log-test-predictions" class="headerlink" title="2. Run training and log test predictions"></a>2. Run training and log test predictions</h3><p>对于每个时期，运行一个训练步骤和一个测试步骤。对于每个测试步骤，创建一个 wandb.Table() 来存储测试预测。这些可以在您的浏览器中进行可视化、动态查询和并排比较。</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ✨ W&amp;B: Initialize a new run to track this model's training</span>
wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>project<span class="token operator">=</span><span class="token string">"table-quickstart"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># ✨ W&amp;B: Log hyperparameters using config</span>
cfg <span class="token operator">=</span> wandb<span class="token punctuation">.</span>config
cfg<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"epochs"</span> <span class="token punctuation">:</span> EPOCHS<span class="token punctuation">,</span> <span class="token string">"batch_size"</span><span class="token punctuation">:</span> BATCH_SIZE<span class="token punctuation">,</span> <span class="token string">"lr"</span> <span class="token punctuation">:</span> LEARNING_RATE<span class="token punctuation">,</span>
            <span class="token string">"l1_size"</span> <span class="token punctuation">:</span> L1_SIZE<span class="token punctuation">,</span> <span class="token string">"l2_size"</span><span class="token punctuation">:</span> L2_SIZE<span class="token punctuation">,</span>
            <span class="token string">"conv_kernel"</span> <span class="token punctuation">:</span> CONV_KERNEL_SIZE<span class="token punctuation">,</span>
            <span class="token string">"img_count"</span> <span class="token punctuation">:</span> min<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> NUM_IMAGES_PER_BATCH<span class="token operator">*</span>NUM_BATCHES_TO_LOG<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># define model, loss, and optimizer</span>
model <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span>NUM_CLASSES<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LEARNING_RATE<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># convenience funtion to log predictions for a batch of test images</span>
<span class="token keyword">def</span> <span class="token function">log_test_predictions</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> test_table<span class="token punctuation">,</span> log_counter<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment" spellcheck="true"># obtain confidence scores for all classes</span>
  scores <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
  log_scores <span class="token operator">=</span> scores<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  log_images <span class="token operator">=</span> images<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  log_labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  log_preds <span class="token operator">=</span> predicted<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token comment" spellcheck="true"># adding ids based on the order of the images</span>
  _id <span class="token operator">=</span> <span class="token number">0</span>
  <span class="token keyword">for</span> i<span class="token punctuation">,</span> l<span class="token punctuation">,</span> p<span class="token punctuation">,</span> s <span class="token keyword">in</span> zip<span class="token punctuation">(</span>log_images<span class="token punctuation">,</span> log_labels<span class="token punctuation">,</span> log_preds<span class="token punctuation">,</span> log_scores<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># add required info to data table:</span>
    <span class="token comment" spellcheck="true"># id, image pixels, model's guess, true label, scores for all classes</span>
    img_id <span class="token operator">=</span> str<span class="token punctuation">(</span>_id<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>log_counter<span class="token punctuation">)</span>
    test_table<span class="token punctuation">.</span>add_data<span class="token punctuation">(</span>img_id<span class="token punctuation">,</span> wandb<span class="token punctuation">.</span>Image<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> p<span class="token punctuation">,</span> l<span class="token punctuation">,</span> <span class="token operator">*</span>s<span class="token punctuation">)</span>
    _id <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">if</span> _id <span class="token operator">==</span> NUM_IMAGES_PER_BATCH<span class="token punctuation">:</span>
      <span class="token keyword">break</span>

<span class="token comment" spellcheck="true"># train the model</span>
total_step <span class="token operator">=</span> len<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>EPOCHS<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># training step</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># forward pass</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># backward and optimize</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
  
        <span class="token comment" spellcheck="true"># ✨ W&amp;B: Log loss over training steps, visualized in the UI live</span>
        wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"loss"</span> <span class="token punctuation">:</span> loss<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'</span>
                <span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> EPOCHS<span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> total_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            

    <span class="token comment" spellcheck="true"># ✨ W&amp;B: Create a Table to store predictions for each test step</span>
    columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">,</span> <span class="token string">"image"</span><span class="token punctuation">,</span> <span class="token string">"guess"</span><span class="token punctuation">,</span> <span class="token string">"truth"</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> digit <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      columns<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">"score_"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>digit<span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_table <span class="token operator">=</span> wandb<span class="token punctuation">.</span>Table<span class="token punctuation">(</span>columns<span class="token operator">=</span>columns<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># test the model</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    log_counter <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        correct <span class="token operator">=</span> <span class="token number">0</span>
        total <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> log_counter <span class="token operator">&lt;</span> NUM_BATCHES_TO_LOG<span class="token punctuation">:</span>
              log_test_predictions<span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> test_table<span class="token punctuation">,</span> log_counter<span class="token punctuation">)</span>
              log_counter <span class="token operator">+=</span> <span class="token number">1</span>
            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        acc <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total
        <span class="token comment" spellcheck="true"># ✨ W&amp;B: Log accuracy across training epochs, to visualize in the UI</span>
        wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"epoch"</span> <span class="token punctuation">:</span> epoch<span class="token punctuation">,</span> <span class="token string">"acc"</span> <span class="token punctuation">:</span> acc<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test Accuracy of the model on the 10000 test images: {} %'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>acc<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># ✨ W&amp;B: Log predictions table to wandb</span>
    wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"test_predictions"</span> <span class="token punctuation">:</span> test_table<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># ✨ W&amp;B: Mark the run as complete (useful for multi-cell notebook)</span>
wandb<span class="token punctuation">.</span>finish<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="Tune-hyperparameters"><a href="#Tune-hyperparameters" class="headerlink" title="Tune hyperparameters"></a>Tune hyperparameters</h2><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W&amp;B.ipynb">在此处试用 Colab Notebook →</a></p>
<p>在高维超参数空间中搜索以找到性能最高的模型可能会很快变得笨拙。超参数扫描提供了一种有组织且高效的方式来进行模型大逃杀并选择最准确的模型。他们通过自动搜索超参数值的组合（例如 learning rate, batch size, number of hidden layers, optimizer type）来找到最佳值来实现这一点。</p>
<p>在本教程中，我们将了解如何使用 Weights &amp; Biases 通过 3 个简单步骤运行复杂的超参数扫描。</p>
<h3 id="Follow-along-with-a-video-tutorial"><a href="#Follow-along-with-a-video-tutorial" class="headerlink" title="Follow along with a video tutorial!"></a>Follow along with a <a target="_blank" rel="noopener" href="http://wandb.me/sweeps-video">video tutorial</a>!</h3><p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedWVKkMWw.png" alt="tune hyperparameters"></p>
<h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h3><p>首先安装实验跟踪库并设置您的免费 W&amp;B 帐户：</p>
<ol>
<li>使用 <code>pip install</code> 安装</li>
<li><code>import</code> Python 所需依赖</li>
<li><code>.login()</code> 这样您就可以将指标记录到您的项目中</li>
</ol>
<p>如果您以前从未使用过 Weights &amp; Biases，登录电话会给您一个注册帐户的链接。 W&amp;B 可免费用于个人和学术项目！</p>
<pre class=" language-bash"><code class="language-bash"><span class="token operator">!</span>pip <span class="token function">install</span> wandb -Uq
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> wandb

wandb<span class="token punctuation">.</span>login<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="Step-1️⃣-Define-the-Sweep"><a href="#Step-1️⃣-Define-the-Sweep" class="headerlink" title="Step 1️⃣. Define the Sweep"></a>Step 1️⃣. Define the Sweep</h3><p>从根本上说，Sweep 将尝试一堆超参数值的策略与评估它们的代码结合在一起。您只需要以<a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/configuration">配置</a>的形式定义您的策略。</p>
<p>当您像这样在笔记本中设置 Sweep 时，该配置对象是一个嵌套字典。当您通过命令行运行 Sweep 时，配置对象是一个 <a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/quickstart#2-sweep-config">YAML file</a>。</p>
<p>让我们一起了解 Sweep 配置的定义。我们会慢慢来，这样我们就有机会解释每个组件。在典型的 Sweep 管道中，此步骤将在单个分配中完成。</p>
<h4 id="Pick-a-method"><a href="#Pick-a-method" class="headerlink" title="Pick a method"></a>Pick a <code>method</code></h4><p>我们需要定义的第一件事是选择新参数值的 <code>method</code>。</p>
<p>我们提供以下搜索 <code>methods</code>：</p>
<ul>
<li>**<code>grid</code> Search **– 迭代超参数值的每个组合。非常有效，但计算量大。</li>
<li><strong><code>random</code> Search</strong> – 根据提供的 <code>distribution</code> 随机选择每个新组合。出乎意料的有效！</li>
<li><strong><code>bayesian</code> Search</strong> – 创建一个度量分数作为超参数函数的概率模型，并选择具有提高度量的高概率的参数。适用于少量连续参数但扩展性差。</li>
</ul>
<p><code>random</code> 方法：</p>
<pre class=" language-python"><code class="language-python">sweep_config <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'method'</span><span class="token punctuation">:</span> <span class="token string">'random'</span>
    <span class="token punctuation">}</span>
</code></pre>
<p>对于 <code>bayesian</code> Sweeps，您还需要告诉我们一些关于您的 metric 的信息。我们需要知道它的名称，以便我们可以在模型输出中找到它，我们需要知道您的目标是最小化它（例如，如果它是 squared error）还是最大化它（例如，如果它是 accuracy）。</p>
<pre class=" language-python"><code class="language-python">metric <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'name'</span><span class="token punctuation">:</span> <span class="token string">'loss'</span><span class="token punctuation">,</span>
    <span class="token string">'goal'</span><span class="token punctuation">:</span> <span class="token string">'minimize'</span>   
    <span class="token punctuation">}</span>

sweep_config<span class="token punctuation">[</span><span class="token string">'metric'</span><span class="token punctuation">]</span> <span class="token operator">=</span> metric
</code></pre>
<p>如果您没有运行 <code>bayesian</code> Sweep，则不必这样做，但无论如何将其包含在您的 <code>sweep_config</code> 中并不是一个坏主意，以防您以后改变主意。记录这样的事情也是很好的再现性实践，以防万一您或其他人在 6 个月或 6 年后回到您的 Sweep 并且不知道 <code>val_G_batch</code> 应该是高还是低。</p>
<h4 id="Name-the-hyperparameters"><a href="#Name-the-hyperparameters" class="headerlink" title="Name the hyperparameters"></a>Name the hyper<code>parameters</code></h4><p>一旦您选择了一种 <code>method</code> 来尝试超参数的新值，您需要定义这些 <code>parameters</code>是什么</p>
<p>大多数时候，这一步很简单：您只需为 <code>parameter</code> 命名并指定参数的合法 <code>values</code> 列表。</p>
<p>例如，当我们为我们的网络选择 <code>optimizer</code> 时，只有有限数量的选项。在这里，我们坚持使用两个最受欢迎的选择，<code>adam</code> 和 <code>sgd</code>。即使对于具有潜在无限选项的超参数，通常也只尝试几个选择 <code>values</code> 才有意义，就像我们在此处对隐藏层 <code>layer_size</code> 和 <code>dropout</code> 所做的那样。</p>
<pre class=" language-python"><code class="language-python">parameters_dict <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'optimizer'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token string">'values'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'adam'</span><span class="token punctuation">,</span> <span class="token string">'sgd'</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'fc_layer_size'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token string">'values'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'dropout'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
          <span class="token string">'values'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>

sweep_config<span class="token punctuation">[</span><span class="token string">'parameters'</span><span class="token punctuation">]</span> <span class="token operator">=</span> parameters_dict
</code></pre>
<p>通常情况下，有些超参数我们不想在此 Sweep 中改变，但我们仍希望在我们的 <code>sweep_config</code> 中设置它们。</p>
<p>在那种情况下，我们直接设置 <code>value</code>：</p>
<pre class=" language-python"><code class="language-python">parameters_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">'epochs'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token string">'value'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
<p>对于 <code>grid</code> 搜索，这就是您所需要的。</p>
<p>对于 <code>random</code> 搜索，参数的所有 <code>values</code> 在给定运行中被选择的可能性相同。</p>
<p>如果这样做不行，您可以改为指定命名 <code>distribution</code> 及其参数，例如 <code>normal</code> 分布的均值 <code>mu</code> 和标准差 <code>sigma</code>。</p>
<p>在<a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/configuration#distributions">此处</a>查看有关如何设置随机变量分布的更多信息。</p>
<pre class=" language-python"><code class="language-python">parameters_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true"># a flat distribution between 0 and 0.1</span>
        <span class="token string">'distribution'</span><span class="token punctuation">:</span> <span class="token string">'uniform'</span><span class="token punctuation">,</span>
        <span class="token string">'min'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token string">'max'</span><span class="token punctuation">:</span> <span class="token number">0.1</span>
      <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'batch_size'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true"># integers between 32 and 256</span>
        <span class="token comment" spellcheck="true"># with evenly-distributed logarithms </span>
        <span class="token string">'distribution'</span><span class="token punctuation">:</span> <span class="token string">'q_log_uniform_values'</span><span class="token punctuation">,</span>
        <span class="token string">'q'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
        <span class="token string">'min'</span><span class="token punctuation">:</span> <span class="token number">32</span><span class="token punctuation">,</span>
        <span class="token string">'max'</span><span class="token punctuation">:</span> <span class="token number">256</span><span class="token punctuation">,</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
<p>当我们完成后，<code>sweep_config</code> 是一个嵌套的字典，它准确地指定了我们有兴趣尝试哪些 <code>parameters</code> 以及我们将使用什么 <code>method</code> 来尝试它们。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pprint

pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>sweep_config<span class="token punctuation">)</span>
</code></pre>
<p>但这不是所有的配置选项！</p>
<p>例如，我们还提供了使用 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.06560.pdf">HyperBand</a> 调度算法 <code>early_terminate</code> 运行的选项。在<a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/configuration#stopping-criteria">这里</a>查看更多。</p>
<p>您可以在<a target="_blank" rel="noopener" href="https://docs.wandb.com/library/sweeps/configuration">此处</a>找到所有配置选项的列表，并在<a target="_blank" rel="noopener" href="https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion">此处</a>找到大量 YAML 格式的示例。</p>
<h3 id="Step-2️⃣-Initialize-the-Sweep"><a href="#Step-2️⃣-Initialize-the-Sweep" class="headerlink" title="Step 2️⃣. Initialize the Sweep"></a>Step 2️⃣. Initialize the Sweep</h3><p>一旦您定义了搜索策略，就该设置一些东西来实现它了。</p>
<p>负责我们 Sweep 的 clockwork taskmaster 被称为 <em>Sweep Controller</em>。每次运行完成时，它将发出一组新的指令来描述要执行的新运行。这些指令由实际执行运行的 <em>agents</em> 获取。</p>
<p>在典型的 Sweep 中，Controller 位于我们的机器上，而完成运行的代理位于您的机器上，如下图所示。这种分工使得只需添加更多机器来运行代理就可以非常容易地扩展 Sweeps！</p>
<p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedzlbw3vQ.png" alt="sweeps-diagram"></p>
<p>我们可以通过使用适当的 <code>sweep_config</code> 和 <code>project</code> 名称调用 <code>wandb.sweep</code> 来结束 Sweep Controller。</p>
<p>此函数返回一个 <code>sweep_id</code>，我们稍后将使用它来将 agents 分配给此 Controller。</p>
<p>旁注：在命令行上，此功能被替换为</p>
<pre class=" language-bash"><code class="language-bash">wandb sweep config.yaml
</code></pre>
<p><a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/quickstart">了解更多关于在命令行中使用 Sweeps ➡</a></p>
<pre class=" language-python"><code class="language-python">sweep_id <span class="token operator">=</span> wandb<span class="token punctuation">.</span>sweep<span class="token punctuation">(</span>sweep_config<span class="token punctuation">,</span> project<span class="token operator">=</span><span class="token string">"pytorch-sweeps-demo"</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="Step-3️⃣-Run-the-Sweep-agent"><a href="#Step-3️⃣-Run-the-Sweep-agent" class="headerlink" title="Step 3️⃣. Run the Sweep agent"></a>Step 3️⃣. Run the Sweep agent</h3><h4 id="Define-Your-Training-Procedure"><a href="#Define-Your-Training-Procedure" class="headerlink" title="Define Your Training Procedure"></a>Define Your Training Procedure</h4><p>在我们实际执行 sweep 之前，我们需要定义使用这些值的训练过程。</p>
<p>在下面的函数中，我们在 PyTorch 中定义了一个简单的全连接神经网络，并添加了以下 <code>wandb</code> 工具来记录模型指标、可视化性能和输出并跟踪我们的实验：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://docs.wandb.com/library/init"><strong><code>wandb.init()</code></strong></a> – 初始化新的 W&amp;B 运行。每次运行都是训练功能的一次执行。</li>
<li><a target="_blank" rel="noopener" href="https://docs.wandb.com/library/config"><strong><code>wandb.config</code></strong></a> – 将所有超参数保存在配置对象中，以便记录它们。在<a target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-config/Configs_in_W%26B.ipynb">此处</a>阅读有关如何使用 <code>wandb.config</code> 的更多信息。</li>
<li><a target="_blank" rel="noopener" href="https://docs.wandb.com/library/log"><strong><code>wandb.log()</code></strong></a> – 将模型行为记录到 W&amp;B。在这里，我们只记录性能；有关可以使用 <code>wandb.log</code> 记录的所有其他富媒体，请参阅此 <a target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Log_(Almost)_Anything_with_W%26B_Media.ipynb">Colab</a>。</li>
</ul>
<p>有关使用 PyTorch 检测 W&amp;B 的更多详细信息，请参阅此 <a target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb">Colab</a>。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms

device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>config<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># Initialize a new wandb run</span>
    <span class="token keyword">with</span> wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>config<span class="token operator">=</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># If called by wandb.agent, as below,</span>
        <span class="token comment" spellcheck="true"># this config will be set by Sweep Controller</span>
        config <span class="token operator">=</span> wandb<span class="token punctuation">.</span>config

        loader <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        network <span class="token operator">=</span> build_network<span class="token punctuation">(</span>config<span class="token punctuation">.</span>fc_layer_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>
        optimizer <span class="token operator">=</span> build_optimizer<span class="token punctuation">(</span>network<span class="token punctuation">,</span> config<span class="token punctuation">.</span>optimizer<span class="token punctuation">,</span> config<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span>

        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>config<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            avg_loss <span class="token operator">=</span> train_epoch<span class="token punctuation">(</span>network<span class="token punctuation">,</span> loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span>
            wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"loss"</span><span class="token punctuation">:</span> avg_loss<span class="token punctuation">,</span> <span class="token string">"epoch"</span><span class="token punctuation">:</span> epoch<span class="token punctuation">}</span><span class="token punctuation">)</span>           
</code></pre>
<p>这个单元格定义了我们训练过程的四个部分：<code>build_dataset</code>, <code>build_network</code>, <code>build_optimizer</code> 和<code>train_epoch</code>.</p>
<p>所有这些都是基本 PyTorch 管道的标准部分，它们的实现不受使用 W&amp;B 的影响，因此我们不会对它们发表评论。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_dataset</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
   
    transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># download MNIST training dataset</span>
    dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                             transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
    sub_dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Subset<span class="token punctuation">(</span>
        dataset<span class="token punctuation">,</span> indices<span class="token operator">=</span>range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>sub_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>

    <span class="token keyword">return</span> loader


<span class="token keyword">def</span> <span class="token function">build_network</span><span class="token punctuation">(</span>fc_layer_size<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
    network <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>  <span class="token comment" spellcheck="true"># fully-connected, single hidden layer</span>
        nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> fc_layer_size<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>fc_layer_size<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> network<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        

<span class="token keyword">def</span> <span class="token function">build_optimizer</span><span class="token punctuation">(</span>network<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> optimizer <span class="token operator">==</span> <span class="token string">"sgd"</span><span class="token punctuation">:</span>
        optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>network<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                              lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> optimizer <span class="token operator">==</span> <span class="token string">"adam"</span><span class="token punctuation">:</span>
        optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>network<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                               lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>
    <span class="token keyword">return</span> optimizer


<span class="token keyword">def</span> <span class="token function">train_epoch</span><span class="token punctuation">(</span>network<span class="token punctuation">,</span> loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    cumu_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> _<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data<span class="token punctuation">,</span> target <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># ➡ Forward pass</span>
        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>network<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span>
        cumu_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># ⬅ Backward pass + weight update</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"batch loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> cumu_loss <span class="token operator">/</span> len<span class="token punctuation">(</span>loader<span class="token punctuation">)</span>
</code></pre>
<p>现在，我们准备开始 sweeping 了！</p>
<p>Sweep Controllers，就像我们通过运行 <code>wandb.sweep</code> 制作的控制器一样，坐等有人要求他们提供 <code>config </code>来试用。</p>
<p>某人是 <code>agent</code>，他们是用 <code>wandb.agent</code> 创建的。要开始，agent 只需要知道</p>
<ol>
<li>它是 (<code>sweep_id</code>) 的一部分</li>
<li>它应该运行哪个函数（这里是 <code>train</code>）</li>
<li>（可选）有多少配置要求控制器（<code>count</code>）</li>
</ol>
<p>仅供参考，您可以在不同的计算资源上启动具有相同 <code>sweep_id</code> 的多个 <code>agent</code>，Controller 将确保它们根据 <code>sweep_config</code> 中制定的策略协同工作。这使得在尽可能多的节点上扩展 Sweeps 变得轻而易举！</p>
<p>旁注：在命令行上，此功能被替换为</p>
<pre class=" language-bash"><code class="language-bash">wandb agent sweep_id
</code></pre>
<p><a target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/quickstart">了解更多关于在命令行中使用 Sweeps ➡</a></p>
<p>下面的单元格将启动一个运行 <code>train</code> 5 次的 <code>agent</code>，使用 Sweep Controller 返回的随机生成的超参数值。执行时间不到 5 分钟。</p>
<pre class=" language-python"><code class="language-python">wandb<span class="token punctuation">.</span>agent<span class="token punctuation">(</span>sweep_id<span class="token punctuation">,</span> train<span class="token punctuation">,</span> count<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="Visualize-Sweep-Results"><a href="#Visualize-Sweep-Results" class="headerlink" title="Visualize Sweep Results"></a>Visualize Sweep Results</h3><h4 id="Parallel-Coordinates-Plot"><a href="#Parallel-Coordinates-Plot" class="headerlink" title="Parallel Coordinates Plot"></a>Parallel Coordinates Plot</h4><p>此图将超参数值映射到模型指标。它对于磨练导致最佳模型性能的超参数组合很有用。</p>
<p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefined5e190366778ad831455f9af2_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695138341_image.png" alt="hyperparameters map to metrics"></p>
<h4 id="Hyperparameter-Importance-Plot"><a href="#Hyperparameter-Importance-Plot" class="headerlink" title="Hyperparameter Importance Plot"></a>Hyperparameter Importance Plot</h4><p>超参数重要性图表明哪些超参数是指标的最佳预测因子。我们报告特征重要性（来自随机森林模型）和相关性（隐式线性模型）。</p>
<p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefined5e190367778ad820b35f9af5_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695757573_image.png" alt="parameter importance"></p>
<p>这些可视化可以通过磨练最重要的参数（和值范围）来帮助您节省运行昂贵的超参数优化的时间和资源，因此值得进一步探索。</p>
<h3 id="Get-your-hands-dirty-with-sweeps"><a href="#Get-your-hands-dirty-with-sweeps" class="headerlink" title="Get your hands dirty with sweeps"></a>Get your hands dirty with sweeps</h3><p>我们创建了一个简单的训练脚本和一些 <a target="_blank" rel="noopener" href="https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion">sweep configs</a> 风格供您使用。我们强烈建议您尝试一下。</p>
<p>该存储库还提供了一些示例，可帮助您尝试更高级的 sweep 功能，例如 <a target="_blank" rel="noopener" href="https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/us0ifmrf?workspace=user-lavanyashukla&amp;_gl=1*1h57q6p*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjYyMjIyOS43LjAuMTY4NjYyMjIyOS42MC4wLjA.">Bayesian Hyperband</a> 和 <a target="_blank" rel="noopener" href="https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/xbs2wm5e?workspace=user-lavanyashukla&amp;_gl=1*5hk37j*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjYyMjIyOS43LjAuMTY4NjYyMjIyOS42MC4wLjA.">Hyperopt</a>。</p>
<h2 id="Track-models-and-datasets"><a href="#Track-models-and-datasets" class="headerlink" title="Track models and datasets"></a>Track models and datasets</h2><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-artifacts/Pipeline_Versioning_with_W&amp;B_Artifacts.ipynb">在此处试用 Colab Notebook →</a></p>
<p>在此笔记本中，我们将向您展示如何使用 W&amp;B Artifacts 跟踪您的 ML 实验管道。</p>
<h4 id="Follow-along-with-a-video-tutorial-1"><a href="#Follow-along-with-a-video-tutorial-1" class="headerlink" title="Follow along with a video tutorial!"></a>Follow along with a <a target="_blank" rel="noopener" href="http://tiny.cc/wb-artifacts-video">video tutorial</a>!</h4><h5 id="What-are-Artifacts-and-Why-Should-I-Care"><a href="#What-are-Artifacts-and-Why-Should-I-Care" class="headerlink" title="What are Artifacts and Why Should I Care?"></a>What are Artifacts and Why Should I Care?</h5><p>“artifact”，如希腊双耳瓶🏺，是一个生产的对象——一个过程的输出。在 ML 中，最重要的工件是 <em>datasets</em> 和 <em>models</em>。</p>
<p>而且，就像 <a target="_blank" rel="noopener" href="https://indianajones.fandom.com/wiki/Cross_of_Coronado">Cross of Coronado</a> 一样，这些重要的文物属于博物馆！也就是说，应该对它们进行分类和组织，以便您、您的团队和整个 ML 社区可以向它们学习。毕竟，那些不跟踪训练的人注定要重蹈覆辙。</p>
<p>使用我们的 Artifacts API，您可以将 <code>Artifacts</code> 记录为 W&amp;B <code>Runs</code> 的输出，或使用 <code>Artifacts</code> 作为 <code>Runs</code> 的输入，如此图所示，其中训练运行接受数据集并生成模型。</p>
<p><img src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedsimple%20artifact%20diagram%202.png" alt="simple artifact diagram"></p>
<p>由于一次运行可以使用另一次的输出作为输入，因此 Artifacts 和 Runs 一起形成了一个有向图——实际上是一个二分 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a>！ – 带有 <code>Artifact</code>s 和 <code>Run</code>s 的节点，以及将 <code>Run</code>s 连接到它们消耗或生产的 <code>Artifact</code>s 的箭头。</p>
<h3 id="0️⃣-Install-and-Import"><a href="#0️⃣-Install-and-Import" class="headerlink" title="0️⃣ Install and Import"></a>0️⃣ Install and Import</h3><p>Artifacts 是我们 Python 库的一部分，从 <code>0.9.2</code> 版开始。</p>
<p>与 ML Python 堆栈的大多数部分一样，它可以通过 <code>pip</code> 获得。</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Compatible with wandb version 0.9.2+</span>
!pip install wandb <span class="token operator">-</span>qqq
!apt install tree
</code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> wandb
</code></pre>
<h3 id="1️⃣-Log-a-Dataset"><a href="#1️⃣-Log-a-Dataset" class="headerlink" title="1️⃣ Log a Dataset"></a>1️⃣ Log a Dataset</h3><p>首先，让我们定义一些 Artifacts。</p>
<p>此示例基于此 PyTorch <a target="_blank" rel="noopener" href="https://github.com/pytorch/examples/tree/master/mnist/">“Basic MNIST Example”</a>，但可以在 <a target="_blank" rel="noopener" href="http://wandb.me/artifacts-colab">TensorFlow</a>、任何其他框架或纯 Python 中轻松完成。</p>
<p>我们从 <code>Dataset</code>s 开始：</p>
<ul>
<li>一个 <code>train</code>ing set，用于选择参数，</li>
<li>一个 <code>validation</code> set，用于选择超参数，</li>
<li>一个 <code>test</code>ing set，用于评估最终模型</li>
</ul>
<p>下面的第一个单元格定义了这三个数据集。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> random 

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> TensorDataset
<span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>auto <span class="token keyword">import</span> tqdm

<span class="token comment" spellcheck="true"># Ensure deterministic behavior</span>
torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>
random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Device configuration</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Data parameters</span>
num_classes <span class="token operator">=</span> <span class="token number">10</span>
input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># drop slow mirror from list of MNIST mirrors</span>
torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">.</span>mirrors <span class="token operator">=</span> <span class="token punctuation">[</span>mirror <span class="token keyword">for</span> mirror <span class="token keyword">in</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">.</span>mirrors
                                      <span class="token keyword">if</span> <span class="token operator">not</span> mirror<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"http://yann.lecun.com"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">load</span><span class="token punctuation">(</span>train_size<span class="token operator">=</span>50_000<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    # Load the data
    """</span>

    <span class="token comment" spellcheck="true"># the data, split between train and test sets</span>
    train <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">"./"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">"./"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">(</span>train<span class="token punctuation">.</span>data<span class="token punctuation">,</span> train<span class="token punctuation">.</span>targets<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>test<span class="token punctuation">.</span>data<span class="token punctuation">,</span> test<span class="token punctuation">.</span>targets<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># split off a validation set for hyperparameter tuning</span>
    x_train<span class="token punctuation">,</span> x_val <span class="token operator">=</span> x_train<span class="token punctuation">[</span><span class="token punctuation">:</span>train_size<span class="token punctuation">]</span><span class="token punctuation">,</span> x_train<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span><span class="token punctuation">]</span>
    y_train<span class="token punctuation">,</span> y_val <span class="token operator">=</span> y_train<span class="token punctuation">[</span><span class="token punctuation">:</span>train_size<span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span><span class="token punctuation">]</span>

    training_set <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
    validation_set <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_val<span class="token punctuation">,</span> y_val<span class="token punctuation">)</span>
    test_set <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>

    datasets <span class="token operator">=</span> <span class="token punctuation">[</span>training_set<span class="token punctuation">,</span> validation_set<span class="token punctuation">,</span> test_set<span class="token punctuation">]</span>

    <span class="token keyword">return</span> datasets
</code></pre>
<p>这建立了一个模式，我们将在这个例子中看到重复：将数据记录为工件的代码包裹在生成该数据的代码周围。在这种情况下，用于 <code>load</code>ing 数据的代码与用于 <code>load_and_log</code>ging 数据的代码分开。</p>
<p>这是很好的做法！</p>
<p>为了将这些数据集记录为工件，我们只需要</p>
<ol>
<li>使用 <code>wandb.init</code> 创建 <code>Run</code>，(L4)</li>
<li>为数据集 (L10) 创建一个 <code>Artifact</code>，以及</li>
<li>保存并记录相关 <code>file</code>s（L20、L23）。</li>
</ol>
<p>查看下面代码单元的示例，然后展开后面的部分以了解更多详细信息。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_and_log</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment" spellcheck="true"># 🚀 start a run, with a type to label it and a project it can call home</span>
    <span class="token keyword">with</span> wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>project<span class="token operator">=</span><span class="token string">"artifacts-example"</span><span class="token punctuation">,</span> job_type<span class="token operator">=</span><span class="token string">"load-data"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> run<span class="token punctuation">:</span>
        
        datasets <span class="token operator">=</span> load<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># separate code for loading the datasets</span>
        names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"training"</span><span class="token punctuation">,</span> <span class="token string">"validation"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">]</span>

        <span class="token comment" spellcheck="true"># 🏺 create our Artifact</span>
        raw_data <span class="token operator">=</span> wandb<span class="token punctuation">.</span>Artifact<span class="token punctuation">(</span>
            <span class="token string">"mnist-raw"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"dataset"</span><span class="token punctuation">,</span>
            description<span class="token operator">=</span><span class="token string">"Raw MNIST dataset, split into train/val/test"</span><span class="token punctuation">,</span>
            metadata<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"source"</span><span class="token punctuation">:</span> <span class="token string">"torchvision.datasets.MNIST"</span><span class="token punctuation">,</span>
                      <span class="token string">"sizes"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>len<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token keyword">for</span> dataset <span class="token keyword">in</span> datasets<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> name<span class="token punctuation">,</span> data <span class="token keyword">in</span> zip<span class="token punctuation">(</span>names<span class="token punctuation">,</span> datasets<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 🐣 Store a new file in the artifact, and write something into its contents.</span>
            <span class="token keyword">with</span> raw_data<span class="token punctuation">.</span>new_file<span class="token punctuation">(</span>name <span class="token operator">+</span> <span class="token string">".pt"</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file<span class="token punctuation">:</span>
                x<span class="token punctuation">,</span> y <span class="token operator">=</span> data<span class="token punctuation">.</span>tensors
                torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">,</span> file<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># ✍️ Save the artifact to W&amp;B.</span>
        run<span class="token punctuation">.</span>log_artifact<span class="token punctuation">(</span>raw_data<span class="token punctuation">)</span>

load_and_log<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="🚀-wandb-init"><a href="#🚀-wandb-init" class="headerlink" title="🚀 wandb.init"></a>🚀 <code>wandb.init</code></h4><p>当我们制作将要产生 <code>Artifact</code>s 的 <code>Run</code>时，我们需要说明它属于哪个 <code>project</code>。</p>
<p>根据您的工作流程，项目可能大到 <code>car-that-drives-itself</code>，也可能小到 <code>iterative-architecture-experiment-117</code>。</p>
<p>Depending on your workflow, a project might be as big as <code>car-that-drives-itself</code> or as small as <code>iterative-architecture-experiment-117</code>.</p>
<blockquote>
<p>👍规则：如果可以，请将所有共享 <code>Artifact</code>s 的 <code>Run</code>s 保留在一个项目中。这使事情变得简单，但不要担心 <code>Artifact</code>s 可以跨项目移植！</p>
</blockquote>
<p>为了帮助跟踪您可能运行的所有不同类型的作业，在进行 <code>Run</code>s 时提供 <code>job_type</code> 很有用。这可以使您的 Artifacts 图表保持整洁。</p>
<blockquote>
<p>👍规则：<code>job_type</code> 应该是描述性的，并且对应于你的管道的单个步骤。在这里，我们将 <code>load</code>ing 数据与 <code>preprocess</code>ing 数据分开。</p>
</blockquote>
<h4 id="🏺-wandb-Artifact"><a href="#🏺-wandb-Artifact" class="headerlink" title="🏺 wandb.Artifact"></a>🏺 <code>wandb.Artifact</code></h4><p>要将某物记录为 <code>Artifact</code>，我们必须首先创建一个 <code>Artifact</code> 对象。</p>
<p>每个 <code>Artifact</code> 都有一个 <code>name</code>——这是第一个参数设置的名称。</p>
<blockquote>
<p>👍的规则：<code>name</code> 应该是描述性的，但易于记忆和输入——我们喜欢使用连字符分隔的名称，并与代码中的变量名相对应。</p>
</blockquote>
<p>它也有一个 <code>type</code>。就像 <code>Run</code>s 的 <code>job_types</code> 一样，它用于组织 <code>Run</code>s 和 <code>Artifact</code>s 的图表。</p>
<blockquote>
<p>👍的规则：<code>type</code> 应该简单：比 <code>mnist-data-YYYYMMDD</code> 更像 <code>dataset</code> 或 <code>model</code>。</p>
</blockquote>
<p>您还可以附加 <code>description</code> 和一些 <code>metadata</code>，作为字典。<code>metadata</code> 只需要可序列化为 JSON。</p>
<blockquote>
<p>👍规则：<code>metadata</code>应尽可能具有描述性。</p>
</blockquote>
<h4 id="🐣-artifact-new-file-and-✍️-run-log-artifact"><a href="#🐣-artifact-new-file-and-✍️-run-log-artifact" class="headerlink" title="🐣 artifact.new_file and ✍️ run.log_artifact"></a>🐣 <code>artifact.new_file</code> and ✍️ <code>run.log_artifact</code></h4><p>一旦我们创建了一个 <code>Artifact</code> 对象，我们需要向它添加文件。</p>
<p>您没看错：带有 s 的 <em>files</em>。<code>Artifact</code>s 的结构类似于目录，包含文件和子目录。</p>
<blockquote>
<p>👍规则：只要有必要，将 <code>Artifact</code> 的内容拆分为多个文件。如果需要扩展，这将有所帮助！</p>
</blockquote>
<p>我们使用 <code>new_file</code> 方法同时写入文件并将其附加到 <code>Artifact</code>。下面，我们将使用 <code>add_file</code> 方法，它将这两个步骤分开</p>
<p>添加完所有文件后，我们需要将 <code>log_artifact</code> 添加到 <a target="_blank" rel="noopener" href="https://wandb.ai/?_gl=1*r07jdw*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjY1MzgzNC45LjEuMTY4NjY1MzgzOS41NS4wLjA.">wandb.ai</a>。</p>
<p>您会注意到一些 URL 出现在输出中，包括一个用于运行页面的 URL。您可以在此处查看 <code>Run</code> 结果，包括已记录的任何 <code>Artifact</code>s。</p>
<p>我们将在下面看到一些示例，这些示例可以更好地利用“运行”页面的其他组件。</p>
<h3 id="2️⃣-Use-a-Logged-Dataset-Artifact"><a href="#2️⃣-Use-a-Logged-Dataset-Artifact" class="headerlink" title="2️⃣ Use a Logged Dataset Artifact"></a>2️⃣ Use a Logged Dataset Artifact</h3><p>与博物馆中的 artifacts 不同，W&amp;B 中的 <code>Artifact</code>s 旨在使用，而不仅仅是存储。</p>
<p>让我们看看它是什么样的。</p>
<p>下面的单元格定义了一个管道步骤，该步骤接收原始数据集并使用它来生成 <code>preprocess</code>ed  数据集：<code>normalize</code>d 和正确整形。</p>
<p>再次注意，我们从与 <code>wandb</code> 接口的代码中分离出了代码的主体，即 <code>preprocess</code>。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> expand_dims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    ## Prepare the data
    """</span>
    x<span class="token punctuation">,</span> y <span class="token operator">=</span> dataset<span class="token punctuation">.</span>tensors

    <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Scale images to the [0, 1] range</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>

    <span class="token keyword">if</span> expand_dims<span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># Make sure images have shape (1, 28, 28)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> TensorDataset<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
</code></pre>
<p>现在是使用 <code>wandb.Artifact</code> 日志记录这个 <code>preprocess</code> 步骤的代码。</p>
<p>请注意，下面的示例都 <code>use</code>s 了一个新的 <code>Artifact</code>，并将其 <code>log</code>s 下来，这与上一步相同。<code>Artifact</code>s 既是 <code>Run</code>s 的输入又是输出！</p>
<p>我们使用一个新的 <code>job_type</code>，<code>preprocess-data</code>，来明确这是一个不同于之前的 job。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">preprocess_and_log</span><span class="token punctuation">(</span>steps<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">with</span> wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>project<span class="token operator">=</span><span class="token string">"artifacts-example"</span><span class="token punctuation">,</span> job_type<span class="token operator">=</span><span class="token string">"preprocess-data"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> run<span class="token punctuation">:</span>

        processed_data <span class="token operator">=</span> wandb<span class="token punctuation">.</span>Artifact<span class="token punctuation">(</span>
            <span class="token string">"mnist-preprocess"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"dataset"</span><span class="token punctuation">,</span>
            description<span class="token operator">=</span><span class="token string">"Preprocessed MNIST dataset"</span><span class="token punctuation">,</span>
            metadata<span class="token operator">=</span>steps<span class="token punctuation">)</span>
         
        <span class="token comment" spellcheck="true"># ✔️ declare which artifact we'll be using</span>
        raw_data_artifact <span class="token operator">=</span> run<span class="token punctuation">.</span>use_artifact<span class="token punctuation">(</span><span class="token string">'mnist-raw:latest'</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 📥 if need be, download the artifact</span>
        raw_dataset <span class="token operator">=</span> raw_data_artifact<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token keyword">for</span> split <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"training"</span><span class="token punctuation">,</span> <span class="token string">"validation"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            raw_split <span class="token operator">=</span> read<span class="token punctuation">(</span>raw_dataset<span class="token punctuation">,</span> split<span class="token punctuation">)</span>
            processed_dataset <span class="token operator">=</span> preprocess<span class="token punctuation">(</span>raw_split<span class="token punctuation">,</span> <span class="token operator">**</span>steps<span class="token punctuation">)</span>

            <span class="token keyword">with</span> processed_data<span class="token punctuation">.</span>new_file<span class="token punctuation">(</span>split <span class="token operator">+</span> <span class="token string">".pt"</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file<span class="token punctuation">:</span>
                x<span class="token punctuation">,</span> y <span class="token operator">=</span> processed_dataset<span class="token punctuation">.</span>tensors
                torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">,</span> file<span class="token punctuation">)</span>

        run<span class="token punctuation">.</span>log_artifact<span class="token punctuation">(</span>processed_data<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">read</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> split<span class="token punctuation">)</span><span class="token punctuation">:</span>
    filename <span class="token operator">=</span> split <span class="token operator">+</span> <span class="token string">".pt"</span>
    x<span class="token punctuation">,</span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> filename<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> TensorDataset<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
</code></pre>
<p>这里要注意的一件事是预处理的 <code>steps</code> 作为 <code>metadata</code> 与 <code>preprocessed_data</code> 一起保存。</p>
<p>如果您想让您的实验可重现，捕获大量元数据是个好主意！</p>
<p>此外，即使我们的数据集是 “<code>large artifact</code>“，<code>download</code> 步骤也可以在不到一秒的时间内完成。</p>
<p>展开下面的 markdown 单元格以了解详细信息。</p>
<pre class=" language-python"><code class="language-python">steps <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"normalize"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
         <span class="token string">"expand_dims"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span>

preprocess_and_log<span class="token punctuation">(</span>steps<span class="token punctuation">)</span>
</code></pre>
<h4 id="✔️-run-use-artifact"><a href="#✔️-run-use-artifact" class="headerlink" title="✔️ run.use_artifact"></a>✔️ <code>run.use_artifact</code></h4><p>这些步骤比较简单。消费者只需要知道 <code>Artifact</code> 的<code>name</code>，再加上 bit more。</p>
<p>“bit more” 是您想要的 <code>Artifact</code> 的特定版本的 <code>alias</code>。</p>
<p>默认情况下，最后上传的版本被标记为<code>latest</code>。否则，您可以选择带有 <code>v0</code>/<code>v1</code> 等的旧版本，或者您可以提供自己的别名，例如 <code>best</code> 或 <code>jit-script</code>。就像 <a target="_blank" rel="noopener" href="https://hub.docker.com/">Docker Hub</a> 标签一样，别名与名称用 <code>:</code> 分隔，所以我们想要的 <code>Artifact</code> 是 <code>mnist-raw:latest</code>。</p>
<blockquote>
<p>👍规则：保持别名简短而甜美。当您想要满足某些属性的 <code>Artifact</code> 时，请使用自定义 <code>alias</code>es，如 <code>latest</code> 或 <code>best</code></p>
</blockquote>
<h4 id="📥-artifact-download"><a href="#📥-artifact-download" class="headerlink" title="📥 artifact.download"></a>📥 <code>artifact.download</code></h4><p>现在，您可能正在担心 <code>download</code> 调用。如果我们再下载一份，内存的负担会不会加倍？</p>
<p>别担心，朋友。在我们实际下载任何东西之前，我们会检查本地是否有正确的版本。使用和版本控制 <code>git</code> 和 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Torrent_file">torrenting</a> 相同的技术：hashing。</p>
<p>随着 <code>Artifact</code>s 的创建和记录，工作目录中名为 <code>artifacts</code> 的文件夹将开始填充子目录，每个 <code>Artifact</code>一个。使用  <code>!tree artifacts</code> 检查其内容：</p>
<pre class=" language-python"><code class="language-python">!tree artifacts
</code></pre>
<h4 id="🌐-The-Artifacts-page-on-wandb-ai"><a href="#🌐-The-Artifacts-page-on-wandb-ai" class="headerlink" title="🌐 The Artifacts page on wandb.ai"></a>🌐 The Artifacts page on <a target="_blank" rel="noopener" href="https://wandb.ai/">wandb.ai</a></h4><p>现在我们已经记录并使用了一个 <code>Artifact</code>，让我们检查一下 Run 页面上的 Artifacts 选项卡。</p>
<p>从<code> wandb</code> 输出导航到运行页面 URL，然后从左侧边栏中选择“工件”选项卡（它是带有数据库图标的选项卡，看起来像三个冰球叠在一起）。</p>
<p>单击 “Input Artifacts” 表或 “Output Artifacts” 表中的一行，然后查看选项卡（”Overview”, “Metadata”）以查看记录的有关 <code>Artifact</code> 的所有内容。</p>
<p>我们特别喜欢 “Graph View”。默认情况下，它显示一个图表，其中 <code>Artifact</code>s 的 <code>type</code>s 和 <code>Run</code> 的 <code>job_types</code> 是两种类型的节点，箭头代表消费和生产。</p>
<h3 id="3️⃣-Log-a-Model"><a href="#3️⃣-Log-a-Model" class="headerlink" title="3️⃣ Log a Model"></a>3️⃣ Log a Model</h3><p>这足以了解 <code>Artifact</code>s 的 API 如何工作，但让我们按照这个示例一直到管道的末尾，以便我们可以了解 <code>Artifact</code>s 如何改进您的 ML 工作流程。</p>
<p>这里的第一个单元格在 PyTorch 中构建了一个 DNN <code>model</code>——一个非常简单的 ConvNet。</p>
<p>我们将从初始化 <code>model</code> 开始，而不是训练它。这样，我们可以重复训练，同时保持其他一切不变。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> math <span class="token keyword">import</span> floor

<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn

<span class="token keyword">class</span> <span class="token class-name">ConvNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_layer_sizes<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  kernel_sizes<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  activation<span class="token operator">=</span><span class="token string">"ReLU"</span><span class="token punctuation">,</span>
                  pool_sizes<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>
                  num_classes<span class="token operator">=</span>num_classes<span class="token punctuation">,</span>
                  input_shape<span class="token operator">=</span>input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
      
        super<span class="token punctuation">(</span>ConvNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
              nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>hidden_layer_sizes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>kernel_sizes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              getattr<span class="token punctuation">(</span>nn<span class="token punctuation">,</span> activation<span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span>pool_sizes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
              nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>hidden_layer_sizes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span>hidden_layer_sizes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>kernel_sizes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              getattr<span class="token punctuation">(</span>nn<span class="token punctuation">,</span> activation<span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span>pool_sizes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
              nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        fc_input_dims <span class="token operator">=</span> floor<span class="token punctuation">(</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> kernel_sizes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> pool_sizes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># layer 1 output size</span>
        fc_input_dims <span class="token operator">=</span> floor<span class="token punctuation">(</span><span class="token punctuation">(</span>fc_input_dims <span class="token operator">-</span> kernel_sizes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> pool_sizes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># layer 2 output size</span>
        fc_input_dims <span class="token operator">=</span> fc_input_dims<span class="token operator">*</span>fc_input_dims<span class="token operator">*</span>hidden_layer_sizes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># layer 3 output size</span>

        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>fc_input_dims<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre>
<p>在这里，我们使用 W&amp;B 来跟踪运行，因此使用 <code>wandb.config</code> 对象来存储所有超参数。</p>
<p>该 <code>config</code> 对象的 <code>dict</code>ionary 版本是一个非常有用的 <code>metadata</code>，所以一定要包含它！</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_model_and_log</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>project<span class="token operator">=</span><span class="token string">"artifacts-example"</span><span class="token punctuation">,</span> job_type<span class="token operator">=</span><span class="token string">"initialize"</span><span class="token punctuation">,</span> config<span class="token operator">=</span>config<span class="token punctuation">)</span> <span class="token keyword">as</span> run<span class="token punctuation">:</span>
        config <span class="token operator">=</span> wandb<span class="token punctuation">.</span>config
        
        model <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span><span class="token operator">**</span>config<span class="token punctuation">)</span>

        model_artifact <span class="token operator">=</span> wandb<span class="token punctuation">.</span>Artifact<span class="token punctuation">(</span>
            <span class="token string">"convnet"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"model"</span><span class="token punctuation">,</span>
            description<span class="token operator">=</span><span class="token string">"Simple AlexNet style CNN"</span><span class="token punctuation">,</span>
            metadata<span class="token operator">=</span>dict<span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">)</span>

        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"initialized_model.pth"</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># ➕ another way to add a file to an Artifact</span>
        model_artifact<span class="token punctuation">.</span>add_file<span class="token punctuation">(</span><span class="token string">"initialized_model.pth"</span><span class="token punctuation">)</span>

        wandb<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"initialized_model.pth"</span><span class="token punctuation">)</span>

        run<span class="token punctuation">.</span>log_artifact<span class="token punctuation">(</span>model_artifact<span class="token punctuation">)</span>

model_config <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"hidden_layer_sizes"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token string">"kernel_sizes"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token string">"activation"</span><span class="token punctuation">:</span> <span class="token string">"ReLU"</span><span class="token punctuation">,</span>
                <span class="token string">"pool_sizes"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token string">"dropout"</span><span class="token punctuation">:</span> <span class="token number">0.5</span><span class="token punctuation">,</span>
                <span class="token string">"num_classes"</span><span class="token punctuation">:</span> <span class="token number">10</span><span class="token punctuation">}</span>

build_model_and_log<span class="token punctuation">(</span>model_config<span class="token punctuation">)</span>
</code></pre>
<h4 id="➕-artifact-add-file"><a href="#➕-artifact-add-file" class="headerlink" title="➕ artifact.add_file"></a>➕ <code>artifact.add_file</code></h4><p>与在数据集日志记录示例中同时编写 <code>new_file</code> 并将其添加到 <code>Artifact</code> 不同，我们还可以一步写入文件（此处为 <code>torch.save</code>），然后在另一步中将它们 <code>add</code> 到 <code>Artifact</code>。</p>
<blockquote>
<p>👍规则：尽可能使用 <code>new_file</code>，以防止重复。</p>
</blockquote>
<h3 id="4️⃣-Use-a-Logged-Model-Artifact"><a href="#4️⃣-Use-a-Logged-Model-Artifact" class="headerlink" title="4️⃣ Use a Logged Model Artifact"></a>4️⃣ Use a Logged Model Artifact</h3><p>就像我们可以在 <code>dataset</code> 上调用 <code>use_artifact</code> 一样，我们可以在我们的 <code>initialized_model</code> 上调用它以在另一个运行中使用它。</p>
<p>这一次，让我们 <code>train</code> <code>model</code>。</p>
<p>有关更多详细信息，请查看我们关于 <a target="_blank" rel="noopener" href="http://wandb.me/pytorch-colab">instrumenting W&amp;B with PyTorch</a> 的 Colab。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> valid_loader<span class="token punctuation">,</span> config<span class="token punctuation">)</span><span class="token punctuation">:</span>
    optimizer <span class="token operator">=</span> getattr<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>optimizer<span class="token punctuation">)</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    example_ct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>config<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            data<span class="token punctuation">,</span> target <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

            example_ct <span class="token operator">+=</span> len<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

            <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> config<span class="token punctuation">.</span>batch_log_interval <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train Epoch: {} [{}/{} ({:.0%})]\tLoss: {:.6f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>
                    epoch<span class="token punctuation">,</span> batch_idx <span class="token operator">*</span> len<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>train_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    batch_idx <span class="token operator">/</span> len<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                
                train_log<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> example_ct<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># evaluate the model on the validation set at each epoch</span>
        loss<span class="token punctuation">,</span> accuracy <span class="token operator">=</span> test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> valid_loader<span class="token punctuation">)</span>  
        test_log<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> accuracy<span class="token punctuation">,</span> example_ct<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>

    
<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    test_loss <span class="token operator">=</span> <span class="token number">0</span>
    correct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> data<span class="token punctuation">,</span> target <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            data<span class="token punctuation">,</span> target <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
            test_loss <span class="token operator">+=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># sum up batch loss</span>
            pred <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># get the index of the max log-probability</span>
            correct <span class="token operator">+=</span> pred<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>target<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>

    test_loss <span class="token operator">/=</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

    accuracy <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">.</span> <span class="token operator">*</span> correct <span class="token operator">/</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> test_loss<span class="token punctuation">,</span> accuracy


<span class="token keyword">def</span> <span class="token function">train_log</span><span class="token punctuation">(</span>loss<span class="token punctuation">,</span> example_ct<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> float<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># where the magic happens</span>
    wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"epoch"</span><span class="token punctuation">:</span> epoch<span class="token punctuation">,</span> <span class="token string">"train/loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">}</span><span class="token punctuation">,</span> step<span class="token operator">=</span>example_ct<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Loss after "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>example_ct<span class="token punctuation">)</span><span class="token punctuation">.</span>zfill<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token operator">+</span> f<span class="token string">" examples: {loss:.3f}"</span><span class="token punctuation">)</span>
    

<span class="token keyword">def</span> <span class="token function">test_log</span><span class="token punctuation">(</span>loss<span class="token punctuation">,</span> accuracy<span class="token punctuation">,</span> example_ct<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> float<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
    accuracy <span class="token operator">=</span> float<span class="token punctuation">(</span>accuracy<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># where the magic happens</span>
    wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"epoch"</span><span class="token punctuation">:</span> epoch<span class="token punctuation">,</span> <span class="token string">"validation/loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span> <span class="token string">"validation/accuracy"</span><span class="token punctuation">:</span> accuracy<span class="token punctuation">}</span><span class="token punctuation">,</span> step<span class="token operator">=</span>example_ct<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Loss/accuracy after "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>example_ct<span class="token punctuation">)</span><span class="token punctuation">.</span>zfill<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token operator">+</span> f<span class="token string">" examples: {loss:.3f}/{accuracy:.3f}"</span><span class="token punctuation">)</span>
</code></pre>
<p>这次我们将运行两个独立的 <code>Artifact</code> 生产 <code>Run</code>s。</p>
<p>一旦第一个完成 <code>train</code>ing <code>model</code>，第二个将通过评估其在 <code>test_dataset</code> 上的性能来使用 <code>trained-model</code> <code>Artifact</code>。</p>
<p>此外，我们将提取网络最混乱的 32 个示例——在这些示例中，<code>categorical_crossentropy</code> 最高。</p>
<p>这是诊断数据集和模型问题的好方法！</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    ## Evaluate the trained model
    """</span>

    loss<span class="token punctuation">,</span> accuracy <span class="token operator">=</span> test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">)</span>
    highest_losses<span class="token punctuation">,</span> hardest_examples<span class="token punctuation">,</span> true_labels<span class="token punctuation">,</span> predictions <span class="token operator">=</span> get_hardest_k_examples<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

    <span class="token keyword">return</span> loss<span class="token punctuation">,</span> accuracy<span class="token punctuation">,</span> highest_losses<span class="token punctuation">,</span> hardest_examples<span class="token punctuation">,</span> true_labels<span class="token punctuation">,</span> predictions

<span class="token keyword">def</span> <span class="token function">get_hardest_k_examples</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> testing_set<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>

    loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>testing_set<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># get the losses and predictions for each item in the dataset</span>
    losses <span class="token operator">=</span> None
    predictions <span class="token operator">=</span> None
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> data<span class="token punctuation">,</span> target <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
            data<span class="token punctuation">,</span> target <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
            pred <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            
            <span class="token keyword">if</span> losses <span class="token keyword">is</span> None<span class="token punctuation">:</span>
                losses <span class="token operator">=</span> loss<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                predictions <span class="token operator">=</span> pred
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                losses <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>losses<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
                predictions <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>predictions<span class="token punctuation">,</span> pred<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

    argsort_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>losses<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    highest_k_losses <span class="token operator">=</span> losses<span class="token punctuation">[</span>argsort_loss<span class="token punctuation">[</span><span class="token operator">-</span>k<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    hardest_k_examples <span class="token operator">=</span> testing_set<span class="token punctuation">[</span>argsort_loss<span class="token punctuation">[</span><span class="token operator">-</span>k<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    true_labels <span class="token operator">=</span> testing_set<span class="token punctuation">[</span>argsort_loss<span class="token punctuation">[</span><span class="token operator">-</span>k<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    predicted_labels <span class="token operator">=</span> predictions<span class="token punctuation">[</span>argsort_loss<span class="token punctuation">[</span><span class="token operator">-</span>k<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

    <span class="token keyword">return</span> highest_k_losses<span class="token punctuation">,</span> hardest_k_examples<span class="token punctuation">,</span> true_labels<span class="token punctuation">,</span> predicted_labels
</code></pre>
<p>这些日志记录功能不会添加任何新的 <code>Artifact</code> 功能，因此我们不会对其进行评论：我们只是在使用、下载和记录 <code>Artifact</code>s。</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token keyword">def</span> <span class="token function">train_and_log</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">with</span> wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>project<span class="token operator">=</span><span class="token string">"artifacts-example"</span><span class="token punctuation">,</span> job_type<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">,</span> config<span class="token operator">=</span>config<span class="token punctuation">)</span> <span class="token keyword">as</span> run<span class="token punctuation">:</span>
        config <span class="token operator">=</span> wandb<span class="token punctuation">.</span>config

        data <span class="token operator">=</span> run<span class="token punctuation">.</span>use_artifact<span class="token punctuation">(</span><span class="token string">'mnist-preprocess:latest'</span><span class="token punctuation">)</span>
        data_dir <span class="token operator">=</span> data<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token punctuation">)</span>

        training_dataset <span class="token operator">=</span>  read<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">"training"</span><span class="token punctuation">)</span>
        validation_dataset <span class="token operator">=</span> read<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">"validation"</span><span class="token punctuation">)</span>

        train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>training_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        validation_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>validation_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        
        model_artifact <span class="token operator">=</span> run<span class="token punctuation">.</span>use_artifact<span class="token punctuation">(</span><span class="token string">"convnet:latest"</span><span class="token punctuation">)</span>
        model_dir <span class="token operator">=</span> model_artifact<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token punctuation">)</span>
        model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>model_dir<span class="token punctuation">,</span> <span class="token string">"initialized_model.pth"</span><span class="token punctuation">)</span>
        model_config <span class="token operator">=</span> model_artifact<span class="token punctuation">.</span>metadata
        config<span class="token punctuation">.</span>update<span class="token punctuation">(</span>model_config<span class="token punctuation">)</span>

        model <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span><span class="token operator">**</span>model_config<span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
        model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
 
        train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> validation_loader<span class="token punctuation">,</span> config<span class="token punctuation">)</span>

        model_artifact <span class="token operator">=</span> wandb<span class="token punctuation">.</span>Artifact<span class="token punctuation">(</span>
            <span class="token string">"trained-model"</span><span class="token punctuation">,</span> type<span class="token operator">=</span><span class="token string">"model"</span><span class="token punctuation">,</span>
            description<span class="token operator">=</span><span class="token string">"Trained NN model"</span><span class="token punctuation">,</span>
            metadata<span class="token operator">=</span>dict<span class="token punctuation">(</span>model_config<span class="token punctuation">)</span><span class="token punctuation">)</span>

        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"trained_model.pth"</span><span class="token punctuation">)</span>
        model_artifact<span class="token punctuation">.</span>add_file<span class="token punctuation">(</span><span class="token string">"trained_model.pth"</span><span class="token punctuation">)</span>
        wandb<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"trained_model.pth"</span><span class="token punctuation">)</span>

        run<span class="token punctuation">.</span>log_artifact<span class="token punctuation">(</span>model_artifact<span class="token punctuation">)</span>

    <span class="token keyword">return</span> model

    
<span class="token keyword">def</span> <span class="token function">evaluate_and_log</span><span class="token punctuation">(</span>config<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">with</span> wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>project<span class="token operator">=</span><span class="token string">"artifacts-example"</span><span class="token punctuation">,</span> job_type<span class="token operator">=</span><span class="token string">"report"</span><span class="token punctuation">,</span> config<span class="token operator">=</span>config<span class="token punctuation">)</span> <span class="token keyword">as</span> run<span class="token punctuation">:</span>
        data <span class="token operator">=</span> run<span class="token punctuation">.</span>use_artifact<span class="token punctuation">(</span><span class="token string">'mnist-preprocess:latest'</span><span class="token punctuation">)</span>
        data_dir <span class="token operator">=</span> data<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token punctuation">)</span>
        testing_set <span class="token operator">=</span> read<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span>

        test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>testing_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

        model_artifact <span class="token operator">=</span> run<span class="token punctuation">.</span>use_artifact<span class="token punctuation">(</span><span class="token string">"trained-model:latest"</span><span class="token punctuation">)</span>
        model_dir <span class="token operator">=</span> model_artifact<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token punctuation">)</span>
        model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>model_dir<span class="token punctuation">,</span> <span class="token string">"trained_model.pth"</span><span class="token punctuation">)</span>
        model_config <span class="token operator">=</span> model_artifact<span class="token punctuation">.</span>metadata

        model <span class="token operator">=</span> ConvNet<span class="token punctuation">(</span><span class="token operator">**</span>model_config<span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
        model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        loss<span class="token punctuation">,</span> accuracy<span class="token punctuation">,</span> highest_losses<span class="token punctuation">,</span> hardest_examples<span class="token punctuation">,</span> true_labels<span class="token punctuation">,</span> preds <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">)</span>

        run<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span> <span class="token string">"accuracy"</span><span class="token punctuation">:</span> accuracy<span class="token punctuation">}</span><span class="token punctuation">)</span>

        wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"high-loss-examples"</span><span class="token punctuation">:</span>
            <span class="token punctuation">[</span>wandb<span class="token punctuation">.</span>Image<span class="token punctuation">(</span>hard_example<span class="token punctuation">,</span> caption<span class="token operator">=</span>str<span class="token punctuation">(</span>int<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span>  str<span class="token punctuation">(</span>int<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
             <span class="token keyword">for</span> hard_example<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> label <span class="token keyword">in</span> zip<span class="token punctuation">(</span>hardest_examples<span class="token punctuation">,</span> preds<span class="token punctuation">,</span> true_labels<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python"><code class="language-python">train_config <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"batch_size"</span><span class="token punctuation">:</span> <span class="token number">128</span><span class="token punctuation">,</span>
                <span class="token string">"epochs"</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
                <span class="token string">"batch_log_interval"</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">,</span>
                <span class="token string">"optimizer"</span><span class="token punctuation">:</span> <span class="token string">"Adam"</span><span class="token punctuation">}</span>

model <span class="token operator">=</span> train_and_log<span class="token punctuation">(</span>train_config<span class="token punctuation">)</span>
evaluate_and_log<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="🔁-The-Graph-View"><a href="#🔁-The-Graph-View" class="headerlink" title="🔁 The Graph View"></a>🔁 The Graph View</h4><p>请注意，我们更改了 <code>Artifact</code> 的 <code>type</code>：这些 <code>Run</code>s 使用的是模型，而不是数据集。在 Artifacts 页面的图形视图中，生产模型的 <code>Run</code>s 将与生成 <code>dataset</code>s 的运行分开。</p>
<p>去看看吧！和以前一样，您需要前往 Run 页面，从左侧栏中选择 “Artifacts” 选项卡，选择一个 <code>Artifact</code>，然后单击 “Graph View” 选项卡。</p>
<h4 id="💣-Exploded-Graphs"><a href="#💣-Exploded-Graphs" class="headerlink" title="💣 Exploded Graphs"></a>💣 Exploded Graphs</h4><p>您可能已经注意到标有“爆炸”的按钮。不要点击它，因为它会在 W&amp;B 总部您不起眼的作者办公桌下引爆一枚小炸弹！</p>
<p>只是在开玩笑。它以更温和的方式“分解”图表：<code>Artifact</code>s 和 <code>Run</code>s 在单个实例级别而不是类型级别分离：节点不是 <code>dataset</code> 和 <code>load-data</code>，而是 <code>dataset:mnist-raw:v1</code> 和 <code>load-data:sunny-smoke-1</code>，等等。</p>
<p>这提供了对您的管道的全面洞察，记录的指标、元数据等都触手可及——您仅受限于您选择与我们一起记录的内容。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">培根请加蛋</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://blog.lfd-world.online/2023/06/12/wandb-xue-xi-ri-ji-yi-doc/">https://blog.lfd-world.online/2023/06/12/wandb-xue-xi-ri-ji-yi-doc/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">培根请加蛋</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/WandB/">
                                    <span class="chip bg-color">WandB</span>
                                </a>
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2023/06/16/gai-lu-lun-yi-bei-xie-si-ding-li/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/21.jpg" class="responsive-img" alt="概率论（一） 贝叶斯公式">
                        
                        <span class="card-title">概率论（一） 贝叶斯公式</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            概率论 贝叶斯公式
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2023-06-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%A6%82%E7%8E%87/" class="post-category">
                                    概率
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%A6%82%E7%8E%87/">
                        <span class="chip bg-color">概率</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2023/06/04/github-pages-ge-ren-bo-ke-da-jian-san-typora-teng-xun-yun-tu-chuang/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="Github Pages + Hexo + Vercel 个人博客搭建（三）Typora + PicGo+ 腾讯云图床">
                        
                        <span class="card-title">Github Pages + Hexo + Vercel 个人博客搭建（三）Typora + PicGo+ 腾讯云图床</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Typora + PicGo + 腾讯云图床
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-06-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Blog/" class="post-category">
                                    Blog
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Blog/">
                        <span class="chip bg-color">Blog</span>
                    </a>
                    
                    <a href="/tags/Hexo/">
                        <span class="chip bg-color">Hexo</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE' || selection.getRangeAt(0).commonAncestorContainer.nodeName === 'CODE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 培根请加蛋<br />'
            + '文章作者: 培根请加蛋<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023</span>
            
            <a href="/about" target="_blank">培根请加蛋</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">23.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/LFD-byte" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:huifali@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
