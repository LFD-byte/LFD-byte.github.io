

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="åŸ¹æ ¹è¯·åŠ è›‹">
  <meta name="keywords" content="">
  
    <meta name="description" content="å¿«é€Ÿå®éªŒæ˜¯æœºå™¨å­¦ä¹ çš„åŸºç¡€ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ W&amp;B æ¥è·Ÿè¸ªå’Œå¯è§†åŒ–å®éªŒï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å¿«é€Ÿè¿­ä»£å’Œç†è§£æˆ‘ä»¬çš„ç»“æœã€‚">
<meta property="og:type" content="article">
<meta property="og:title" content="WandB å­¦ä¹ æ—¥è®°ï¼ˆä¸€ï¼‰Tutorials">
<meta property="og:url" content="https://blog.lfd-world.online/2023/06/12/wandb-xue-xi-ri-ji-yi-doc/index.html">
<meta property="og:site_name" content="åŸ¹æ ¹è¯·åŠ è›‹">
<meta property="og:description" content="å¿«é€Ÿå®éªŒæ˜¯æœºå™¨å­¦ä¹ çš„åŸºç¡€ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ W&amp;B æ¥è·Ÿè¸ªå’Œå¯è§†åŒ–å®éªŒï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å¿«é€Ÿè¿­ä»£å’Œç†è§£æˆ‘ä»¬çš„ç»“æœã€‚">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-06-12T06:06:00.000Z">
<meta property="article:modified_time" content="2023-07-10T03:43:06.573Z">
<meta property="article:author" content="åŸ¹æ ¹è¯·åŠ è›‹">
<meta property="article:tag" content="WandB">
<meta property="article:tag" content="æ·±åº¦å­¦ä¹ ">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>WandB å­¦ä¹ æ—¥è®°ï¼ˆä¸€ï¼‰Tutorials - åŸ¹æ ¹è¯·åŠ è›‹</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.lfd-world.online","root":"/","version":"1.9.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":false,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>åŸ¹æ ¹è¯·åŠ è›‹</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>é¦–é¡µ</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>å½’æ¡£</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>åˆ†ç±»</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>æ ‡ç­¾</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>å…³äº</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="WandB å­¦ä¹ æ—¥è®°ï¼ˆä¸€ï¼‰Tutorials"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-06-12 14:06" pubdate>
          2023å¹´6æœˆ12æ—¥ ä¸‹åˆ
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          36k å­—
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          304 åˆ†é’Ÿ
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> æ¬¡
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">WandB å­¦ä¹ æ—¥è®°ï¼ˆä¸€ï¼‰Tutorials</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="track-experiments">Track experiments</h2>
<p>å¿«é€Ÿå®éªŒæ˜¯æœºå™¨å­¦ä¹ çš„åŸºç¡€ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ W&amp;B
æ¥è·Ÿè¸ªå’Œå¯è§†åŒ–å®éªŒï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å¿«é€Ÿè¿­ä»£å’Œç†è§£æˆ‘ä»¬çš„ç»“æœã€‚</p>
<h3 id="a-shared-dashboard-for-your-experiments">A shared dashboard for
your experiments</h3>
<p>åªéœ€å‡ è¡Œä»£ç ï¼Œæ‚¨å°±å¯ä»¥è·å¾—ä¸°å¯Œçš„ã€äº¤äº’å¼çš„ã€å¯å…±äº«çš„ä»ªè¡¨æ¿ï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°<a
target="_blank" rel="noopener" href="https://wandb.ai/wandb/wandb_example?_gl=1*1ycseye*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MDE0OC41MC4wLjA.">è‡ªå·±çš„
dashboard</a>ã€‚</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedPell4Oo.png"
alt="dashboard" />
<figcaption aria-hidden="true">dashboard</figcaption>
</figure>
<h3 id="data-privacy">Data &amp; Privacy</h3>
<p>æˆ‘ä»¬éå¸¸é‡è§†å®‰å…¨æ€§ï¼Œæˆ‘ä»¬çš„äº‘æ‰˜ç®¡ dashboard
ä½¿ç”¨è¡Œä¸šæ ‡å‡†æœ€ä½³åŠ å¯†å®è·µã€‚å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨æ— æ³•ç¦»å¼€ä¼ä¸šé›†ç¾¤çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥æä¾›<a
target="_blank" rel="noopener" href="https://docs.wandb.com/self-hosted">æœ¬åœ°å®‰è£…</a>ã€‚</p>
<p>ä¸‹è½½æ‰€æœ‰æ•°æ®å¹¶å°†å…¶å¯¼å‡ºåˆ°å…¶ä»–å·¥å…·ä¹Ÿå¾ˆå®¹æ˜“â€”â€”ä¾‹å¦‚åœ¨ Jupyter
ç¬”è®°æœ¬ä¸­è¿›è¡Œè‡ªå®šä¹‰åˆ†æã€‚ä¸‹é¢æ˜¯å…³äºæˆ‘ä»¬ <a
target="_blank" rel="noopener" href="https://docs.wandb.com/library/api">API</a> çš„æ›´å¤šä¿¡æ¯ã€‚</p>
<h3 id="install-wandb-library-and-login">Install <code>wandb</code>
library and login</h3>
<p>é¦–å…ˆå®‰è£…åº“å¹¶ç™»å½•åˆ°æ‚¨çš„å…è´¹å¸æˆ·ã€‚</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">!pip install wandb -qU<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Log in to your W&amp;B account</span><br><span class="hljs-keyword">import</span> wandb<br>wandb.login()<br></code></pre></td></tr></table></figure>
<h3 id="run-an-experiment">Run an experiment</h3>
<p>1ï¸âƒ£. å¼€å§‹æ–°çš„è¿è¡Œå¹¶ä¼ å…¥è¶…å‚æ•°è¿›è¡Œè·Ÿè¸ª</p>
<p>2ï¸âƒ£. è®­ç»ƒæˆ–è¯„ä¼°çš„æ—¥å¿—æŒ‡æ ‡</p>
<p>3ï¸âƒ£. åœ¨ dashboard ä¸­å¯è§†åŒ–ç»“æœ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><br><span class="hljs-comment"># Launch 5 simulated experiments</span><br>total_runs = <span class="hljs-number">5</span><br><span class="hljs-keyword">for</span> run <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(total_runs):<br>  <span class="hljs-comment"># ğŸ 1ï¸âƒ£ Start a new run to track this script</span><br>  wandb.init(<br>      <span class="hljs-comment"># Set the project where this run will be logged</span><br>      project=<span class="hljs-string">&quot;basic-intro&quot;</span>, <br>      <span class="hljs-comment"># We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)</span><br>      name=<span class="hljs-string">f&quot;experiment_<span class="hljs-subst">&#123;run&#125;</span>&quot;</span>, <br>      <span class="hljs-comment"># Track hyperparameters and run metadata</span><br>      config=&#123;<br>      <span class="hljs-string">&quot;learning_rate&quot;</span>: <span class="hljs-number">0.02</span>,<br>      <span class="hljs-string">&quot;architecture&quot;</span>: <span class="hljs-string">&quot;CNN&quot;</span>,<br>      <span class="hljs-string">&quot;dataset&quot;</span>: <span class="hljs-string">&quot;CIFAR-100&quot;</span>,<br>      <span class="hljs-string">&quot;epochs&quot;</span>: <span class="hljs-number">10</span>,<br>      &#125;)<br>  <br>  <span class="hljs-comment"># This simple block simulates a training loop logging metrics</span><br>  epochs = <span class="hljs-number">10</span><br>  offset = random.random() / <span class="hljs-number">5</span><br>  <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, epochs):<br>      acc = <span class="hljs-number">1</span> - <span class="hljs-number">2</span> ** -epoch - random.random() / epoch - offset<br>      loss = <span class="hljs-number">2</span> ** -epoch + random.random() / epoch + offset<br>      <br>      <span class="hljs-comment"># ğŸ 2ï¸âƒ£ Log metrics from your script to W&amp;B</span><br>      wandb.log(&#123;<span class="hljs-string">&quot;acc&quot;</span>: acc, <span class="hljs-string">&quot;loss&quot;</span>: loss&#125;)<br>      <br>  <span class="hljs-comment"># Mark the run as finished</span><br>  wandb.finish()<br></code></pre></td></tr></table></figure>
<p>3ï¸âƒ£ å½“æ‚¨è¿è¡Œæ­¤ä»£ç æ—¶ï¼Œæ‚¨å¯ä»¥é€šè¿‡å•å‡»ä¸Šé¢çš„ä»»ä½• ğŸ‘† wandb
é“¾æ¥æ‰¾åˆ°æ‚¨çš„äº¤äº’å¼ dashboardã€‚</p>
<h3 id="simple-pytorch-neural-network">Simple Pytorch Neural
Network</h3>
<p>è¿è¡Œæ­¤æ¨¡å‹ä»¥è®­ç»ƒä¸€ä¸ªç®€å•çš„ MNIST
åˆ†ç±»å™¨ï¼Œç„¶åå•å‡»é¡¹ç›®é¡µé¢é“¾æ¥ä»¥å®æ—¶æŸ¥çœ‹æ‚¨çš„ç»“æœæµåˆ° W&amp;B é¡¹ç›®ã€‚</p>
<p>wandb ä¸­çš„ä»»ä½•è¿è¡Œéƒ½ä¼šè‡ªåŠ¨è®°å½• <a
target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#charts-tab">metrics</a>,
<a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#system-tab">system
information</a>, <a
target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#overview-tab">hyperparameters</a>,
<a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/app/pages/run-page#logs-tab">terminal
output</a> ï¼Œæ‚¨å°†çœ‹åˆ°ä¸€ä¸ªåŒ…å«æ¨¡å‹è¾“å…¥å’Œè¾“å‡ºçš„äº¤äº’å¼è¡¨æ ¼ã€‚</p>
<h4 id="set-up-dataloader">Set up Dataloader</h4>
<p>è¦è¿è¡Œæ­¤ç¤ºä¾‹ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£… PyTorchã€‚å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ Google
Colabï¼Œåˆ™å®ƒå·²ç»é¢„è£…ã€‚</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">!pip install torch torchvision<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> wandb<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch, torchvision<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> T<br><br>device = <span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataloader</span>(<span class="hljs-params">is_train, batch_size, <span class="hljs-built_in">slice</span>=<span class="hljs-number">5</span></span>):<br>    <span class="hljs-string">&quot;Get a training dataloader&quot;</span><br>    full_dataset = torchvision.datasets.MNIST(root=<span class="hljs-string">&quot;.&quot;</span>, train=is_train, transform=T.ToTensor(), download=<span class="hljs-literal">True</span>)<br>    sub_dataset = torch.utils.data.Subset(full_dataset, indices=<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(full_dataset), <span class="hljs-built_in">slice</span>))<br>    loader = torch.utils.data.DataLoader(dataset=sub_dataset, <br>                                         batch_size=batch_size, <br>                                         shuffle=<span class="hljs-literal">True</span> <span class="hljs-keyword">if</span> is_train <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span>, <br>                                         pin_memory=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> loader<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_model</span>(<span class="hljs-params">dropout</span>):<br>    <span class="hljs-string">&quot;A simple model&quot;</span><br>    model = nn.Sequential(nn.Flatten(),<br>                         nn.Linear(<span class="hljs-number">28</span>*<span class="hljs-number">28</span>, <span class="hljs-number">256</span>),<br>                         nn.BatchNorm1d(<span class="hljs-number">256</span>),<br>                         nn.ReLU(),<br>                         nn.Dropout(dropout),<br>                         nn.Linear(<span class="hljs-number">256</span>,<span class="hljs-number">10</span>)).to(device)<br>    <span class="hljs-keyword">return</span> model<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">validate_model</span>(<span class="hljs-params">model, valid_dl, loss_func, log_images=<span class="hljs-literal">False</span>, batch_idx=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-string">&quot;Compute performance of the model on the validation dataset and log a wandb.Table&quot;</span><br>    model.<span class="hljs-built_in">eval</span>()<br>    val_loss = <span class="hljs-number">0.</span><br>    <span class="hljs-keyword">with</span> torch.inference_mode():<br>        correct = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i, (images, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(valid_dl):<br>            images, labels = images.to(device), labels.to(device)<br><br>            <span class="hljs-comment"># Forward pass â¡</span><br>            outputs = model(images)<br>            val_loss += loss_func(outputs, labels)*labels.size(<span class="hljs-number">0</span>)<br><br>            <span class="hljs-comment"># Compute accuracy and accumulate</span><br>            _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>            correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br>            <span class="hljs-comment"># Log one batch of images to the dashboard, always same batch_idx.</span><br>            <span class="hljs-keyword">if</span> i==batch_idx <span class="hljs-keyword">and</span> log_images:<br>                log_image_table(images, predicted, labels, outputs.softmax(dim=<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">return</span> val_loss / <span class="hljs-built_in">len</span>(valid_dl.dataset), correct / <span class="hljs-built_in">len</span>(valid_dl.dataset)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">log_image_table</span>(<span class="hljs-params">images, predicted, labels, probs</span>):<br>    <span class="hljs-string">&quot;Log a wandb.Table with (img, pred, target, scores)&quot;</span><br>    <span class="hljs-comment"># ğŸ Create a wandb Table to log images, labels and predictions to</span><br>    table = wandb.Table(columns=[<span class="hljs-string">&quot;image&quot;</span>, <span class="hljs-string">&quot;pred&quot;</span>, <span class="hljs-string">&quot;target&quot;</span>]+[<span class="hljs-string">f&quot;score_<span class="hljs-subst">&#123;i&#125;</span>&quot;</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)])<br>    <span class="hljs-keyword">for</span> img, pred, targ, prob <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(images.to(<span class="hljs-string">&quot;cpu&quot;</span>), predicted.to(<span class="hljs-string">&quot;cpu&quot;</span>), labels.to(<span class="hljs-string">&quot;cpu&quot;</span>), probs.to(<span class="hljs-string">&quot;cpu&quot;</span>)):<br>        table.add_data(wandb.Image(img[<span class="hljs-number">0</span>].numpy()*<span class="hljs-number">255</span>), pred, targ, *prob.numpy())<br>    wandb.log(&#123;<span class="hljs-string">&quot;predictions_table&quot;</span>:table&#125;, commit=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>
<h4 id="train-your-model">Train Your Model</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Launch 5 experiments, trying different dropout rates</span><br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>    <span class="hljs-comment"># ğŸ initialise a wandb run</span><br>    wandb.init(<br>        project=<span class="hljs-string">&quot;pytorch-intro&quot;</span>,<br>        config=&#123;<br>            <span class="hljs-string">&quot;epochs&quot;</span>: <span class="hljs-number">10</span>,<br>            <span class="hljs-string">&quot;batch_size&quot;</span>: <span class="hljs-number">128</span>,<br>            <span class="hljs-string">&quot;lr&quot;</span>: <span class="hljs-number">1e-3</span>,<br>            <span class="hljs-string">&quot;dropout&quot;</span>: random.uniform(<span class="hljs-number">0.01</span>, <span class="hljs-number">0.80</span>),<br>            &#125;)<br>    <br>    <span class="hljs-comment"># Copy your config </span><br>    config = wandb.config<br><br>    <span class="hljs-comment"># Get the data</span><br>    train_dl = get_dataloader(is_train=<span class="hljs-literal">True</span>, batch_size=config.batch_size)<br>    valid_dl = get_dataloader(is_train=<span class="hljs-literal">False</span>, batch_size=<span class="hljs-number">2</span>*config.batch_size)<br>    n_steps_per_epoch = math.ceil(<span class="hljs-built_in">len</span>(train_dl.dataset) / config.batch_size)<br>    <br>    <span class="hljs-comment"># A simple MLP model</span><br>    model = get_model(config.dropout)<br><br>    <span class="hljs-comment"># Make the loss and optimizer</span><br>    loss_func = nn.CrossEntropyLoss()<br>    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)<br><br>   <span class="hljs-comment"># Training</span><br>    example_ct = <span class="hljs-number">0</span><br>    step_ct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.epochs):<br>        model.train()<br>        <span class="hljs-keyword">for</span> step, (images, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dl):<br>            images, labels = images.to(device), labels.to(device)<br><br>            outputs = model(images)<br>            train_loss = loss_func(outputs, labels)<br>            optimizer.zero_grad()<br>            train_loss.backward()<br>            optimizer.step()<br>            <br>            example_ct += <span class="hljs-built_in">len</span>(images)<br>            metrics = &#123;<span class="hljs-string">&quot;train/train_loss&quot;</span>: train_loss, <br>                       <span class="hljs-string">&quot;train/epoch&quot;</span>: (step + <span class="hljs-number">1</span> + (n_steps_per_epoch * epoch)) / n_steps_per_epoch, <br>                       <span class="hljs-string">&quot;train/example_ct&quot;</span>: example_ct&#125;<br>            <br>            <span class="hljs-keyword">if</span> step + <span class="hljs-number">1</span> &lt; n_steps_per_epoch:<br>                <span class="hljs-comment"># ğŸ Log train metrics to wandb </span><br>                wandb.log(metrics)<br>                <br>            step_ct += <span class="hljs-number">1</span><br><br>        val_loss, accuracy = validate_model(model, valid_dl, loss_func, log_images=(epoch==(config.epochs-<span class="hljs-number">1</span>)))<br><br>        <span class="hljs-comment"># ğŸ Log train and validation metrics to wandb</span><br>        val_metrics = &#123;<span class="hljs-string">&quot;val/val_loss&quot;</span>: val_loss, <br>                       <span class="hljs-string">&quot;val/val_accuracy&quot;</span>: accuracy&#125;<br>        wandb.log(&#123;**metrics, **val_metrics&#125;)<br>        <br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Train Loss: <span class="hljs-subst">&#123;train_loss:<span class="hljs-number">.3</span>f&#125;</span>, Valid Loss: <span class="hljs-subst">&#123;val_loss:3f&#125;</span>, Accuracy: <span class="hljs-subst">&#123;accuracy:<span class="hljs-number">.2</span>f&#125;</span>&quot;</span>)<br><br>    <span class="hljs-comment"># If you had a test set, this is how you could log it as a Summary metric</span><br>    wandb.summary[<span class="hljs-string">&#x27;test_accuracy&#x27;</span>] = <span class="hljs-number">0.8</span><br><br>    <span class="hljs-comment"># ğŸ Close your wandb run </span><br>    wandb.finish()<br></code></pre></td></tr></table></figure>
<p>æ‚¨ç°åœ¨å·²ç»ä½¿ç”¨ wandb è®­ç»ƒäº†æ‚¨çš„ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼ ğŸ‘† å•å‡»ä¸Šé¢çš„ wandb
é“¾æ¥æŸ¥çœ‹æ‚¨çš„æŒ‡æ ‡</p>
<h3 id="try-wb-alerts">Try W&amp;B Alerts</h3>
<p><strong><a target="_blank" rel="noopener" href="https://docs.wandb.ai/guides/track/alert">W&amp;B
Alerts</a></strong> å…è®¸æ‚¨å°†ä» Python ä»£ç è§¦å‘çš„è­¦æŠ¥å‘é€åˆ°æ‚¨çš„ Slack
æˆ–ç”µå­é‚®ä»¶ã€‚ç¬¬ä¸€æ¬¡å‘é€ Slack æˆ–ç”µå­é‚®ä»¶è­¦æŠ¥æ—¶ï¼Œéœ€è¦æ‰§è¡Œ 2
ä¸ªæ­¥éª¤ï¼Œè¿™äº›è­¦æŠ¥ç”±æ‚¨çš„ä»£ç è§¦å‘ï¼š</p>
<p>1) åœ¨ä½ çš„ W&amp;B <a target="_blank" rel="noopener" href="https://wandb.ai/settings">User
Settings</a> å¼€å¯è­¦æŠ¥</p>
<p>2) æ·»åŠ  <code>wandb.alert()</code> åˆ°ä½ çš„ä»£ç :</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">wandb.alert(<br>    title=<span class="hljs-string">&quot;Low accuracy&quot;</span>, <br>    text=<span class="hljs-string">f&quot;Accuracy is below the acceptable threshold&quot;</span><br>)<br></code></pre></td></tr></table></figure>
<p>è¯·å‚é˜…ä¸‹é¢çš„æœ€å°ç¤ºä¾‹ä»¥äº†è§£å¦‚ä½•ä½¿ç”¨ wandb.alertï¼Œæ‚¨å¯ä»¥åœ¨æ­¤å¤„æ‰¾åˆ° <a
target="_blank" rel="noopener" href="https://docs.wandb.ai/guides/track/alert">W&amp;B
Alerts</a>çš„å®Œæ•´æ–‡æ¡£</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Start a wandb run</span><br>wandb.init(project=<span class="hljs-string">&quot;pytorch-intro&quot;</span>)<br><br><span class="hljs-comment"># Simulating a model training loop</span><br>acc_threshold = <span class="hljs-number">0.3</span><br><span class="hljs-keyword">for</span> training_step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>):<br><br>    <span class="hljs-comment"># Generate a random number for accuracy</span><br>    accuracy = <span class="hljs-built_in">round</span>(random.random() + random.random(), <span class="hljs-number">3</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Accuracy is: <span class="hljs-subst">&#123;accuracy&#125;</span>, <span class="hljs-subst">&#123;acc_threshold&#125;</span>&#x27;</span>)<br>    <br>    <span class="hljs-comment"># ğŸ Log accuracy to wandb</span><br>    wandb.log(&#123;<span class="hljs-string">&quot;Accuracy&quot;</span>: accuracy&#125;)<br><br>    <span class="hljs-comment"># ğŸ”” If the accuracy is below the threshold, fire a W&amp;B Alert and stop the run</span><br>    <span class="hljs-keyword">if</span> accuracy &lt;= acc_threshold:<br>        <span class="hljs-comment"># ğŸ Send the wandb Alert</span><br>        wandb.alert(<br>            title=<span class="hljs-string">&#x27;Low Accuracy&#x27;</span>,<br>            text=<span class="hljs-string">f&#x27;Accuracy <span class="hljs-subst">&#123;accuracy&#125;</span> at step <span class="hljs-subst">&#123;training_step&#125;</span> is below the acceptable theshold, <span class="hljs-subst">&#123;acc_threshold&#125;</span>&#x27;</span>,<br>        )<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Alert triggered&#x27;</span>)<br>        <span class="hljs-keyword">break</span><br><br><span class="hljs-comment"># Mark the run as finished (useful in Jupyter notebooks)</span><br>wandb.finish()<br></code></pre></td></tr></table></figure>
<h2 id="visualize-predictions">Visualize predictions</h2>
<p>è¿™åŒ…æ‹¬å¦‚ä½•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨ PyTorch å¯¹ MNIST
æ•°æ®è¿›è¡Œè·Ÿè¸ªã€å¯è§†åŒ–å’Œæ¯”è¾ƒæ¨¡å‹é¢„æµ‹ã€‚</p>
<p>ä½ å°†å­¦åˆ°å¦‚ä½•ï¼š</p>
<ol type="1">
<li>åœ¨æ¨¡å‹è®­ç»ƒæˆ–è¯„ä¼°æœŸé—´å°†æŒ‡æ ‡ã€å›¾åƒã€æ–‡æœ¬ç­‰è®°å½•åˆ°
<code>wandb.Table()</code></li>
<li>æŸ¥çœ‹ã€æ’åºã€ç­›é€‰ã€åˆ†ç»„ã€åŠ å…¥ã€äº¤äº’å¼æŸ¥è¯¢å’Œæ¢ç´¢è¿™äº›è¡¨</li>
<li>æ¯”è¾ƒæ¨¡å‹é¢„æµ‹æˆ–ç»“æœï¼šåŠ¨æ€åœ°è·¨è¶Šç‰¹å®šå›¾åƒã€è¶…å‚æ•°/æ¨¡å‹ç‰ˆæœ¬æˆ–æ—¶é—´æ­¥é•¿ã€‚</li>
</ol>
<h3 id="examples">Examples</h3>
<h4 id="compare-predicted-scores-for-specific-images">Compare predicted
scores for specific images</h4>
<p><a
target="_blank" rel="noopener" href="https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU?_gl=1*6z1980*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MTg0Ni4zOC4wLjA.#compare-predictions-after-1-vs-5-epochs">å®ä¾‹ï¼šæ¯”è¾ƒ
1 å’Œ 5 ä¸ªè®­ç»ƒå‘¨æœŸåçš„é¢„æµ‹</a></p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedNMme6Qj.png"
alt="1 epoch vs 5 epochs of training" />
<figcaption aria-hidden="true">1 epoch vs 5 epochs of
training</figcaption>
</figure>
<p>ç›´æ–¹å›¾æ¯”è¾ƒäº†ä¸¤ä¸ªæ¨¡å‹ä¹‹é—´çš„æ¯ç±»åˆ†æ•°ã€‚æ¯ä¸ªç›´æ–¹å›¾ä¸­é¡¶éƒ¨çš„ç»¿è‰²æ¡ä»£è¡¨æ¨¡å‹â€œCNN-2,
1 epochâ€ï¼ˆid 0ï¼‰ï¼Œå®ƒåªè®­ç»ƒäº† 1 ä¸ª epochã€‚åº•éƒ¨çš„ç´«è‰²æ¡ä»£è¡¨æ¨¡å‹â€œCNN-2, 5
epochsâ€ (id 1)ï¼Œå®ƒè®­ç»ƒäº† 5 ä¸ª
epochsã€‚å›¾åƒè¢«è¿‡æ»¤åˆ°æ¨¡å‹ä¸ä¸€è‡´çš„æƒ…å†µã€‚ä¾‹å¦‚ï¼Œåœ¨ç¬¬ä¸€è¡Œä¸­ï¼Œâ€œ4â€åœ¨ 1
ä¸ªæ—¶æœŸååœ¨æ‰€æœ‰å¯èƒ½çš„æ•°å­—ä¸­è·å¾—é«˜åˆ†ï¼Œä½†åœ¨ 5
ä¸ªæ—¶æœŸåï¼Œå®ƒåœ¨æ­£ç¡®æ ‡ç­¾ä¸Šå¾—åˆ†æœ€é«˜ï¼Œè€Œåœ¨å…¶ä½™éƒ¨åˆ†å¾—åˆ†éå¸¸ä½ã€‚</p>
<h4 id="focus-on-top-errors-over-time">Focus on top errors over
time</h4>
<p><a
target="_blank" rel="noopener" href="https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU?_gl=1*1nxbzl7*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MTg0Ni4zOC4wLjA.#top-errors-over-time">å®ä¾‹
â†’</a></p>
<p>æŸ¥çœ‹å®Œæ•´æµ‹è¯•æ•°æ®çš„ä¸æ­£ç¡®é¢„æµ‹ï¼ˆè¿‡æ»¤ "guess" != "truth"
çš„è¡Œï¼‰ã€‚è¯·æ³¨æ„ï¼Œåœ¨ 1 ä¸ªè®­ç»ƒæ—¶æœŸåæœ‰ 229 ä¸ªé”™è¯¯çŒœæµ‹ï¼Œä½†åœ¨ 5 ä¸ªæ—¶æœŸååªæœ‰
98 ä¸ªã€‚</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefined7g8nodn.png"
alt="side by side, 1 vs 5 epochs of training" />
<figcaption aria-hidden="true">side by side, 1 vs 5 epochs of
training</figcaption>
</figure>
<h4 id="compare-model-performance-and-find-patterns">Compare model
performance and find patterns</h4>
<p><a
target="_blank" rel="noopener" href="https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU?_gl=1*8r828v*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjU0ODg1NC40LjEuMTY4NjU1MTg0Ni4zOC4wLjA.#false-positives-grouped-by-guess">æŸ¥çœ‹å®ä¾‹ä¸­çš„å®Œæ•´è¯¦ç»†ä¿¡æ¯
â†’</a></p>
<p>è¿‡æ»¤å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œç„¶åæŒ‰çŒœæµ‹åˆ†ç»„ï¼Œä»¥æŸ¥çœ‹é”™è¯¯åˆ†ç±»å›¾åƒçš„ç¤ºä¾‹å’ŒçœŸå®æ ‡ç­¾çš„åŸºæœ¬åˆ†å¸ƒâ€”â€”å¹¶æ’æ˜¾ç¤ºä¸¤ä¸ªæ¨¡å‹ã€‚å…·æœ‰
2X layer sizes
å’Œå­¦ä¹ ç‡çš„æ¨¡å‹å˜ä½“åœ¨å·¦ä¾§ï¼ŒåŸºçº¿åœ¨å³ä¾§ã€‚è¯·æ³¨æ„ï¼Œå¯¹äºæ¯ä¸ªçŒœæµ‹çš„ç±»ï¼ŒåŸºçº¿éƒ½ä¼šçŠ¯æ›´å¤šçš„é”™è¯¯ã€‚</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedi5PP9AE.png"
alt="grouped errors for baseline vs double variant" />
<figcaption aria-hidden="true">grouped errors for baseline vs double
variant</figcaption>
</figure>
<h3 id="sign-up-or-login">Sign up or login</h3>
<p><a target="_blank" rel="noopener" href="https://wandb.ai/login">Sign up or login</a> W&amp;B
ä»¥åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹æ‚¨çš„å®éªŒå¹¶ä¸ä¹‹äº’åŠ¨ã€‚</p>
<p>åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ Google Colab
ä½œä¸ºæ–¹ä¾¿çš„æ‰˜ç®¡ç¯å¢ƒï¼Œä½†æ‚¨å¯ä»¥ä»ä»»ä½•åœ°æ–¹è¿è¡Œè‡ªå·±çš„è®­ç»ƒè„šæœ¬ï¼Œå¹¶ä½¿ç”¨ W&amp;B
çš„å®éªŒè·Ÿè¸ªå·¥å…·å¯è§†åŒ–æŒ‡æ ‡ã€‚</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">!pip install wandb -qqq<br></code></pre></td></tr></table></figure>
<p>ç™»å½•æ‚¨çš„å¸æˆ·</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> wandb<br>wandb.login()<br><br>WANDB_PROJECT = <span class="hljs-string">&quot;mnist-viz&quot;</span><br></code></pre></td></tr></table></figure>
<h3 id="setup">0. Setup</h3>
<p>å®‰è£…ä¾èµ–é¡¹ï¼Œä¸‹è½½ MNISTï¼Œå¹¶ä½¿ç”¨ PyTorch åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> T <br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><br>device = <span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span><br><br><span class="hljs-comment"># create train and test dataloaders</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataloader</span>(<span class="hljs-params">is_train, batch_size, <span class="hljs-built_in">slice</span>=<span class="hljs-number">5</span></span>):<br>    <span class="hljs-string">&quot;Get a training dataloader&quot;</span><br>    ds = torchvision.datasets.MNIST(root=<span class="hljs-string">&quot;.&quot;</span>, train=is_train, transform=T.ToTensor(), download=<span class="hljs-literal">True</span>)<br>    loader = torch.utils.data.DataLoader(dataset=ds, <br>                                         batch_size=batch_size, <br>                                         shuffle=<span class="hljs-literal">True</span> <span class="hljs-keyword">if</span> is_train <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span>, <br>                                         pin_memory=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> loader<br></code></pre></td></tr></table></figure>
<h3 id="define-the-model-and-training-schedule">1. Define the model and
training schedule</h3>
<ul>
<li>è®¾ç½®è¦è¿è¡Œçš„çºªå…ƒæ•°ï¼Œå…¶ä¸­æ¯ä¸ªçºªå…ƒåŒ…å«ä¸€ä¸ªè®­ç»ƒæ­¥éª¤å’Œä¸€ä¸ªéªŒè¯ï¼ˆæµ‹è¯•ï¼‰æ­¥éª¤ã€‚
ï¼ˆå¯é€‰ï¼‰é…ç½®æ¯ä¸ªæµ‹è¯•æ­¥éª¤è¦è®°å½•çš„æ•°æ®é‡ã€‚è¿™é‡Œè¦å¯è§†åŒ–çš„æ‰¹æ¬¡æ•°å’Œæ¯æ‰¹æ¬¡çš„å›¾åƒæ•°è®¾ç½®å¾—è¾ƒä½ï¼Œä»¥ç®€åŒ–æ¼”ç¤ºã€‚</li>
<li>å®šä¹‰ä¸€ä¸ªç®€å•çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆéµå¾ª <a
target="_blank" rel="noopener" href="https://github.com/yunjey/pytorch-tutorial">pytorch-tutorial</a>
ä»£ç ï¼‰ã€‚</li>
<li>ä½¿ç”¨ PyTorch åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Number of epochs to run</span><br><span class="hljs-comment"># Each epoch includes a training step and a test step, so this sets</span><br><span class="hljs-comment"># the number of tables of test predictions to log</span><br>EPOCHS = <span class="hljs-number">1</span><br><br><span class="hljs-comment"># Number of batches to log from the test data for each test step</span><br><span class="hljs-comment"># (default set low to simplify demo)</span><br>NUM_BATCHES_TO_LOG = <span class="hljs-number">10</span> <span class="hljs-comment">#79</span><br><br><span class="hljs-comment"># Number of images to log per test batch</span><br><span class="hljs-comment"># (default set low to simplify demo)</span><br>NUM_IMAGES_PER_BATCH = <span class="hljs-number">32</span> <span class="hljs-comment">#128</span><br><br><span class="hljs-comment"># training configuration and hyperparameters</span><br>NUM_CLASSES = <span class="hljs-number">10</span><br>BATCH_SIZE = <span class="hljs-number">32</span><br>LEARNING_RATE = <span class="hljs-number">0.001</span><br>L1_SIZE = <span class="hljs-number">32</span><br>L2_SIZE = <span class="hljs-number">64</span><br><span class="hljs-comment"># changing this may require changing the shape of adjacent layers</span><br>CONV_KERNEL_SIZE = <span class="hljs-number">5</span><br><br><span class="hljs-comment"># define a two-layer convolutional neural network</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ConvNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_classes=<span class="hljs-number">10</span></span>):<br>        <span class="hljs-built_in">super</span>(ConvNet, self).__init__()<br>        self.layer1 = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">1</span>, L1_SIZE, CONV_KERNEL_SIZE, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">2</span>),<br>            nn.BatchNorm2d(L1_SIZE),<br>            nn.ReLU(),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>))<br>        self.layer2 = nn.Sequential(<br>            nn.Conv2d(L1_SIZE, L2_SIZE, CONV_KERNEL_SIZE, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">2</span>),<br>            nn.BatchNorm2d(L2_SIZE),<br>            nn.ReLU(),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>))<br>        self.fc = nn.Linear(<span class="hljs-number">7</span>*<span class="hljs-number">7</span>*L2_SIZE, NUM_CLASSES)<br>        self.softmax = nn.Softmax(NUM_CLASSES)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># uncomment to see the shape of a given layer:</span><br>        <span class="hljs-comment">#print(&quot;x: &quot;, x.size())</span><br>        out = self.layer1(x)<br>        out = self.layer2(out)<br>        out = out.reshape(out.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>        out = self.fc(out)<br>        <span class="hljs-keyword">return</span> out<br><br>train_loader = get_dataloader(is_train=<span class="hljs-literal">True</span>, batch_size=BATCH_SIZE)<br>test_loader = get_dataloader(is_train=<span class="hljs-literal">False</span>, batch_size=<span class="hljs-number">2</span>*BATCH_SIZE)<br><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br></code></pre></td></tr></table></figure>
<h3 id="run-training-and-log-test-predictions">2. Run training and log
test predictions</h3>
<p>å¯¹äºæ¯ä¸ªæ—¶æœŸï¼Œè¿è¡Œä¸€ä¸ªè®­ç»ƒæ­¥éª¤å’Œä¸€ä¸ªæµ‹è¯•æ­¥éª¤ã€‚å¯¹äºæ¯ä¸ªæµ‹è¯•æ­¥éª¤ï¼Œåˆ›å»ºä¸€ä¸ª
wandb.Table()
æ¥å­˜å‚¨æµ‹è¯•é¢„æµ‹ã€‚è¿™äº›å¯ä»¥åœ¨æ‚¨çš„æµè§ˆå™¨ä¸­è¿›è¡Œå¯è§†åŒ–ã€åŠ¨æ€æŸ¥è¯¢å’Œå¹¶æ’æ¯”è¾ƒã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># âœ¨ W&amp;B: Initialize a new run to track this model&#x27;s training</span><br>wandb.init(project=<span class="hljs-string">&quot;table-quickstart&quot;</span>)<br><br><span class="hljs-comment"># âœ¨ W&amp;B: Log hyperparameters using config</span><br>cfg = wandb.config<br>cfg.update(&#123;<span class="hljs-string">&quot;epochs&quot;</span> : EPOCHS, <span class="hljs-string">&quot;batch_size&quot;</span>: BATCH_SIZE, <span class="hljs-string">&quot;lr&quot;</span> : LEARNING_RATE,<br>            <span class="hljs-string">&quot;l1_size&quot;</span> : L1_SIZE, <span class="hljs-string">&quot;l2_size&quot;</span>: L2_SIZE,<br>            <span class="hljs-string">&quot;conv_kernel&quot;</span> : CONV_KERNEL_SIZE,<br>            <span class="hljs-string">&quot;img_count&quot;</span> : <span class="hljs-built_in">min</span>(<span class="hljs-number">10000</span>, NUM_IMAGES_PER_BATCH*NUM_BATCHES_TO_LOG)&#125;)<br><br><span class="hljs-comment"># define model, loss, and optimizer</span><br>model = ConvNet(NUM_CLASSES).to(device)<br>criterion = nn.CrossEntropyLoss()<br>optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)<br><br><span class="hljs-comment"># convenience funtion to log predictions for a batch of test images</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">log_test_predictions</span>(<span class="hljs-params">images, labels, outputs, predicted, test_table, log_counter</span>):<br>  <span class="hljs-comment"># obtain confidence scores for all classes</span><br>  scores = F.softmax(outputs.data, dim=<span class="hljs-number">1</span>)<br>  log_scores = scores.cpu().numpy()<br>  log_images = images.cpu().numpy()<br>  log_labels = labels.cpu().numpy()<br>  log_preds = predicted.cpu().numpy()<br>  <span class="hljs-comment"># adding ids based on the order of the images</span><br>  _<span class="hljs-built_in">id</span> = <span class="hljs-number">0</span><br>  <span class="hljs-keyword">for</span> i, l, p, s <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(log_images, log_labels, log_preds, log_scores):<br>    <span class="hljs-comment"># add required info to data table:</span><br>    <span class="hljs-comment"># id, image pixels, model&#x27;s guess, true label, scores for all classes</span><br>    img_id = <span class="hljs-built_in">str</span>(_<span class="hljs-built_in">id</span>) + <span class="hljs-string">&quot;_&quot;</span> + <span class="hljs-built_in">str</span>(log_counter)<br>    test_table.add_data(img_id, wandb.Image(i), p, l, *s)<br>    _<span class="hljs-built_in">id</span> += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> _<span class="hljs-built_in">id</span> == NUM_IMAGES_PER_BATCH:<br>      <span class="hljs-keyword">break</span><br><br><span class="hljs-comment"># train the model</span><br>total_step = <span class="hljs-built_in">len</span>(train_loader)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(EPOCHS):<br>    <span class="hljs-comment"># training step</span><br>    <span class="hljs-keyword">for</span> i, (images, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        images = images.to(device)<br>        labels = labels.to(device)<br>        <span class="hljs-comment"># forward pass</span><br>        outputs = model(images)<br>        loss = criterion(outputs, labels)<br>        <span class="hljs-comment"># backward and optimize</span><br>        optimizer.zero_grad()<br>        loss.backward()<br>        optimizer.step()<br>  <br>        <span class="hljs-comment"># âœ¨ W&amp;B: Log loss over training steps, visualized in the UI live</span><br>        wandb.log(&#123;<span class="hljs-string">&quot;loss&quot;</span> : loss&#125;)<br>        <span class="hljs-keyword">if</span> (i+<span class="hljs-number">1</span>) % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], Loss: &#123;:.4f&#125;&#x27;</span><br>                .<span class="hljs-built_in">format</span>(epoch+<span class="hljs-number">1</span>, EPOCHS, i+<span class="hljs-number">1</span>, total_step, loss.item()))<br>            <br><br>    <span class="hljs-comment"># âœ¨ W&amp;B: Create a Table to store predictions for each test step</span><br>    columns=[<span class="hljs-string">&quot;id&quot;</span>, <span class="hljs-string">&quot;image&quot;</span>, <span class="hljs-string">&quot;guess&quot;</span>, <span class="hljs-string">&quot;truth&quot;</span>]<br>    <span class="hljs-keyword">for</span> digit <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>      columns.append(<span class="hljs-string">&quot;score_&quot;</span> + <span class="hljs-built_in">str</span>(digit))<br>    test_table = wandb.Table(columns=columns)<br><br>    <span class="hljs-comment"># test the model</span><br>    model.<span class="hljs-built_in">eval</span>()<br>    log_counter = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        correct = <span class="hljs-number">0</span><br>        total = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> images, labels <span class="hljs-keyword">in</span> test_loader:<br>            images = images.to(device)<br>            labels = labels.to(device)<br>            outputs = model(images)<br>            _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">if</span> log_counter &lt; NUM_BATCHES_TO_LOG:<br>              log_test_predictions(images, labels, outputs, predicted, test_table, log_counter)<br>              log_counter += <span class="hljs-number">1</span><br>            total += labels.size(<span class="hljs-number">0</span>)<br>            correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br>        acc = <span class="hljs-number">100</span> * correct / total<br>        <span class="hljs-comment"># âœ¨ W&amp;B: Log accuracy across training epochs, to visualize in the UI</span><br>        wandb.log(&#123;<span class="hljs-string">&quot;epoch&quot;</span> : epoch, <span class="hljs-string">&quot;acc&quot;</span> : acc&#125;)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Test Accuracy of the model on the 10000 test images: &#123;&#125; %&#x27;</span>.<span class="hljs-built_in">format</span>(acc))<br><br>    <span class="hljs-comment"># âœ¨ W&amp;B: Log predictions table to wandb</span><br>    wandb.log(&#123;<span class="hljs-string">&quot;test_predictions&quot;</span> : test_table&#125;)<br><br><span class="hljs-comment"># âœ¨ W&amp;B: Mark the run as complete (useful for multi-cell notebook)</span><br>wandb.finish()<br></code></pre></td></tr></table></figure>
<h2 id="tune-hyperparameters">Tune hyperparameters</h2>
<p><a
target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W&amp;B.ipynb">åœ¨æ­¤å¤„è¯•ç”¨
Colab Notebook â†’</a></p>
<p>åœ¨é«˜ç»´è¶…å‚æ•°ç©ºé—´ä¸­æœç´¢ä»¥æ‰¾åˆ°æ€§èƒ½æœ€é«˜çš„æ¨¡å‹å¯èƒ½ä¼šå¾ˆå¿«å˜å¾—ç¬¨æ‹™ã€‚è¶…å‚æ•°æ‰«ææä¾›äº†ä¸€ç§æœ‰ç»„ç»‡ä¸”é«˜æ•ˆçš„æ–¹å¼æ¥è¿›è¡Œæ¨¡å‹å¤§é€ƒæ€å¹¶é€‰æ‹©æœ€å‡†ç¡®çš„æ¨¡å‹ã€‚ä»–ä»¬é€šè¿‡è‡ªåŠ¨æœç´¢è¶…å‚æ•°å€¼çš„ç»„åˆï¼ˆä¾‹å¦‚
learning rate, batch size, number of hidden layers, optimizer
typeï¼‰æ¥æ‰¾åˆ°æœ€ä½³å€¼æ¥å®ç°è¿™ä¸€ç‚¹ã€‚</p>
<p>åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£å¦‚ä½•ä½¿ç”¨ Weights &amp; Biases é€šè¿‡ 3
ä¸ªç®€å•æ­¥éª¤è¿è¡Œå¤æ‚çš„è¶…å‚æ•°æ‰«æã€‚</p>
<h3 id="follow-along-with-a-video-tutorial">Follow along with a <a
target="_blank" rel="noopener" href="http://wandb.me/sweeps-video">video tutorial</a>!</h3>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedWVKkMWw.png"
alt="tune hyperparameters" />
<figcaption aria-hidden="true">tune hyperparameters</figcaption>
</figure>
<h3 id="setup-1">Setup</h3>
<p>é¦–å…ˆå®‰è£…å®éªŒè·Ÿè¸ªåº“å¹¶è®¾ç½®æ‚¨çš„å…è´¹ W&amp;B å¸æˆ·ï¼š</p>
<ol type="1">
<li>ä½¿ç”¨ <code>pip install</code> å®‰è£…</li>
<li><code>import</code> Python æ‰€éœ€ä¾èµ–</li>
<li><code>.login()</code> è¿™æ ·æ‚¨å°±å¯ä»¥å°†æŒ‡æ ‡è®°å½•åˆ°æ‚¨çš„é¡¹ç›®ä¸­</li>
</ol>
<p>å¦‚æœæ‚¨ä»¥å‰ä»æœªä½¿ç”¨è¿‡ Weights &amp;
Biasesï¼Œç™»å½•ç”µè¯ä¼šç»™æ‚¨ä¸€ä¸ªæ³¨å†Œå¸æˆ·çš„é“¾æ¥ã€‚ W&amp;B
å¯å…è´¹ç”¨äºä¸ªäººå’Œå­¦æœ¯é¡¹ç›®ï¼</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">!pip install wandb -Uq<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> wandb<br><br>wandb.login()<br></code></pre></td></tr></table></figure>
<h3 id="step-1.-define-the-sweep">Step 1ï¸âƒ£. Define the Sweep</h3>
<p>ä»æ ¹æœ¬ä¸Šè¯´ï¼ŒSweep
å°†å°è¯•ä¸€å †è¶…å‚æ•°å€¼çš„ç­–ç•¥ä¸è¯„ä¼°å®ƒä»¬çš„ä»£ç ç»“åˆåœ¨ä¸€èµ·ã€‚æ‚¨åªéœ€è¦ä»¥<a
target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/configuration">é…ç½®</a>çš„å½¢å¼å®šä¹‰æ‚¨çš„ç­–ç•¥ã€‚</p>
<p>å½“æ‚¨åƒè¿™æ ·åœ¨ç¬”è®°æœ¬ä¸­è®¾ç½® Sweep
æ—¶ï¼Œè¯¥é…ç½®å¯¹è±¡æ˜¯ä¸€ä¸ªåµŒå¥—å­—å…¸ã€‚å½“æ‚¨é€šè¿‡å‘½ä»¤è¡Œè¿è¡Œ Sweep
æ—¶ï¼Œé…ç½®å¯¹è±¡æ˜¯ä¸€ä¸ª <a
target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/quickstart#2-sweep-config">YAML
file</a>ã€‚</p>
<p>è®©æˆ‘ä»¬ä¸€èµ·äº†è§£ Sweep
é…ç½®çš„å®šä¹‰ã€‚æˆ‘ä»¬ä¼šæ…¢æ…¢æ¥ï¼Œè¿™æ ·æˆ‘ä»¬å°±æœ‰æœºä¼šè§£é‡Šæ¯ä¸ªç»„ä»¶ã€‚åœ¨å…¸å‹çš„ Sweep
ç®¡é“ä¸­ï¼Œæ­¤æ­¥éª¤å°†åœ¨å•ä¸ªåˆ†é…ä¸­å®Œæˆã€‚</p>
<h4 id="pick-a-method">Pick a <code>method</code></h4>
<p>æˆ‘ä»¬éœ€è¦å®šä¹‰çš„ç¬¬ä¸€ä»¶äº‹æ˜¯é€‰æ‹©æ–°å‚æ•°å€¼çš„ <code>method</code>ã€‚</p>
<p>æˆ‘ä»¬æä¾›ä»¥ä¸‹æœç´¢ <code>methods</code>ï¼š</p>
<ul>
<li><strong><code>grid</code> Search </strong>â€“
è¿­ä»£è¶…å‚æ•°å€¼çš„æ¯ä¸ªç»„åˆã€‚éå¸¸æœ‰æ•ˆï¼Œä½†è®¡ç®—é‡å¤§ã€‚</li>
<li><strong><code>random</code> Search</strong> â€“ æ ¹æ®æä¾›çš„
<code>distribution</code> éšæœºé€‰æ‹©æ¯ä¸ªæ–°ç»„åˆã€‚å‡ºä¹æ„æ–™çš„æœ‰æ•ˆï¼</li>
<li><strong><code>bayesian</code> Search</strong> â€“
åˆ›å»ºä¸€ä¸ªåº¦é‡åˆ†æ•°ä½œä¸ºè¶…å‚æ•°å‡½æ•°çš„æ¦‚ç‡æ¨¡å‹ï¼Œå¹¶é€‰æ‹©å…·æœ‰æé«˜åº¦é‡çš„é«˜æ¦‚ç‡çš„å‚æ•°ã€‚é€‚ç”¨äºå°‘é‡è¿ç»­å‚æ•°ä½†æ‰©å±•æ€§å·®ã€‚</li>
</ul>
<p><code>random</code> æ–¹æ³•ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">sweep_config = &#123;<br>    <span class="hljs-string">&#x27;method&#x27;</span>: <span class="hljs-string">&#x27;random&#x27;</span><br>    &#125;<br></code></pre></td></tr></table></figure>
<p>å¯¹äº <code>bayesian</code> Sweepsï¼Œæ‚¨è¿˜éœ€è¦å‘Šè¯‰æˆ‘ä»¬ä¸€äº›å…³äºæ‚¨çš„
metric
çš„ä¿¡æ¯ã€‚æˆ‘ä»¬éœ€è¦çŸ¥é“å®ƒçš„åç§°ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥åœ¨æ¨¡å‹è¾“å‡ºä¸­æ‰¾åˆ°å®ƒï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“æ‚¨çš„ç›®æ ‡æ˜¯æœ€å°åŒ–å®ƒï¼ˆä¾‹å¦‚ï¼Œå¦‚æœå®ƒæ˜¯
squared errorï¼‰è¿˜æ˜¯æœ€å¤§åŒ–å®ƒï¼ˆä¾‹å¦‚ï¼Œå¦‚æœå®ƒæ˜¯ accuracyï¼‰ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">metric = &#123;<br>    <span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;loss&#x27;</span>,<br>    <span class="hljs-string">&#x27;goal&#x27;</span>: <span class="hljs-string">&#x27;minimize&#x27;</span>   <br>    &#125;<br><br>sweep_config[<span class="hljs-string">&#x27;metric&#x27;</span>] = metric<br></code></pre></td></tr></table></figure>
<p>å¦‚æœæ‚¨æ²¡æœ‰è¿è¡Œ <code>bayesian</code>
Sweepï¼Œåˆ™ä¸å¿…è¿™æ ·åšï¼Œä½†æ— è®ºå¦‚ä½•å°†å…¶åŒ…å«åœ¨æ‚¨çš„ <code>sweep_config</code>
ä¸­å¹¶ä¸æ˜¯ä¸€ä¸ªåä¸»æ„ï¼Œä»¥é˜²æ‚¨ä»¥åæ”¹å˜ä¸»æ„ã€‚è®°å½•è¿™æ ·çš„äº‹æƒ…ä¹Ÿæ˜¯å¾ˆå¥½çš„å†ç°æ€§å®è·µï¼Œä»¥é˜²ä¸‡ä¸€æ‚¨æˆ–å…¶ä»–äººåœ¨
6 ä¸ªæœˆæˆ– 6 å¹´åå›åˆ°æ‚¨çš„ Sweep å¹¶ä¸”ä¸çŸ¥é“ <code>val_G_batch</code>
åº”è¯¥æ˜¯é«˜è¿˜æ˜¯ä½ã€‚</p>
<h4 id="name-the-hyperparameters">Name the
hyper<code>parameters</code></h4>
<p>ä¸€æ—¦æ‚¨é€‰æ‹©äº†ä¸€ç§ <code>method</code>
æ¥å°è¯•è¶…å‚æ•°çš„æ–°å€¼ï¼Œæ‚¨éœ€è¦å®šä¹‰è¿™äº› <code>parameters</code>æ˜¯ä»€ä¹ˆ</p>
<p>å¤§å¤šæ•°æ—¶å€™ï¼Œè¿™ä¸€æ­¥å¾ˆç®€å•ï¼šæ‚¨åªéœ€ä¸º <code>parameter</code>
å‘½åå¹¶æŒ‡å®šå‚æ•°çš„åˆæ³• <code>values</code> åˆ—è¡¨ã€‚</p>
<p>ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬ä¸ºæˆ‘ä»¬çš„ç½‘ç»œé€‰æ‹© <code>optimizer</code>
æ—¶ï¼Œåªæœ‰æœ‰é™æ•°é‡çš„é€‰é¡¹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åšæŒä½¿ç”¨ä¸¤ä¸ªæœ€å—æ¬¢è¿çš„é€‰æ‹©ï¼Œ<code>adam</code>
å’Œ
<code>sgd</code>ã€‚å³ä½¿å¯¹äºå…·æœ‰æ½œåœ¨æ— é™é€‰é¡¹çš„è¶…å‚æ•°ï¼Œé€šå¸¸ä¹Ÿåªå°è¯•å‡ ä¸ªé€‰æ‹©
<code>values</code> æ‰æœ‰æ„ä¹‰ï¼Œå°±åƒæˆ‘ä»¬åœ¨æ­¤å¤„å¯¹éšè—å±‚
<code>layer_size</code> å’Œ <code>dropout</code> æ‰€åšçš„é‚£æ ·ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">parameters_dict = &#123;<br>    <span class="hljs-string">&#x27;optimizer&#x27;</span>: &#123;<br>        <span class="hljs-string">&#x27;values&#x27;</span>: [<span class="hljs-string">&#x27;adam&#x27;</span>, <span class="hljs-string">&#x27;sgd&#x27;</span>]<br>        &#125;,<br>    <span class="hljs-string">&#x27;fc_layer_size&#x27;</span>: &#123;<br>        <span class="hljs-string">&#x27;values&#x27;</span>: [<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>]<br>        &#125;,<br>    <span class="hljs-string">&#x27;dropout&#x27;</span>: &#123;<br>          <span class="hljs-string">&#x27;values&#x27;</span>: [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.5</span>]<br>        &#125;,<br>    &#125;<br><br>sweep_config[<span class="hljs-string">&#x27;parameters&#x27;</span>] = parameters_dict<br></code></pre></td></tr></table></figure>
<p>é€šå¸¸æƒ…å†µä¸‹ï¼Œæœ‰äº›è¶…å‚æ•°æˆ‘ä»¬ä¸æƒ³åœ¨æ­¤ Sweep ä¸­æ”¹å˜ï¼Œä½†æˆ‘ä»¬ä»å¸Œæœ›åœ¨æˆ‘ä»¬çš„
<code>sweep_config</code> ä¸­è®¾ç½®å®ƒä»¬ã€‚</p>
<p>åœ¨é‚£ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç›´æ¥è®¾ç½® <code>value</code>ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">parameters_dict.update(&#123;<br>    <span class="hljs-string">&#x27;epochs&#x27;</span>: &#123;<br>        <span class="hljs-string">&#x27;value&#x27;</span>: <span class="hljs-number">1</span>&#125;<br>    &#125;)<br></code></pre></td></tr></table></figure>
<p>å¯¹äº <code>grid</code> æœç´¢ï¼Œè¿™å°±æ˜¯æ‚¨æ‰€éœ€è¦çš„ã€‚</p>
<p>å¯¹äº <code>random</code> æœç´¢ï¼Œå‚æ•°çš„æ‰€æœ‰ <code>values</code>
åœ¨ç»™å®šè¿è¡Œä¸­è¢«é€‰æ‹©çš„å¯èƒ½æ€§ç›¸åŒã€‚</p>
<p>å¦‚æœè¿™æ ·åšä¸è¡Œï¼Œæ‚¨å¯ä»¥æ”¹ä¸ºæŒ‡å®šå‘½å <code>distribution</code>
åŠå…¶å‚æ•°ï¼Œä¾‹å¦‚ <code>normal</code> åˆ†å¸ƒçš„å‡å€¼ <code>mu</code> å’Œæ ‡å‡†å·®
<code>sigma</code>ã€‚</p>
<p>åœ¨<a
target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/configuration#distributions">æ­¤å¤„</a>æŸ¥çœ‹æœ‰å…³å¦‚ä½•è®¾ç½®éšæœºå˜é‡åˆ†å¸ƒçš„æ›´å¤šä¿¡æ¯ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">parameters_dict.update(&#123;<br>    <span class="hljs-string">&#x27;learning_rate&#x27;</span>: &#123;<br>        <span class="hljs-comment"># a flat distribution between 0 and 0.1</span><br>        <span class="hljs-string">&#x27;distribution&#x27;</span>: <span class="hljs-string">&#x27;uniform&#x27;</span>,<br>        <span class="hljs-string">&#x27;min&#x27;</span>: <span class="hljs-number">0</span>,<br>        <span class="hljs-string">&#x27;max&#x27;</span>: <span class="hljs-number">0.1</span><br>      &#125;,<br>    <span class="hljs-string">&#x27;batch_size&#x27;</span>: &#123;<br>        <span class="hljs-comment"># integers between 32 and 256</span><br>        <span class="hljs-comment"># with evenly-distributed logarithms </span><br>        <span class="hljs-string">&#x27;distribution&#x27;</span>: <span class="hljs-string">&#x27;q_log_uniform_values&#x27;</span>,<br>        <span class="hljs-string">&#x27;q&#x27;</span>: <span class="hljs-number">8</span>,<br>        <span class="hljs-string">&#x27;min&#x27;</span>: <span class="hljs-number">32</span>,<br>        <span class="hljs-string">&#x27;max&#x27;</span>: <span class="hljs-number">256</span>,<br>      &#125;<br>    &#125;)<br></code></pre></td></tr></table></figure>
<p>å½“æˆ‘ä»¬å®Œæˆåï¼Œ<code>sweep_config</code>
æ˜¯ä¸€ä¸ªåµŒå¥—çš„å­—å…¸ï¼Œå®ƒå‡†ç¡®åœ°æŒ‡å®šäº†æˆ‘ä»¬æœ‰å…´è¶£å°è¯•å“ªäº›
<code>parameters</code> ä»¥åŠæˆ‘ä»¬å°†ä½¿ç”¨ä»€ä¹ˆ <code>method</code>
æ¥å°è¯•å®ƒä»¬ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pprint<br><br>pprint.pprint(sweep_config)<br></code></pre></td></tr></table></figure>
<p>ä½†è¿™ä¸æ˜¯æ‰€æœ‰çš„é…ç½®é€‰é¡¹ï¼</p>
<p>ä¾‹å¦‚ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä½¿ç”¨ <a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.06560.pdf">HyperBand</a> è°ƒåº¦ç®—æ³•
<code>early_terminate</code> è¿è¡Œçš„é€‰é¡¹ã€‚åœ¨<a
target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/configuration#stopping-criteria">è¿™é‡Œ</a>æŸ¥çœ‹æ›´å¤šã€‚</p>
<p>æ‚¨å¯ä»¥åœ¨<a
target="_blank" rel="noopener" href="https://docs.wandb.com/library/sweeps/configuration">æ­¤å¤„</a>æ‰¾åˆ°æ‰€æœ‰é…ç½®é€‰é¡¹çš„åˆ—è¡¨ï¼Œå¹¶åœ¨<a
target="_blank" rel="noopener" href="https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion">æ­¤å¤„</a>æ‰¾åˆ°å¤§é‡
YAML æ ¼å¼çš„ç¤ºä¾‹ã€‚</p>
<h3 id="step-2.-initialize-the-sweep">Step 2ï¸âƒ£. Initialize the Sweep</h3>
<p>ä¸€æ—¦æ‚¨å®šä¹‰äº†æœç´¢ç­–ç•¥ï¼Œå°±è¯¥è®¾ç½®ä¸€äº›ä¸œè¥¿æ¥å®ç°å®ƒäº†ã€‚</p>
<p>è´Ÿè´£æˆ‘ä»¬ Sweep çš„ clockwork taskmaster è¢«ç§°ä¸º <em>Sweep
Controller</em>ã€‚æ¯æ¬¡è¿è¡Œå®Œæˆæ—¶ï¼Œå®ƒå°†å‘å‡ºä¸€ç»„æ–°çš„æŒ‡ä»¤æ¥æè¿°è¦æ‰§è¡Œçš„æ–°è¿è¡Œã€‚è¿™äº›æŒ‡ä»¤ç”±å®é™…æ‰§è¡Œè¿è¡Œçš„
<em>agents</em> è·å–ã€‚</p>
<p>åœ¨å…¸å‹çš„ Sweep ä¸­ï¼ŒController
ä½äºæˆ‘ä»¬çš„æœºå™¨ä¸Šï¼Œè€Œå®Œæˆè¿è¡Œçš„ä»£ç†ä½äºæ‚¨çš„æœºå™¨ä¸Šï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚è¿™ç§åˆ†å·¥ä½¿å¾—åªéœ€æ·»åŠ æ›´å¤šæœºå™¨æ¥è¿è¡Œä»£ç†å°±å¯ä»¥éå¸¸å®¹æ˜“åœ°æ‰©å±•
Sweepsï¼</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedzlbw3vQ.png"
alt="sweeps-diagram" />
<figcaption aria-hidden="true">sweeps-diagram</figcaption>
</figure>
<p>æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨é€‚å½“çš„ <code>sweep_config</code> å’Œ
<code>project</code> åç§°è°ƒç”¨ <code>wandb.sweep</code> æ¥ç»“æŸ Sweep
Controllerã€‚</p>
<p>æ­¤å‡½æ•°è¿”å›ä¸€ä¸ª <code>sweep_id</code>ï¼Œæˆ‘ä»¬ç¨åå°†ä½¿ç”¨å®ƒæ¥å°† agents
åˆ†é…ç»™æ­¤ Controllerã€‚</p>
<p>æ—æ³¨ï¼šåœ¨å‘½ä»¤è¡Œä¸Šï¼Œæ­¤åŠŸèƒ½è¢«æ›¿æ¢ä¸º</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wandb sweep config.yaml<br></code></pre></td></tr></table></figure>
<p><a
target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/quickstart">äº†è§£æ›´å¤šå…³äºåœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨
Sweeps â¡</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">sweep_id = wandb.sweep(sweep_config, project=<span class="hljs-string">&quot;pytorch-sweeps-demo&quot;</span>)<br></code></pre></td></tr></table></figure>
<h3 id="step-3.-run-the-sweep-agent">Step 3ï¸âƒ£. Run the Sweep agent</h3>
<h4 id="define-your-training-procedure">Define Your Training
Procedure</h4>
<p>åœ¨æˆ‘ä»¬å®é™…æ‰§è¡Œ sweep ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä½¿ç”¨è¿™äº›å€¼çš„è®­ç»ƒè¿‡ç¨‹ã€‚</p>
<p>åœ¨ä¸‹é¢çš„å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬åœ¨ PyTorch
ä¸­å®šä¹‰äº†ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œå¹¶æ·»åŠ äº†ä»¥ä¸‹ <code>wandb</code>
å·¥å…·æ¥è®°å½•æ¨¡å‹æŒ‡æ ‡ã€å¯è§†åŒ–æ€§èƒ½å’Œè¾“å‡ºå¹¶è·Ÿè¸ªæˆ‘ä»¬çš„å®éªŒï¼š</p>
<ul>
<li><a
target="_blank" rel="noopener" href="https://docs.wandb.com/library/init"><strong><code>wandb.init()</code></strong></a>
â€“ åˆå§‹åŒ–æ–°çš„ W&amp;B è¿è¡Œã€‚æ¯æ¬¡è¿è¡Œéƒ½æ˜¯è®­ç»ƒåŠŸèƒ½çš„ä¸€æ¬¡æ‰§è¡Œã€‚</li>
<li><a
target="_blank" rel="noopener" href="https://docs.wandb.com/library/config"><strong><code>wandb.config</code></strong></a>
â€“ å°†æ‰€æœ‰è¶…å‚æ•°ä¿å­˜åœ¨é…ç½®å¯¹è±¡ä¸­ï¼Œä»¥ä¾¿è®°å½•å®ƒä»¬ã€‚åœ¨<a
target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-config/Configs_in_W%26B.ipynb">æ­¤å¤„</a>é˜…è¯»æœ‰å…³å¦‚ä½•ä½¿ç”¨
<code>wandb.config</code> çš„æ›´å¤šä¿¡æ¯ã€‚</li>
<li><a
target="_blank" rel="noopener" href="https://docs.wandb.com/library/log"><strong><code>wandb.log()</code></strong></a>
â€“ å°†æ¨¡å‹è¡Œä¸ºè®°å½•åˆ° W&amp;Bã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åªè®°å½•æ€§èƒ½ï¼›æœ‰å…³å¯ä»¥ä½¿ç”¨
<code>wandb.log</code> è®°å½•çš„æ‰€æœ‰å…¶ä»–å¯Œåª’ä½“ï¼Œè¯·å‚é˜…æ­¤ <a
target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Log_(Almost)_Anything_with_W%26B_Media.ipynb">Colab</a>ã€‚</li>
</ul>
<p>æœ‰å…³ä½¿ç”¨ PyTorch æ£€æµ‹ W&amp;B çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ­¤ <a
target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb">Colab</a>ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">config=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-comment"># Initialize a new wandb run</span><br>    <span class="hljs-keyword">with</span> wandb.init(config=config):<br>        <span class="hljs-comment"># If called by wandb.agent, as below,</span><br>        <span class="hljs-comment"># this config will be set by Sweep Controller</span><br>        config = wandb.config<br><br>        loader = build_dataset(config.batch_size)<br>        network = build_network(config.fc_layer_size, config.dropout)<br>        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)<br><br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.epochs):<br>            avg_loss = train_epoch(network, loader, optimizer)<br>            wandb.log(&#123;<span class="hljs-string">&quot;loss&quot;</span>: avg_loss, <span class="hljs-string">&quot;epoch&quot;</span>: epoch&#125;)           <br></code></pre></td></tr></table></figure>
<p>è¿™ä¸ªå•å…ƒæ ¼å®šä¹‰äº†æˆ‘ä»¬è®­ç»ƒè¿‡ç¨‹çš„å››ä¸ªéƒ¨åˆ†ï¼š<code>build_dataset</code>,
<code>build_network</code>, <code>build_optimizer</code>
å’Œ<code>train_epoch</code>.</p>
<p>æ‰€æœ‰è¿™äº›éƒ½æ˜¯åŸºæœ¬ PyTorch ç®¡é“çš„æ ‡å‡†éƒ¨åˆ†ï¼Œå®ƒä»¬çš„å®ç°ä¸å—ä½¿ç”¨ W&amp;B
çš„å½±å“ï¼Œå› æ­¤æˆ‘ä»¬ä¸ä¼šå¯¹å®ƒä»¬å‘è¡¨è¯„è®ºã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_dataset</span>(<span class="hljs-params">batch_size</span>):<br>   <br>    transform = transforms.Compose(<br>        [transforms.ToTensor(),<br>         transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))])<br>    <span class="hljs-comment"># download MNIST training dataset</span><br>    dataset = datasets.MNIST(<span class="hljs-string">&quot;.&quot;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>,<br>                             transform=transform)<br>    sub_dataset = torch.utils.data.Subset(<br>        dataset, indices=<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(dataset), <span class="hljs-number">5</span>))<br>    loader = torch.utils.data.DataLoader(sub_dataset, batch_size=batch_size)<br><br>    <span class="hljs-keyword">return</span> loader<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_network</span>(<span class="hljs-params">fc_layer_size, dropout</span>):<br>    network = nn.Sequential(  <span class="hljs-comment"># fully-connected, single hidden layer</span><br>        nn.Flatten(),<br>        nn.Linear(<span class="hljs-number">784</span>, fc_layer_size), nn.ReLU(),<br>        nn.Dropout(dropout),<br>        nn.Linear(fc_layer_size, <span class="hljs-number">10</span>),<br>        nn.LogSoftmax(dim=<span class="hljs-number">1</span>))<br><br>    <span class="hljs-keyword">return</span> network.to(device)<br>        <br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_optimizer</span>(<span class="hljs-params">network, optimizer, learning_rate</span>):<br>    <span class="hljs-keyword">if</span> optimizer == <span class="hljs-string">&quot;sgd&quot;</span>:<br>        optimizer = optim.SGD(network.parameters(),<br>                              lr=learning_rate, momentum=<span class="hljs-number">0.9</span>)<br>    <span class="hljs-keyword">elif</span> optimizer == <span class="hljs-string">&quot;adam&quot;</span>:<br>        optimizer = optim.Adam(network.parameters(),<br>                               lr=learning_rate)<br>    <span class="hljs-keyword">return</span> optimizer<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_epoch</span>(<span class="hljs-params">network, loader, optimizer</span>):<br>    cumu_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> _, (data, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>        data, target = data.to(device), target.to(device)<br>        optimizer.zero_grad()<br><br>        <span class="hljs-comment"># â¡ Forward pass</span><br>        loss = F.nll_loss(network(data), target)<br>        cumu_loss += loss.item()<br><br>        <span class="hljs-comment"># â¬… Backward pass + weight update</span><br>        loss.backward()<br>        optimizer.step()<br><br>        wandb.log(&#123;<span class="hljs-string">&quot;batch loss&quot;</span>: loss.item()&#125;)<br><br>    <span class="hljs-keyword">return</span> cumu_loss / <span class="hljs-built_in">len</span>(loader)<br></code></pre></td></tr></table></figure>
<p>ç°åœ¨ï¼Œæˆ‘ä»¬å‡†å¤‡å¼€å§‹ sweeping äº†ï¼</p>
<p>Sweep Controllersï¼Œå°±åƒæˆ‘ä»¬é€šè¿‡è¿è¡Œ <code>wandb.sweep</code>
åˆ¶ä½œçš„æ§åˆ¶å™¨ä¸€æ ·ï¼Œåç­‰æœ‰äººè¦æ±‚ä»–ä»¬æä¾› <code>config</code>æ¥è¯•ç”¨ã€‚</p>
<p>æŸäººæ˜¯ <code>agent</code>ï¼Œä»–ä»¬æ˜¯ç”¨ <code>wandb.agent</code>
åˆ›å»ºçš„ã€‚è¦å¼€å§‹ï¼Œagent åªéœ€è¦çŸ¥é“</p>
<ol type="1">
<li>å®ƒæ˜¯ (<code>sweep_id</code>) çš„ä¸€éƒ¨åˆ†</li>
<li>å®ƒåº”è¯¥è¿è¡Œå“ªä¸ªå‡½æ•°ï¼ˆè¿™é‡Œæ˜¯ <code>train</code>ï¼‰</li>
<li>ï¼ˆå¯é€‰ï¼‰æœ‰å¤šå°‘é…ç½®è¦æ±‚æ§åˆ¶å™¨ï¼ˆ<code>count</code>ï¼‰</li>
</ol>
<p>ä»…ä¾›å‚è€ƒï¼Œæ‚¨å¯ä»¥åœ¨ä¸åŒçš„è®¡ç®—èµ„æºä¸Šå¯åŠ¨å…·æœ‰ç›¸åŒ <code>sweep_id</code>
çš„å¤šä¸ª <code>agent</code>ï¼ŒController å°†ç¡®ä¿å®ƒä»¬æ ¹æ®
<code>sweep_config</code>
ä¸­åˆ¶å®šçš„ç­–ç•¥ååŒå·¥ä½œã€‚è¿™ä½¿å¾—åœ¨å°½å¯èƒ½å¤šçš„èŠ‚ç‚¹ä¸Šæ‰©å±• Sweeps
å˜å¾—è½»è€Œæ˜“ä¸¾ï¼</p>
<p>æ—æ³¨ï¼šåœ¨å‘½ä»¤è¡Œä¸Šï¼Œæ­¤åŠŸèƒ½è¢«æ›¿æ¢ä¸º</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wandb agent sweep_id<br></code></pre></td></tr></table></figure>
<p><a
target="_blank" rel="noopener" href="https://docs.wandb.com/sweeps/quickstart">äº†è§£æ›´å¤šå…³äºåœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨
Sweeps â¡</a></p>
<p>ä¸‹é¢çš„å•å…ƒæ ¼å°†å¯åŠ¨ä¸€ä¸ªè¿è¡Œ <code>train</code> 5 æ¬¡çš„
<code>agent</code>ï¼Œä½¿ç”¨ Sweep Controller
è¿”å›çš„éšæœºç”Ÿæˆçš„è¶…å‚æ•°å€¼ã€‚æ‰§è¡Œæ—¶é—´ä¸åˆ° 5 åˆ†é’Ÿã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">wandb.agent(sweep_id, train, count=<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure>
<h3 id="visualize-sweep-results">Visualize Sweep Results</h3>
<h4 id="parallel-coordinates-plot">Parallel Coordinates Plot</h4>
<p>æ­¤å›¾å°†è¶…å‚æ•°å€¼æ˜ å°„åˆ°æ¨¡å‹æŒ‡æ ‡ã€‚å®ƒå¯¹äºç£¨ç»ƒå¯¼è‡´æœ€ä½³æ¨¡å‹æ€§èƒ½çš„è¶…å‚æ•°ç»„åˆå¾ˆæœ‰ç”¨ã€‚</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefined5e190366778ad831455f9af2_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695138341_image.png"
alt="hyperparameters map to metrics" />
<figcaption aria-hidden="true">hyperparameters map to
metrics</figcaption>
</figure>
<h4 id="hyperparameter-importance-plot">Hyperparameter Importance
Plot</h4>
<p>è¶…å‚æ•°é‡è¦æ€§å›¾è¡¨æ˜å“ªäº›è¶…å‚æ•°æ˜¯æŒ‡æ ‡çš„æœ€ä½³é¢„æµ‹å› å­ã€‚æˆ‘ä»¬æŠ¥å‘Šç‰¹å¾é‡è¦æ€§ï¼ˆæ¥è‡ªéšæœºæ£®æ—æ¨¡å‹ï¼‰å’Œç›¸å…³æ€§ï¼ˆéšå¼çº¿æ€§æ¨¡å‹ï¼‰ã€‚</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefined5e190367778ad820b35f9af5_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695757573_image.png"
alt="parameter importance" />
<figcaption aria-hidden="true">parameter importance</figcaption>
</figure>
<p>è¿™äº›å¯è§†åŒ–å¯ä»¥é€šè¿‡ç£¨ç»ƒæœ€é‡è¦çš„å‚æ•°ï¼ˆå’Œå€¼èŒƒå›´ï¼‰æ¥å¸®åŠ©æ‚¨èŠ‚çœè¿è¡Œæ˜‚è´µçš„è¶…å‚æ•°ä¼˜åŒ–çš„æ—¶é—´å’Œèµ„æºï¼Œå› æ­¤å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢ã€‚</p>
<h3 id="get-your-hands-dirty-with-sweeps">Get your hands dirty with
sweeps</h3>
<p>æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªç®€å•çš„è®­ç»ƒè„šæœ¬å’Œä¸€äº› <a
target="_blank" rel="noopener" href="https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion">sweep
configs</a> é£æ ¼ä¾›æ‚¨ä½¿ç”¨ã€‚æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨å°è¯•ä¸€ä¸‹ã€‚</p>
<p>è¯¥å­˜å‚¨åº“è¿˜æä¾›äº†ä¸€äº›ç¤ºä¾‹ï¼Œå¯å¸®åŠ©æ‚¨å°è¯•æ›´é«˜çº§çš„ sweep åŠŸèƒ½ï¼Œä¾‹å¦‚ <a
target="_blank" rel="noopener" href="https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/us0ifmrf?workspace=user-lavanyashukla&amp;_gl=1*1h57q6p*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjYyMjIyOS43LjAuMTY4NjYyMjIyOS42MC4wLjA.">Bayesian
Hyperband</a> å’Œ <a
target="_blank" rel="noopener" href="https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/xbs2wm5e?workspace=user-lavanyashukla&amp;_gl=1*5hk37j*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjYyMjIyOS43LjAuMTY4NjYyMjIyOS42MC4wLjA.">Hyperopt</a>ã€‚</p>
<h2 id="track-models-and-datasets">Track models and datasets</h2>
<p><a
target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-artifacts/Pipeline_Versioning_with_W&amp;B_Artifacts.ipynb">åœ¨æ­¤å¤„è¯•ç”¨
Colab Notebook â†’</a></p>
<p>åœ¨æ­¤ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨ W&amp;B Artifacts è·Ÿè¸ªæ‚¨çš„ ML
å®éªŒç®¡é“ã€‚</p>
<h4 id="follow-along-with-a-video-tutorial-1">Follow along with a <a
target="_blank" rel="noopener" href="http://tiny.cc/wb-artifacts-video">video tutorial</a>!</h4>
<h5 id="what-are-artifacts-and-why-should-i-care">What are Artifacts and
Why Should I Care?</h5>
<p>â€œartifactâ€ï¼Œå¦‚å¸Œè…ŠåŒè€³ç“¶ğŸºï¼Œæ˜¯ä¸€ä¸ªç”Ÿäº§çš„å¯¹è±¡â€”â€”ä¸€ä¸ªè¿‡ç¨‹çš„è¾“å‡ºã€‚åœ¨ ML
ä¸­ï¼Œæœ€é‡è¦çš„å·¥ä»¶æ˜¯ <em>datasets</em> å’Œ <em>models</em>ã€‚</p>
<p>è€Œä¸”ï¼Œå°±åƒ <a
target="_blank" rel="noopener" href="https://indianajones.fandom.com/wiki/Cross_of_Coronado">Cross of
Coronado</a>
ä¸€æ ·ï¼Œè¿™äº›é‡è¦çš„æ–‡ç‰©å±äºåšç‰©é¦†ï¼ä¹Ÿå°±æ˜¯è¯´ï¼Œåº”è¯¥å¯¹å®ƒä»¬è¿›è¡Œåˆ†ç±»å’Œç»„ç»‡ï¼Œä»¥ä¾¿æ‚¨ã€æ‚¨çš„å›¢é˜Ÿå’Œæ•´ä¸ª
ML ç¤¾åŒºå¯ä»¥å‘å®ƒä»¬å­¦ä¹ ã€‚æ¯•ç«Ÿï¼Œé‚£äº›ä¸è·Ÿè¸ªè®­ç»ƒçš„äººæ³¨å®šè¦é‡è¹ˆè¦†è¾™ã€‚</p>
<p>ä½¿ç”¨æˆ‘ä»¬çš„ Artifacts APIï¼Œæ‚¨å¯ä»¥å°† <code>Artifacts</code> è®°å½•ä¸º
W&amp;B <code>Runs</code> çš„è¾“å‡ºï¼Œæˆ–ä½¿ç”¨ <code>Artifacts</code> ä½œä¸º
<code>Runs</code>
çš„è¾“å…¥ï¼Œå¦‚æ­¤å›¾æ‰€ç¤ºï¼Œå…¶ä¸­è®­ç»ƒè¿è¡Œæ¥å—æ•°æ®é›†å¹¶ç”Ÿæˆæ¨¡å‹ã€‚</p>
<figure>
<img
src="https://blog-img-1304093596.cos.ap-shanghai.myqcloud.com/undefinedsimple%20artifact%20diagram%202.png"
alt="simple artifact diagram" />
<figcaption aria-hidden="true">simple artifact diagram</figcaption>
</figure>
<p>ç”±äºä¸€æ¬¡è¿è¡Œå¯ä»¥ä½¿ç”¨å¦ä¸€æ¬¡çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼Œå› æ­¤ Artifacts å’Œ Runs
ä¸€èµ·å½¢æˆäº†ä¸€ä¸ªæœ‰å‘å›¾â€”â€”å®é™…ä¸Šæ˜¯ä¸€ä¸ªäºŒåˆ† <a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a>ï¼ --
å¸¦æœ‰ <code>Artifact</code>s å’Œ <code>Run</code>s çš„èŠ‚ç‚¹ï¼Œä»¥åŠå°†
<code>Run</code>s è¿æ¥åˆ°å®ƒä»¬æ¶ˆè€—æˆ–ç”Ÿäº§çš„ <code>Artifact</code>s
çš„ç®­å¤´ã€‚</p>
<h3 id="install-and-import">0ï¸âƒ£ Install and Import</h3>
<p>Artifacts æ˜¯æˆ‘ä»¬ Python åº“çš„ä¸€éƒ¨åˆ†ï¼Œä» <code>0.9.2</code>
ç‰ˆå¼€å§‹ã€‚</p>
<p>ä¸ ML Python å †æ ˆçš„å¤§å¤šæ•°éƒ¨åˆ†ä¸€æ ·ï¼Œå®ƒå¯ä»¥é€šè¿‡ <code>pip</code>
è·å¾—ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Compatible with wandb version 0.9.2+</span><br>!pip install wandb -qqq<br>!apt install tree<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> wandb<br></code></pre></td></tr></table></figure>
<h3 id="log-a-dataset">1ï¸âƒ£ Log a Dataset</h3>
<p>é¦–å…ˆï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€äº› Artifactsã€‚</p>
<p>æ­¤ç¤ºä¾‹åŸºäºæ­¤ PyTorch <a
target="_blank" rel="noopener" href="https://github.com/pytorch/examples/tree/master/mnist/">"Basic
MNIST Example"</a>ï¼Œä½†å¯ä»¥åœ¨ <a
target="_blank" rel="noopener" href="http://wandb.me/artifacts-colab">TensorFlow</a>ã€ä»»ä½•å…¶ä»–æ¡†æ¶æˆ–çº¯
Python ä¸­è½»æ¾å®Œæˆã€‚</p>
<p>æˆ‘ä»¬ä» <code>Dataset</code>s å¼€å§‹ï¼š</p>
<ul>
<li>ä¸€ä¸ª <code>train</code>ing setï¼Œç”¨äºé€‰æ‹©å‚æ•°ï¼Œ</li>
<li>ä¸€ä¸ª <code>validation</code> setï¼Œç”¨äºé€‰æ‹©è¶…å‚æ•°ï¼Œ</li>
<li>ä¸€ä¸ª <code>test</code>ing setï¼Œç”¨äºè¯„ä¼°æœ€ç»ˆæ¨¡å‹</li>
</ul>
<p>ä¸‹é¢çš„ç¬¬ä¸€ä¸ªå•å…ƒæ ¼å®šä¹‰äº†è¿™ä¸‰ä¸ªæ•°æ®é›†ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random <br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset<br><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># Ensure deterministic behavior</span><br>torch.backends.cudnn.deterministic = <span class="hljs-literal">True</span><br>random.seed(<span class="hljs-number">0</span>)<br>torch.manual_seed(<span class="hljs-number">0</span>)<br>torch.cuda.manual_seed_all(<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># Device configuration</span><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><br><span class="hljs-comment"># Data parameters</span><br>num_classes = <span class="hljs-number">10</span><br>input_shape = (<span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)<br><br><span class="hljs-comment"># drop slow mirror from list of MNIST mirrors</span><br>torchvision.datasets.MNIST.mirrors = [mirror <span class="hljs-keyword">for</span> mirror <span class="hljs-keyword">in</span> torchvision.datasets.MNIST.mirrors<br>                                      <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> mirror.startswith(<span class="hljs-string">&quot;http://yann.lecun.com&quot;</span>)]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load</span>(<span class="hljs-params">train_size=<span class="hljs-number">50_000</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    # Load the data</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># the data, split between train and test sets</span><br>    train = torchvision.datasets.MNIST(<span class="hljs-string">&quot;./&quot;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>)<br>    test = torchvision.datasets.MNIST(<span class="hljs-string">&quot;./&quot;</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>)<br>    (x_train, y_train), (x_test, y_test) = (train.data, train.targets), (test.data, test.targets)<br><br>    <span class="hljs-comment"># split off a validation set for hyperparameter tuning</span><br>    x_train, x_val = x_train[:train_size], x_train[train_size:]<br>    y_train, y_val = y_train[:train_size], y_train[train_size:]<br><br>    training_set = TensorDataset(x_train, y_train)<br>    validation_set = TensorDataset(x_val, y_val)<br>    test_set = TensorDataset(x_test, y_test)<br><br>    datasets = [training_set, validation_set, test_set]<br><br>    <span class="hljs-keyword">return</span> datasets<br></code></pre></td></tr></table></figure>
<p>è¿™å»ºç«‹äº†ä¸€ä¸ªæ¨¡å¼ï¼Œæˆ‘ä»¬å°†åœ¨è¿™ä¸ªä¾‹å­ä¸­çœ‹åˆ°é‡å¤ï¼šå°†æ•°æ®è®°å½•ä¸ºå·¥ä»¶çš„ä»£ç åŒ…è£¹åœ¨ç”Ÿæˆè¯¥æ•°æ®çš„ä»£ç å‘¨å›´ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”¨äº
<code>load</code>ing æ•°æ®çš„ä»£ç ä¸ç”¨äº <code>load_and_log</code>ging
æ•°æ®çš„ä»£ç åˆ†å¼€ã€‚</p>
<p>è¿™æ˜¯å¾ˆå¥½çš„åšæ³•ï¼</p>
<p>ä¸ºäº†å°†è¿™äº›æ•°æ®é›†è®°å½•ä¸ºå·¥ä»¶ï¼Œæˆ‘ä»¬åªéœ€è¦</p>
<ol type="1">
<li>ä½¿ç”¨ <code>wandb.init</code> åˆ›å»º <code>Run</code>ï¼Œ(L4)</li>
<li>ä¸ºæ•°æ®é›† (L10) åˆ›å»ºä¸€ä¸ª <code>Artifact</code>ï¼Œä»¥åŠ</li>
<li>ä¿å­˜å¹¶è®°å½•ç›¸å…³ <code>file</code>sï¼ˆL20ã€L23ï¼‰ã€‚</li>
</ol>
<p>æŸ¥çœ‹ä¸‹é¢ä»£ç å•å…ƒçš„ç¤ºä¾‹ï¼Œç„¶åå±•å¼€åé¢çš„éƒ¨åˆ†ä»¥äº†è§£æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_and_log</span>():<br><br>    <span class="hljs-comment"># ğŸš€ start a run, with a type to label it and a project it can call home</span><br>    <span class="hljs-keyword">with</span> wandb.init(project=<span class="hljs-string">&quot;artifacts-example&quot;</span>, job_type=<span class="hljs-string">&quot;load-data&quot;</span>) <span class="hljs-keyword">as</span> run:<br>        <br>        datasets = load()  <span class="hljs-comment"># separate code for loading the datasets</span><br>        names = [<span class="hljs-string">&quot;training&quot;</span>, <span class="hljs-string">&quot;validation&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>]<br><br>        <span class="hljs-comment"># ğŸº create our Artifact</span><br>        raw_data = wandb.Artifact(<br>            <span class="hljs-string">&quot;mnist-raw&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;dataset&quot;</span>,<br>            description=<span class="hljs-string">&quot;Raw MNIST dataset, split into train/val/test&quot;</span>,<br>            metadata=&#123;<span class="hljs-string">&quot;source&quot;</span>: <span class="hljs-string">&quot;torchvision.datasets.MNIST&quot;</span>,<br>                      <span class="hljs-string">&quot;sizes&quot;</span>: [<span class="hljs-built_in">len</span>(dataset) <span class="hljs-keyword">for</span> dataset <span class="hljs-keyword">in</span> datasets]&#125;)<br><br>        <span class="hljs-keyword">for</span> name, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(names, datasets):<br>            <span class="hljs-comment"># ğŸ£ Store a new file in the artifact, and write something into its contents.</span><br>            <span class="hljs-keyword">with</span> raw_data.new_file(name + <span class="hljs-string">&quot;.pt&quot;</span>, mode=<span class="hljs-string">&quot;wb&quot;</span>) <span class="hljs-keyword">as</span> file:<br>                x, y = data.tensors<br>                torch.save((x, y), file)<br><br>        <span class="hljs-comment"># âœï¸ Save the artifact to W&amp;B.</span><br>        run.log_artifact(raw_data)<br><br>load_and_log()<br></code></pre></td></tr></table></figure>
<h4 id="wandb.init">ğŸš€ <code>wandb.init</code></h4>
<p>å½“æˆ‘ä»¬åˆ¶ä½œå°†è¦äº§ç”Ÿ <code>Artifact</code>s çš„
<code>Run</code>æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è¯´æ˜å®ƒå±äºå“ªä¸ª <code>project</code>ã€‚</p>
<p>æ ¹æ®æ‚¨çš„å·¥ä½œæµç¨‹ï¼Œé¡¹ç›®å¯èƒ½å¤§åˆ°
<code>car-that-drives-itself</code>ï¼Œä¹Ÿå¯èƒ½å°åˆ°
<code>iterative-architecture-experiment-117</code>ã€‚</p>
<p>Depending on your workflow, a project might be as big as
<code>car-that-drives-itself</code> or as small as
<code>iterative-architecture-experiment-117</code>.</p>
<blockquote>
<p>ğŸ‘è§„åˆ™ï¼šå¦‚æœå¯ä»¥ï¼Œè¯·å°†æ‰€æœ‰å…±äº« <code>Artifact</code>s çš„
<code>Run</code>s ä¿ç•™åœ¨ä¸€ä¸ªé¡¹ç›®ä¸­ã€‚è¿™ä½¿äº‹æƒ…å˜å¾—ç®€å•ï¼Œä½†ä¸è¦æ‹…å¿ƒ
<code>Artifact</code>s å¯ä»¥è·¨é¡¹ç›®ç§»æ¤ï¼</p>
</blockquote>
<p>ä¸ºäº†å¸®åŠ©è·Ÿè¸ªæ‚¨å¯èƒ½è¿è¡Œçš„æ‰€æœ‰ä¸åŒç±»å‹çš„ä½œä¸šï¼Œåœ¨è¿›è¡Œ <code>Run</code>s
æ—¶æä¾› <code>job_type</code> å¾ˆæœ‰ç”¨ã€‚è¿™å¯ä»¥ä½¿æ‚¨çš„ Artifacts
å›¾è¡¨ä¿æŒæ•´æ´ã€‚</p>
<blockquote>
<p>ğŸ‘è§„åˆ™ï¼š<code>job_type</code>
åº”è¯¥æ˜¯æè¿°æ€§çš„ï¼Œå¹¶ä¸”å¯¹åº”äºä½ çš„ç®¡é“çš„å•ä¸ªæ­¥éª¤ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†
<code>load</code>ing æ•°æ®ä¸ <code>preprocess</code>ing æ•°æ®åˆ†å¼€ã€‚</p>
</blockquote>
<h4 id="wandb.artifact">ğŸº <code>wandb.Artifact</code></h4>
<p>è¦å°†æŸç‰©è®°å½•ä¸º <code>Artifact</code>ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆåˆ›å»ºä¸€ä¸ª
<code>Artifact</code> å¯¹è±¡ã€‚</p>
<p>æ¯ä¸ª <code>Artifact</code> éƒ½æœ‰ä¸€ä¸ª
<code>name</code>â€”â€”è¿™æ˜¯ç¬¬ä¸€ä¸ªå‚æ•°è®¾ç½®çš„åç§°ã€‚</p>
<blockquote>
<p>ğŸ‘çš„è§„åˆ™ï¼š<code>name</code>
åº”è¯¥æ˜¯æè¿°æ€§çš„ï¼Œä½†æ˜“äºè®°å¿†å’Œè¾“å…¥â€”â€”æˆ‘ä»¬å–œæ¬¢ä½¿ç”¨è¿å­—ç¬¦åˆ†éš”çš„åç§°ï¼Œå¹¶ä¸ä»£ç ä¸­çš„å˜é‡åç›¸å¯¹åº”ã€‚</p>
</blockquote>
<p>å®ƒä¹Ÿæœ‰ä¸€ä¸ª <code>type</code>ã€‚å°±åƒ <code>Run</code>s çš„
<code>job_types</code> ä¸€æ ·ï¼Œå®ƒç”¨äºç»„ç»‡ <code>Run</code>s å’Œ
<code>Artifact</code>s çš„å›¾è¡¨ã€‚</p>
<blockquote>
<p>ğŸ‘çš„è§„åˆ™ï¼š<code>type</code> åº”è¯¥ç®€å•ï¼šæ¯”
<code>mnist-data-YYYYMMDD</code> æ›´åƒ <code>dataset</code> æˆ–
<code>model</code>ã€‚</p>
</blockquote>
<p>æ‚¨è¿˜å¯ä»¥é™„åŠ  <code>description</code> å’Œä¸€äº›
<code>metadata</code>ï¼Œä½œä¸ºå­—å…¸ã€‚<code>metadata</code> åªéœ€è¦å¯åºåˆ—åŒ–ä¸º
JSONã€‚</p>
<blockquote>
<p>ğŸ‘è§„åˆ™ï¼š<code>metadata</code>åº”å°½å¯èƒ½å…·æœ‰æè¿°æ€§ã€‚</p>
</blockquote>
<h4 id="artifact.new_file-and-run.log_artifact">ğŸ£
<code>artifact.new_file</code> and âœï¸ <code>run.log_artifact</code></h4>
<p>ä¸€æ—¦æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª <code>Artifact</code>
å¯¹è±¡ï¼Œæˆ‘ä»¬éœ€è¦å‘å®ƒæ·»åŠ æ–‡ä»¶ã€‚</p>
<p>æ‚¨æ²¡çœ‹é”™ï¼šå¸¦æœ‰ s çš„ <em>files</em>ã€‚<code>Artifact</code>s
çš„ç»“æ„ç±»ä¼¼äºç›®å½•ï¼ŒåŒ…å«æ–‡ä»¶å’Œå­ç›®å½•ã€‚</p>
<blockquote>
<p>ğŸ‘è§„åˆ™ï¼šåªè¦æœ‰å¿…è¦ï¼Œå°† <code>Artifact</code>
çš„å†…å®¹æ‹†åˆ†ä¸ºå¤šä¸ªæ–‡ä»¶ã€‚å¦‚æœéœ€è¦æ‰©å±•ï¼Œè¿™å°†æœ‰æ‰€å¸®åŠ©ï¼</p>
</blockquote>
<p>æˆ‘ä»¬ä½¿ç”¨ <code>new_file</code> æ–¹æ³•åŒæ—¶å†™å…¥æ–‡ä»¶å¹¶å°†å…¶é™„åŠ åˆ°
<code>Artifact</code>ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ <code>add_file</code>
æ–¹æ³•ï¼Œå®ƒå°†è¿™ä¸¤ä¸ªæ­¥éª¤åˆ†å¼€</p>
<p>æ·»åŠ å®Œæ‰€æœ‰æ–‡ä»¶åï¼Œæˆ‘ä»¬éœ€è¦å°† <code>log_artifact</code> æ·»åŠ åˆ° <a
target="_blank" rel="noopener" href="https://wandb.ai/?_gl=1*r07jdw*_ga*MTUwMzMwNTA4NC4xNjg1MzI0NjI3*_ga_JH1SJHJQXJ*MTY4NjY1MzgzNC45LjEuMTY4NjY1MzgzOS41NS4wLjA.">wandb.ai</a>ã€‚</p>
<p>æ‚¨ä¼šæ³¨æ„åˆ°ä¸€äº› URL å‡ºç°åœ¨è¾“å‡ºä¸­ï¼ŒåŒ…æ‹¬ä¸€ä¸ªç”¨äºè¿è¡Œé¡µé¢çš„
URLã€‚æ‚¨å¯ä»¥åœ¨æ­¤å¤„æŸ¥çœ‹ <code>Run</code> ç»“æœï¼ŒåŒ…æ‹¬å·²è®°å½•çš„ä»»ä½•
<code>Artifact</code>sã€‚</p>
<p>æˆ‘ä»¬å°†åœ¨ä¸‹é¢çœ‹åˆ°ä¸€äº›ç¤ºä¾‹ï¼Œè¿™äº›ç¤ºä¾‹å¯ä»¥æ›´å¥½åœ°åˆ©ç”¨â€œè¿è¡Œâ€é¡µé¢çš„å…¶ä»–ç»„ä»¶ã€‚</p>
<h3 id="use-a-logged-dataset-artifact">2ï¸âƒ£ Use a Logged Dataset
Artifact</h3>
<p>ä¸åšç‰©é¦†ä¸­çš„ artifacts ä¸åŒï¼ŒW&amp;B ä¸­çš„ <code>Artifact</code>s
æ—¨åœ¨ä½¿ç”¨ï¼Œè€Œä¸ä»…ä»…æ˜¯å­˜å‚¨ã€‚</p>
<p>è®©æˆ‘ä»¬çœ‹çœ‹å®ƒæ˜¯ä»€ä¹ˆæ ·çš„ã€‚</p>
<p>ä¸‹é¢çš„å•å…ƒæ ¼å®šä¹‰äº†ä¸€ä¸ªç®¡é“æ­¥éª¤ï¼Œè¯¥æ­¥éª¤æ¥æ”¶åŸå§‹æ•°æ®é›†å¹¶ä½¿ç”¨å®ƒæ¥ç”Ÿæˆ
<code>preprocess</code>ed æ•°æ®é›†ï¼š<code>normalize</code>d
å’Œæ­£ç¡®æ•´å½¢ã€‚</p>
<p>å†æ¬¡æ³¨æ„ï¼Œæˆ‘ä»¬ä»ä¸ <code>wandb</code>
æ¥å£çš„ä»£ç ä¸­åˆ†ç¦»å‡ºäº†ä»£ç çš„ä¸»ä½“ï¼Œå³ <code>preprocess</code>ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess</span>(<span class="hljs-params">dataset, normalize=<span class="hljs-literal">True</span>, expand_dims=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    ## Prepare the data</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    x, y = dataset.tensors<br><br>    <span class="hljs-keyword">if</span> normalize:<br>        <span class="hljs-comment"># Scale images to the [0, 1] range</span><br>        x = x.<span class="hljs-built_in">type</span>(torch.float32) / <span class="hljs-number">255</span><br><br>    <span class="hljs-keyword">if</span> expand_dims:<br>        <span class="hljs-comment"># Make sure images have shape (1, 28, 28)</span><br>        x = torch.unsqueeze(x, <span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-keyword">return</span> TensorDataset(x, y)<br></code></pre></td></tr></table></figure>
<p>ç°åœ¨æ˜¯ä½¿ç”¨ <code>wandb.Artifact</code> æ—¥å¿—è®°å½•è¿™ä¸ª
<code>preprocess</code> æ­¥éª¤çš„ä»£ç ã€‚</p>
<p>è¯·æ³¨æ„ï¼Œä¸‹é¢çš„ç¤ºä¾‹éƒ½ <code>use</code>s äº†ä¸€ä¸ªæ–°çš„
<code>Artifact</code>ï¼Œå¹¶å°†å…¶ <code>log</code>s
ä¸‹æ¥ï¼Œè¿™ä¸ä¸Šä¸€æ­¥ç›¸åŒã€‚<code>Artifact</code>s æ—¢æ˜¯ <code>Run</code>s
çš„è¾“å…¥åˆæ˜¯è¾“å‡ºï¼</p>
<p>æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ–°çš„
<code>job_type</code>ï¼Œ<code>preprocess-data</code>ï¼Œæ¥æ˜ç¡®è¿™æ˜¯ä¸€ä¸ªä¸åŒäºä¹‹å‰çš„
jobã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_and_log</span>(<span class="hljs-params">steps</span>):<br><br>    <span class="hljs-keyword">with</span> wandb.init(project=<span class="hljs-string">&quot;artifacts-example&quot;</span>, job_type=<span class="hljs-string">&quot;preprocess-data&quot;</span>) <span class="hljs-keyword">as</span> run:<br><br>        processed_data = wandb.Artifact(<br>            <span class="hljs-string">&quot;mnist-preprocess&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;dataset&quot;</span>,<br>            description=<span class="hljs-string">&quot;Preprocessed MNIST dataset&quot;</span>,<br>            metadata=steps)<br>         <br>        <span class="hljs-comment"># âœ”ï¸ declare which artifact we&#x27;ll be using</span><br>        raw_data_artifact = run.use_artifact(<span class="hljs-string">&#x27;mnist-raw:latest&#x27;</span>)<br><br>        <span class="hljs-comment"># ğŸ“¥ if need be, download the artifact</span><br>        raw_dataset = raw_data_artifact.download()<br>        <br>        <span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;training&quot;</span>, <span class="hljs-string">&quot;validation&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>]:<br>            raw_split = read(raw_dataset, split)<br>            processed_dataset = preprocess(raw_split, **steps)<br><br>            <span class="hljs-keyword">with</span> processed_data.new_file(split + <span class="hljs-string">&quot;.pt&quot;</span>, mode=<span class="hljs-string">&quot;wb&quot;</span>) <span class="hljs-keyword">as</span> file:<br>                x, y = processed_dataset.tensors<br>                torch.save((x, y), file)<br><br>        run.log_artifact(processed_data)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read</span>(<span class="hljs-params">data_dir, split</span>):<br>    filename = split + <span class="hljs-string">&quot;.pt&quot;</span><br>    x, y = torch.load(os.path.join(data_dir, filename))<br><br>    <span class="hljs-keyword">return</span> TensorDataset(x, y)<br></code></pre></td></tr></table></figure>
<p>è¿™é‡Œè¦æ³¨æ„çš„ä¸€ä»¶äº‹æ˜¯é¢„å¤„ç†çš„ <code>steps</code> ä½œä¸º
<code>metadata</code> ä¸ <code>preprocessed_data</code> ä¸€èµ·ä¿å­˜ã€‚</p>
<p>å¦‚æœæ‚¨æƒ³è®©æ‚¨çš„å®éªŒå¯é‡ç°ï¼Œæ•è·å¤§é‡å…ƒæ•°æ®æ˜¯ä¸ªå¥½ä¸»æ„ï¼</p>
<p>æ­¤å¤–ï¼Œå³ä½¿æˆ‘ä»¬çš„æ•°æ®é›†æ˜¯
"<code>large artifact</code>"ï¼Œ<code>download</code>
æ­¥éª¤ä¹Ÿå¯ä»¥åœ¨ä¸åˆ°ä¸€ç§’çš„æ—¶é—´å†…å®Œæˆã€‚</p>
<p>å±•å¼€ä¸‹é¢çš„ markdown å•å…ƒæ ¼ä»¥äº†è§£è¯¦ç»†ä¿¡æ¯ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">steps = &#123;<span class="hljs-string">&quot;normalize&quot;</span>: <span class="hljs-literal">True</span>,<br>         <span class="hljs-string">&quot;expand_dims&quot;</span>: <span class="hljs-literal">True</span>&#125;<br><br>preprocess_and_log(steps)<br></code></pre></td></tr></table></figure>
<h4 id="run.use_artifact">âœ”ï¸ <code>run.use_artifact</code></h4>
<p>è¿™äº›æ­¥éª¤æ¯”è¾ƒç®€å•ã€‚æ¶ˆè´¹è€…åªéœ€è¦çŸ¥é“ <code>Artifact</code>
çš„<code>name</code>ï¼Œå†åŠ ä¸Š bit moreã€‚</p>
<p>â€œbit moreâ€ æ˜¯æ‚¨æƒ³è¦çš„ <code>Artifact</code> çš„ç‰¹å®šç‰ˆæœ¬çš„
<code>alias</code>ã€‚</p>
<p>é»˜è®¤æƒ…å†µä¸‹ï¼Œæœ€åä¸Šä¼ çš„ç‰ˆæœ¬è¢«æ ‡è®°ä¸º<code>latest</code>ã€‚å¦åˆ™ï¼Œæ‚¨å¯ä»¥é€‰æ‹©å¸¦æœ‰
<code>v0</code>/<code>v1</code>
ç­‰çš„æ—§ç‰ˆæœ¬ï¼Œæˆ–è€…æ‚¨å¯ä»¥æä¾›è‡ªå·±çš„åˆ«åï¼Œä¾‹å¦‚ <code>best</code> æˆ–
<code>jit-script</code>ã€‚å°±åƒ <a target="_blank" rel="noopener" href="https://hub.docker.com/">Docker
Hub</a> æ ‡ç­¾ä¸€æ ·ï¼Œåˆ«åä¸åç§°ç”¨ <code>:</code> åˆ†éš”ï¼Œæ‰€ä»¥æˆ‘ä»¬æƒ³è¦çš„
<code>Artifact</code> æ˜¯ <code>mnist-raw:latest</code>ã€‚</p>
<blockquote>
<p>ğŸ‘è§„åˆ™ï¼šä¿æŒåˆ«åç®€çŸ­è€Œç”œç¾ã€‚å½“æ‚¨æƒ³è¦æ»¡è¶³æŸäº›å±æ€§çš„
<code>Artifact</code> æ—¶ï¼Œè¯·ä½¿ç”¨è‡ªå®šä¹‰ <code>alias</code>esï¼Œå¦‚
<code>latest</code> æˆ– <code>best</code></p>
</blockquote>
<h4 id="artifact.download">ğŸ“¥ <code>artifact.download</code></h4>
<p>ç°åœ¨ï¼Œæ‚¨å¯èƒ½æ­£åœ¨æ‹…å¿ƒ <code>download</code>
è°ƒç”¨ã€‚å¦‚æœæˆ‘ä»¬å†ä¸‹è½½ä¸€ä»½ï¼Œå†…å­˜çš„è´Ÿæ‹…ä¼šä¸ä¼šåŠ å€ï¼Ÿ</p>
<p>åˆ«æ‹…å¿ƒï¼Œæœ‹å‹ã€‚åœ¨æˆ‘ä»¬å®é™…ä¸‹è½½ä»»ä½•ä¸œè¥¿ä¹‹å‰ï¼Œæˆ‘ä»¬ä¼šæ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰æ­£ç¡®çš„ç‰ˆæœ¬ã€‚ä½¿ç”¨å’Œç‰ˆæœ¬æ§åˆ¶
<code>git</code> å’Œ <a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Torrent_file">torrenting</a>
ç›¸åŒçš„æŠ€æœ¯ï¼šhashingã€‚</p>
<p>éšç€ <code>Artifact</code>s çš„åˆ›å»ºå’Œè®°å½•ï¼Œå·¥ä½œç›®å½•ä¸­åä¸º
<code>artifacts</code> çš„æ–‡ä»¶å¤¹å°†å¼€å§‹å¡«å……å­ç›®å½•ï¼Œæ¯ä¸ª
<code>Artifact</code>ä¸€ä¸ªã€‚ä½¿ç”¨ <code>!tree artifacts</code>
æ£€æŸ¥å…¶å†…å®¹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">!tree artifacts<br></code></pre></td></tr></table></figure>
<h4 id="the-artifacts-page-on-wandb.ai">ğŸŒ The Artifacts page on <a
target="_blank" rel="noopener" href="https://wandb.ai/">wandb.ai</a></h4>
<p>ç°åœ¨æˆ‘ä»¬å·²ç»è®°å½•å¹¶ä½¿ç”¨äº†ä¸€ä¸ª <code>Artifact</code>ï¼Œè®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹
Run é¡µé¢ä¸Šçš„ Artifacts é€‰é¡¹å¡ã€‚</p>
<p>ä»<code>wandb</code> è¾“å‡ºå¯¼èˆªåˆ°è¿è¡Œé¡µé¢
URLï¼Œç„¶åä»å·¦ä¾§è¾¹æ ä¸­é€‰æ‹©â€œå·¥ä»¶â€é€‰é¡¹å¡ï¼ˆå®ƒæ˜¯å¸¦æœ‰æ•°æ®åº“å›¾æ ‡çš„é€‰é¡¹å¡ï¼Œçœ‹èµ·æ¥åƒä¸‰ä¸ªå†°çƒå åœ¨ä¸€èµ·ï¼‰ã€‚</p>
<p>å•å‡» "Input Artifacts" è¡¨æˆ– "Output Artifacts"
è¡¨ä¸­çš„ä¸€è¡Œï¼Œç„¶åæŸ¥çœ‹é€‰é¡¹å¡ï¼ˆ"Overview", "Metadata"ï¼‰ä»¥æŸ¥çœ‹è®°å½•çš„æœ‰å…³
<code>Artifact</code> çš„æ‰€æœ‰å†…å®¹ã€‚</p>
<p>æˆ‘ä»¬ç‰¹åˆ«å–œæ¬¢ "Graph View"ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒæ˜¾ç¤ºä¸€ä¸ªå›¾è¡¨ï¼Œå…¶ä¸­
<code>Artifact</code>s çš„ <code>type</code>s å’Œ <code>Run</code> çš„
<code>job_types</code> æ˜¯ä¸¤ç§ç±»å‹çš„èŠ‚ç‚¹ï¼Œç®­å¤´ä»£è¡¨æ¶ˆè´¹å’Œç”Ÿäº§ã€‚</p>
<h3 id="log-a-model">3ï¸âƒ£ Log a Model</h3>
<p>è¿™è¶³ä»¥äº†è§£ <code>Artifact</code>s çš„ API
å¦‚ä½•å·¥ä½œï¼Œä½†è®©æˆ‘ä»¬æŒ‰ç…§è¿™ä¸ªç¤ºä¾‹ä¸€ç›´åˆ°ç®¡é“çš„æœ«å°¾ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥äº†è§£
<code>Artifact</code>s å¦‚ä½•æ”¹è¿›æ‚¨çš„ ML å·¥ä½œæµç¨‹ã€‚</p>
<p>è¿™é‡Œçš„ç¬¬ä¸€ä¸ªå•å…ƒæ ¼åœ¨ PyTorch ä¸­æ„å»ºäº†ä¸€ä¸ª DNN
<code>model</code>â€”â€”ä¸€ä¸ªéå¸¸ç®€å•çš„ ConvNetã€‚</p>
<p>æˆ‘ä»¬å°†ä»åˆå§‹åŒ– <code>model</code>
å¼€å§‹ï¼Œè€Œä¸æ˜¯è®­ç»ƒå®ƒã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥é‡å¤è®­ç»ƒï¼ŒåŒæ—¶ä¿æŒå…¶ä»–ä¸€åˆ‡ä¸å˜ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> floor<br><br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ConvNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_layer_sizes=[<span class="hljs-number">32</span>, <span class="hljs-number">64</span>],</span><br><span class="hljs-params">                  kernel_sizes=[<span class="hljs-number">3</span>],</span><br><span class="hljs-params">                  activation=<span class="hljs-string">&quot;ReLU&quot;</span>,</span><br><span class="hljs-params">                  pool_sizes=[<span class="hljs-number">2</span>],</span><br><span class="hljs-params">                  dropout=<span class="hljs-number">0.5</span>,</span><br><span class="hljs-params">                  num_classes=num_classes,</span><br><span class="hljs-params">                  input_shape=input_shape</span>):<br>      <br>        <span class="hljs-built_in">super</span>(ConvNet, self).__init__()<br><br>        self.layer1 = nn.Sequential(<br>              nn.Conv2d(in_channels=input_shape[<span class="hljs-number">0</span>], out_channels=hidden_layer_sizes[<span class="hljs-number">0</span>], kernel_size=kernel_sizes[<span class="hljs-number">0</span>]),<br>              <span class="hljs-built_in">getattr</span>(nn, activation)(),<br>              nn.MaxPool2d(kernel_size=pool_sizes[<span class="hljs-number">0</span>])<br>        )<br>        self.layer2 = nn.Sequential(<br>              nn.Conv2d(in_channels=hidden_layer_sizes[<span class="hljs-number">0</span>], out_channels=hidden_layer_sizes[-<span class="hljs-number">1</span>], kernel_size=kernel_sizes[-<span class="hljs-number">1</span>]),<br>              <span class="hljs-built_in">getattr</span>(nn, activation)(),<br>              nn.MaxPool2d(kernel_size=pool_sizes[-<span class="hljs-number">1</span>])<br>        )<br>        self.layer3 = nn.Sequential(<br>              nn.Flatten(),<br>              nn.Dropout(dropout)<br>        )<br><br>        fc_input_dims = floor((input_shape[<span class="hljs-number">1</span>] - kernel_sizes[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span>) / pool_sizes[<span class="hljs-number">0</span>]) <span class="hljs-comment"># layer 1 output size</span><br>        fc_input_dims = floor((fc_input_dims - kernel_sizes[-<span class="hljs-number">1</span>] + <span class="hljs-number">1</span>) / pool_sizes[-<span class="hljs-number">1</span>]) <span class="hljs-comment"># layer 2 output size</span><br>        fc_input_dims = fc_input_dims*fc_input_dims*hidden_layer_sizes[-<span class="hljs-number">1</span>] <span class="hljs-comment"># layer 3 output size</span><br><br>        self.fc = nn.Linear(fc_input_dims, num_classes)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.layer1(x)<br>        x = self.layer2(x)<br>        x = self.layer3(x)<br>        x = self.fc(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure>
<p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ W&amp;B æ¥è·Ÿè¸ªè¿è¡Œï¼Œå› æ­¤ä½¿ç”¨
<code>wandb.config</code> å¯¹è±¡æ¥å­˜å‚¨æ‰€æœ‰è¶…å‚æ•°ã€‚</p>
<p>è¯¥ <code>config</code> å¯¹è±¡çš„ <code>dict</code>ionary
ç‰ˆæœ¬æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„ <code>metadata</code>ï¼Œæ‰€ä»¥ä¸€å®šè¦åŒ…å«å®ƒï¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_model_and_log</span>(<span class="hljs-params">config</span>):<br>    <span class="hljs-keyword">with</span> wandb.init(project=<span class="hljs-string">&quot;artifacts-example&quot;</span>, job_type=<span class="hljs-string">&quot;initialize&quot;</span>, config=config) <span class="hljs-keyword">as</span> run:<br>        config = wandb.config<br>        <br>        model = ConvNet(**config)<br><br>        model_artifact = wandb.Artifact(<br>            <span class="hljs-string">&quot;convnet&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;model&quot;</span>,<br>            description=<span class="hljs-string">&quot;Simple AlexNet style CNN&quot;</span>,<br>            metadata=<span class="hljs-built_in">dict</span>(config))<br><br>        torch.save(model.state_dict(), <span class="hljs-string">&quot;initialized_model.pth&quot;</span>)<br>        <span class="hljs-comment"># â• another way to add a file to an Artifact</span><br>        model_artifact.add_file(<span class="hljs-string">&quot;initialized_model.pth&quot;</span>)<br><br>        wandb.save(<span class="hljs-string">&quot;initialized_model.pth&quot;</span>)<br><br>        run.log_artifact(model_artifact)<br><br>model_config = &#123;<span class="hljs-string">&quot;hidden_layer_sizes&quot;</span>: [<span class="hljs-number">32</span>, <span class="hljs-number">64</span>],<br>                <span class="hljs-string">&quot;kernel_sizes&quot;</span>: [<span class="hljs-number">3</span>],<br>                <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;ReLU&quot;</span>,<br>                <span class="hljs-string">&quot;pool_sizes&quot;</span>: [<span class="hljs-number">2</span>],<br>                <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.5</span>,<br>                <span class="hljs-string">&quot;num_classes&quot;</span>: <span class="hljs-number">10</span>&#125;<br><br>build_model_and_log(model_config)<br></code></pre></td></tr></table></figure>
<h4 id="artifact.add_file">â• <code>artifact.add_file</code></h4>
<p>ä¸åœ¨æ•°æ®é›†æ—¥å¿—è®°å½•ç¤ºä¾‹ä¸­åŒæ—¶ç¼–å†™ <code>new_file</code> å¹¶å°†å…¶æ·»åŠ åˆ°
<code>Artifact</code> ä¸åŒï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä¸€æ­¥å†™å…¥æ–‡ä»¶ï¼ˆæ­¤å¤„ä¸º
<code>torch.save</code>ï¼‰ï¼Œç„¶ååœ¨å¦ä¸€æ­¥ä¸­å°†å®ƒä»¬ <code>add</code> åˆ°
<code>Artifact</code>ã€‚</p>
<blockquote>
<p>ğŸ‘è§„åˆ™ï¼šå°½å¯èƒ½ä½¿ç”¨ <code>new_file</code>ï¼Œä»¥é˜²æ­¢é‡å¤ã€‚</p>
</blockquote>
<h3 id="use-a-logged-model-artifact">4ï¸âƒ£ Use a Logged Model Artifact</h3>
<p>å°±åƒæˆ‘ä»¬å¯ä»¥åœ¨ <code>dataset</code> ä¸Šè°ƒç”¨ <code>use_artifact</code>
ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æˆ‘ä»¬çš„ <code>initialized_model</code>
ä¸Šè°ƒç”¨å®ƒä»¥åœ¨å¦ä¸€ä¸ªè¿è¡Œä¸­ä½¿ç”¨å®ƒã€‚</p>
<p>è¿™ä¸€æ¬¡ï¼Œè®©æˆ‘ä»¬ <code>train</code> <code>model</code>ã€‚</p>
<p>æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬å…³äº <a
target="_blank" rel="noopener" href="http://wandb.me/pytorch-colab">instrumenting W&amp;B with
PyTorch</a> çš„ Colabã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">model, train_loader, valid_loader, config</span>):<br>    optimizer = <span class="hljs-built_in">getattr</span>(torch.optim, config.optimizer)(model.parameters())<br>    model.train()<br>    example_ct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.epochs):<br>        <span class="hljs-keyword">for</span> batch_idx, (data, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>            data, target = data.to(device), target.to(device)<br>            optimizer.zero_grad()<br>            output = model(data)<br>            loss = F.cross_entropy(output, target)<br>            loss.backward()<br>            optimizer.step()<br><br>            example_ct += <span class="hljs-built_in">len</span>(data)<br><br>            <span class="hljs-keyword">if</span> batch_idx % config.batch_log_interval == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0%&#125;)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>                    epoch, batch_idx * <span class="hljs-built_in">len</span>(data), <span class="hljs-built_in">len</span>(train_loader.dataset),<br>                    batch_idx / <span class="hljs-built_in">len</span>(train_loader), loss.item()))<br>                <br>                train_log(loss, example_ct, epoch)<br><br>        <span class="hljs-comment"># evaluate the model on the validation set at each epoch</span><br>        loss, accuracy = test(model, valid_loader)  <br>        test_log(loss, accuracy, example_ct, epoch)<br><br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">model, test_loader</span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> test_loader:<br>            data, target = data.to(device), target.to(device)<br>            output = model(data)<br>            test_loss += F.cross_entropy(output, target, reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)  <span class="hljs-comment"># sum up batch loss</span><br>            pred = output.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># get the index of the max log-probability</span><br>            correct += pred.eq(target.view_as(pred)).<span class="hljs-built_in">sum</span>()<br><br>    test_loss /= <span class="hljs-built_in">len</span>(test_loader.dataset)<br><br>    accuracy = <span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_loader.dataset)<br>    <br>    <span class="hljs-keyword">return</span> test_loss, accuracy<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_log</span>(<span class="hljs-params">loss, example_ct, epoch</span>):<br>    loss = <span class="hljs-built_in">float</span>(loss)<br><br>    <span class="hljs-comment"># where the magic happens</span><br>    wandb.log(&#123;<span class="hljs-string">&quot;epoch&quot;</span>: epoch, <span class="hljs-string">&quot;train/loss&quot;</span>: loss&#125;, step=example_ct)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Loss after &quot;</span> + <span class="hljs-built_in">str</span>(example_ct).zfill(<span class="hljs-number">5</span>) + <span class="hljs-string">f&quot; examples: <span class="hljs-subst">&#123;loss:<span class="hljs-number">.3</span>f&#125;</span>&quot;</span>)<br>    <br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_log</span>(<span class="hljs-params">loss, accuracy, example_ct, epoch</span>):<br>    loss = <span class="hljs-built_in">float</span>(loss)<br>    accuracy = <span class="hljs-built_in">float</span>(accuracy)<br><br>    <span class="hljs-comment"># where the magic happens</span><br>    wandb.log(&#123;<span class="hljs-string">&quot;epoch&quot;</span>: epoch, <span class="hljs-string">&quot;validation/loss&quot;</span>: loss, <span class="hljs-string">&quot;validation/accuracy&quot;</span>: accuracy&#125;, step=example_ct)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Loss/accuracy after &quot;</span> + <span class="hljs-built_in">str</span>(example_ct).zfill(<span class="hljs-number">5</span>) + <span class="hljs-string">f&quot; examples: <span class="hljs-subst">&#123;loss:<span class="hljs-number">.3</span>f&#125;</span>/<span class="hljs-subst">&#123;accuracy:<span class="hljs-number">.3</span>f&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>è¿™æ¬¡æˆ‘ä»¬å°†è¿è¡Œä¸¤ä¸ªç‹¬ç«‹çš„ <code>Artifact</code> ç”Ÿäº§
<code>Run</code>sã€‚</p>
<p>ä¸€æ—¦ç¬¬ä¸€ä¸ªå®Œæˆ <code>train</code>ing
<code>model</code>ï¼Œç¬¬äºŒä¸ªå°†é€šè¿‡è¯„ä¼°å…¶åœ¨ <code>test_dataset</code>
ä¸Šçš„æ€§èƒ½æ¥ä½¿ç”¨ <code>trained-model</code> <code>Artifact</code>ã€‚</p>
<p>æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æå–ç½‘ç»œæœ€æ··ä¹±çš„ 32
ä¸ªç¤ºä¾‹â€”â€”åœ¨è¿™äº›ç¤ºä¾‹ä¸­ï¼Œ<code>categorical_crossentropy</code> æœ€é«˜ã€‚</p>
<p>è¿™æ˜¯è¯Šæ–­æ•°æ®é›†å’Œæ¨¡å‹é—®é¢˜çš„å¥½æ–¹æ³•ï¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">model, test_loader</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    ## Evaluate the trained model</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    loss, accuracy = test(model, test_loader)<br>    highest_losses, hardest_examples, true_labels, predictions = get_hardest_k_examples(model, test_loader.dataset)<br><br>    <span class="hljs-keyword">return</span> loss, accuracy, highest_losses, hardest_examples, true_labels, predictions<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_hardest_k_examples</span>(<span class="hljs-params">model, testing_set, k=<span class="hljs-number">32</span></span>):<br>    model.<span class="hljs-built_in">eval</span>()<br><br>    loader = DataLoader(testing_set, <span class="hljs-number">1</span>, shuffle=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-comment"># get the losses and predictions for each item in the dataset</span><br>    losses = <span class="hljs-literal">None</span><br>    predictions = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> loader:<br>            data, target = data.to(device), target.to(device)<br>            output = model(data)<br>            loss = F.cross_entropy(output, target)<br>            pred = output.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>            <br>            <span class="hljs-keyword">if</span> losses <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                losses = loss.view((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>                predictions = pred<br>            <span class="hljs-keyword">else</span>:<br>                losses = torch.cat((losses, loss.view((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))), <span class="hljs-number">0</span>)<br>                predictions = torch.cat((predictions, pred), <span class="hljs-number">0</span>)<br><br>    argsort_loss = torch.argsort(losses, dim=<span class="hljs-number">0</span>)<br><br>    highest_k_losses = losses[argsort_loss[-k:]]<br>    hardest_k_examples = testing_set[argsort_loss[-k:]][<span class="hljs-number">0</span>]<br>    true_labels = testing_set[argsort_loss[-k:]][<span class="hljs-number">1</span>]<br>    predicted_labels = predictions[argsort_loss[-k:]]<br><br>    <span class="hljs-keyword">return</span> highest_k_losses, hardest_k_examples, true_labels, predicted_labels<br></code></pre></td></tr></table></figure>
<p>è¿™äº›æ—¥å¿—è®°å½•åŠŸèƒ½ä¸ä¼šæ·»åŠ ä»»ä½•æ–°çš„ <code>Artifact</code>
åŠŸèƒ½ï¼Œå› æ­¤æˆ‘ä»¬ä¸ä¼šå¯¹å…¶è¿›è¡Œè¯„è®ºï¼šæˆ‘ä»¬åªæ˜¯åœ¨ä½¿ç”¨ã€ä¸‹è½½å’Œè®°å½•
<code>Artifact</code>sã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_and_log</span>(<span class="hljs-params">config</span>):<br><br>    <span class="hljs-keyword">with</span> wandb.init(project=<span class="hljs-string">&quot;artifacts-example&quot;</span>, job_type=<span class="hljs-string">&quot;train&quot;</span>, config=config) <span class="hljs-keyword">as</span> run:<br>        config = wandb.config<br><br>        data = run.use_artifact(<span class="hljs-string">&#x27;mnist-preprocess:latest&#x27;</span>)<br>        data_dir = data.download()<br><br>        training_dataset =  read(data_dir, <span class="hljs-string">&quot;training&quot;</span>)<br>        validation_dataset = read(data_dir, <span class="hljs-string">&quot;validation&quot;</span>)<br><br>        train_loader = DataLoader(training_dataset, batch_size=config.batch_size)<br>        validation_loader = DataLoader(validation_dataset, batch_size=config.batch_size)<br>        <br>        model_artifact = run.use_artifact(<span class="hljs-string">&quot;convnet:latest&quot;</span>)<br>        model_dir = model_artifact.download()<br>        model_path = os.path.join(model_dir, <span class="hljs-string">&quot;initialized_model.pth&quot;</span>)<br>        model_config = model_artifact.metadata<br>        config.update(model_config)<br><br>        model = ConvNet(**model_config)<br>        model.load_state_dict(torch.load(model_path))<br>        model = model.to(device)<br> <br>        train(model, train_loader, validation_loader, config)<br><br>        model_artifact = wandb.Artifact(<br>            <span class="hljs-string">&quot;trained-model&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;model&quot;</span>,<br>            description=<span class="hljs-string">&quot;Trained NN model&quot;</span>,<br>            metadata=<span class="hljs-built_in">dict</span>(model_config))<br><br>        torch.save(model.state_dict(), <span class="hljs-string">&quot;trained_model.pth&quot;</span>)<br>        model_artifact.add_file(<span class="hljs-string">&quot;trained_model.pth&quot;</span>)<br>        wandb.save(<span class="hljs-string">&quot;trained_model.pth&quot;</span>)<br><br>        run.log_artifact(model_artifact)<br><br>    <span class="hljs-keyword">return</span> model<br><br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_and_log</span>(<span class="hljs-params">config=<span class="hljs-literal">None</span></span>):<br>    <br>    <span class="hljs-keyword">with</span> wandb.init(project=<span class="hljs-string">&quot;artifacts-example&quot;</span>, job_type=<span class="hljs-string">&quot;report&quot;</span>, config=config) <span class="hljs-keyword">as</span> run:<br>        data = run.use_artifact(<span class="hljs-string">&#x27;mnist-preprocess:latest&#x27;</span>)<br>        data_dir = data.download()<br>        testing_set = read(data_dir, <span class="hljs-string">&quot;test&quot;</span>)<br><br>        test_loader = torch.utils.data.DataLoader(testing_set, batch_size=<span class="hljs-number">128</span>, shuffle=<span class="hljs-literal">False</span>)<br><br>        model_artifact = run.use_artifact(<span class="hljs-string">&quot;trained-model:latest&quot;</span>)<br>        model_dir = model_artifact.download()<br>        model_path = os.path.join(model_dir, <span class="hljs-string">&quot;trained_model.pth&quot;</span>)<br>        model_config = model_artifact.metadata<br><br>        model = ConvNet(**model_config)<br>        model.load_state_dict(torch.load(model_path))<br>        model.to(device)<br><br>        loss, accuracy, highest_losses, hardest_examples, true_labels, preds = evaluate(model, test_loader)<br><br>        run.summary.update(&#123;<span class="hljs-string">&quot;loss&quot;</span>: loss, <span class="hljs-string">&quot;accuracy&quot;</span>: accuracy&#125;)<br><br>        wandb.log(&#123;<span class="hljs-string">&quot;high-loss-examples&quot;</span>:<br>            [wandb.Image(hard_example, caption=<span class="hljs-built_in">str</span>(<span class="hljs-built_in">int</span>(pred)) + <span class="hljs-string">&quot;,&quot;</span> +  <span class="hljs-built_in">str</span>(<span class="hljs-built_in">int</span>(label)))<br>             <span class="hljs-keyword">for</span> hard_example, pred, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(hardest_examples, preds, true_labels)]&#125;)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">train_config = &#123;<span class="hljs-string">&quot;batch_size&quot;</span>: <span class="hljs-number">128</span>,<br>                <span class="hljs-string">&quot;epochs&quot;</span>: <span class="hljs-number">5</span>,<br>                <span class="hljs-string">&quot;batch_log_interval&quot;</span>: <span class="hljs-number">25</span>,<br>                <span class="hljs-string">&quot;optimizer&quot;</span>: <span class="hljs-string">&quot;Adam&quot;</span>&#125;<br><br>model = train_and_log(train_config)<br>evaluate_and_log()<br></code></pre></td></tr></table></figure>
<h4 id="the-graph-view">ğŸ” The Graph View</h4>
<p>è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ›´æ”¹äº† <code>Artifact</code> çš„ <code>type</code>ï¼šè¿™äº›
<code>Run</code>s ä½¿ç”¨çš„æ˜¯æ¨¡å‹ï¼Œè€Œä¸æ˜¯æ•°æ®é›†ã€‚åœ¨ Artifacts
é¡µé¢çš„å›¾å½¢è§†å›¾ä¸­ï¼Œç”Ÿäº§æ¨¡å‹çš„ <code>Run</code>s å°†ä¸ç”Ÿæˆ
<code>dataset</code>s çš„è¿è¡Œåˆ†å¼€ã€‚</p>
<p>å»çœ‹çœ‹å§ï¼å’Œä»¥å‰ä¸€æ ·ï¼Œæ‚¨éœ€è¦å‰å¾€ Run é¡µé¢ï¼Œä»å·¦ä¾§æ ä¸­é€‰æ‹© "Artifacts"
é€‰é¡¹å¡ï¼Œé€‰æ‹©ä¸€ä¸ª <code>Artifact</code>ï¼Œç„¶åå•å‡» "Graph View"
é€‰é¡¹å¡ã€‚</p>
<h4 id="exploded-graphs">ğŸ’£ Exploded Graphs</h4>
<p>æ‚¨å¯èƒ½å·²ç»æ³¨æ„åˆ°æ ‡æœ‰â€œçˆ†ç‚¸â€çš„æŒ‰é’®ã€‚ä¸è¦ç‚¹å‡»å®ƒï¼Œå› ä¸ºå®ƒä¼šåœ¨ W&amp;B
æ€»éƒ¨æ‚¨ä¸èµ·çœ¼çš„ä½œè€…åŠå…¬æ¡Œä¸‹å¼•çˆ†ä¸€æšå°ç‚¸å¼¹ï¼</p>
<p>åªæ˜¯åœ¨å¼€ç©ç¬‘ã€‚å®ƒä»¥æ›´æ¸©å’Œçš„æ–¹å¼â€œåˆ†è§£â€å›¾è¡¨ï¼š<code>Artifact</code>s å’Œ
<code>Run</code>s åœ¨å•ä¸ªå®ä¾‹çº§åˆ«è€Œä¸æ˜¯ç±»å‹çº§åˆ«åˆ†ç¦»ï¼šèŠ‚ç‚¹ä¸æ˜¯
<code>dataset</code> å’Œ <code>load-data</code>ï¼Œè€Œæ˜¯
<code>dataset:mnist-raw:v1</code> å’Œ
<code>load-data:sunny-smoke-1</code>ï¼Œç­‰ç­‰ã€‚</p>
<p>è¿™æä¾›äº†å¯¹æ‚¨çš„ç®¡é“çš„å…¨é¢æ´å¯Ÿï¼Œè®°å½•çš„æŒ‡æ ‡ã€å…ƒæ•°æ®ç­‰éƒ½è§¦æ‰‹å¯åŠâ€”â€”æ‚¨ä»…å—é™äºæ‚¨é€‰æ‹©ä¸æˆ‘ä»¬ä¸€èµ·è®°å½•çš„å†…å®¹ã€‚</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">æ·±åº¦å­¦ä¹ </a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/WandB/" class="print-no-link">#WandB</a>
      
        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="print-no-link">#æ·±åº¦å­¦ä¹ </a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>WandB å­¦ä¹ æ—¥è®°ï¼ˆä¸€ï¼‰Tutorials</div>
      <div>https://blog.lfd-world.online/2023/06/12/wandb-xue-xi-ri-ji-yi-doc/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>ä½œè€…</div>
          <div>åŸ¹æ ¹è¯·åŠ è›‹</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>å‘å¸ƒäº</div>
          <div>2023å¹´6æœˆ12æ—¥</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>è®¸å¯åè®®</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - ç½²å">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/06/16/gai-lu-lun-yi-bei-xie-si-ding-li/" title="æ¦‚ç‡è®ºï¼ˆä¸€ï¼‰ è´å¶æ–¯å…¬å¼">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">æ¦‚ç‡è®ºï¼ˆä¸€ï¼‰ è´å¶æ–¯å…¬å¼</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/06/04/github-pages-ge-ren-bo-ke-da-jian-si-zi-ding-yi-yu-ming-ji-bai-du-gu-ge-shou-lu/" title="Github Pages + Hexo + Vercel ä¸ªäººåšå®¢æ­å»ºï¼ˆå››ï¼‰è‡ªå®šä¹‰åŸŸååŠç™¾åº¦è°·æ­Œæ”¶å½•">
                        <span class="hidden-mobile">Github Pages + Hexo + Vercel ä¸ªäººåšå®¢æ­å»ºï¼ˆå››ï¼‰è‡ªå®šä¹‰åŸŸååŠç™¾åº¦è°·æ­Œæ”¶å½•</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>ç›®å½•</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>







  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div>
  </noscript>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
